"doi","title","keywords","year","abstract","authors","url","ReferencesId","idpaper"
"10.1109/TVCG.2010.126","behaviorism: a framework for dynamic data visualization","Frameworks, information visualization, information art, dynamic data",2010,"While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.","Angus Graeme Forbes;Tobias Höllerer;George Legrady","http://dx.doi.org/10.1109/TVCG.2010.126","10.1109/INFVIS.2004.64;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1997.636761;10.1109/TVCG.2009.111",1
"10.1109/TVCG.2010.129","A Visual Backchannel for Large-Scale Events","Backchannel, information visualization, events, multiple views, microblogging, information retrieval, World Wide Web",2010,"We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.","Marian Dörk;Dan Gruen;Carey L. Williamson;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2010.129","10.1109/VAST.2009.5333443;10.1109/TVCG.2007.70541;10.1109/TVCG.2008.166;10.1109/TVCG.2008.175;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2003.1249028;10.1109/VAST.2008.4677364;10.1109/VAST.2009.5333437",2
"10.1109/TVCG.2010.138","Comparative Analysis of Multidimensional; Quantitative Data","Multidimensional data, cluster comparison, bioinformatics visualization",2010,"When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.","Alexander Lex;Marc Streit;Christian Partl;Karl Kashofer;Dieter Schmalstieg","http://dx.doi.org/10.1109/TVCG.2010.138","10.1109/VISUAL.1996.568118;10.1109/VISUAL.1990.146402;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70556;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.167;10.1109/INFVIS.2000.885086",3
"10.1109/TVCG.2010.144","Declarative Language Design for Interactive Visualization","Information visualization, user interfaces, toolkits, domain specific languages, declarative languages, optimization",2010,"We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.","Jeffrey Heer;Michael Bostock","http://dx.doi.org/10.1109/TVCG.2010.144","10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.12;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.128;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.191;10.1109/TVCG.2009.110;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885086",4
"10.1109/TVCG.2010.154","FacetAtlas: Multifaceted Visualization for Rich Text Corpora","Multi-facet visualization, Text visualization, Multi-relational Graph, Search UI",2010,"Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.","Nan Cao;Jimeng Sun;Yu-Ru Lin;David Gotz;Shixia Liu;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2010.154","10.1109/TVCG.2006.122;10.1109/VAST.2009.5333443;10.1109/INFVIS.2000.885098;10.1109/TVCG.2009.140;10.1109/TVCG.2008.135;10.1109/TVCG.2008.172;10.1109/TVCG.2009.139;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2006.142;10.1109/TVCG.2006.147;10.1109/VISUAL.1998.745302;10.1109/TVCG.2009.165;10.1109/INFVIS.1995.528686;10.1109/TVCG.2006.185",5
"10.1109/TVCG.2010.159","GeneaQuilts: A System for Exploring Large Genealogies","Genealogy visualization, interaction",2010,"GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring & Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.","Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete;Juhee Bae;Benjamin Watson","http://dx.doi.org/10.1109/TVCG.2010.159","10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2005.1532124",6
"10.1109/TVCG.2010.161","Graphical inference for infovis","Statistics, visual testing, permutation tests, null hypotheses, data plots",2010,"How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The ""Rorschach"" helps the analyst calibrate their understanding of uncertainty and ""line-up"" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.","Hadley Wickham;Dianne Cook;Heike Hofmann;Andreas Buja","http://dx.doi.org/10.1109/TVCG.2010.161","10.1109/TVCG.2007.70577",7
"10.1109/TVCG.2010.162","Graphical Perception of Multiple Time Series","Line graphs, braided graphs, horizon graphs, small multiples, stacked graphs, evaluation, design guidelines",2010,"Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.","Waqas Javed;Bryan McDonnel;Niklas Elmqvist","http://dx.doi.org/10.1109/TVCG.2010.162","10.1109/TVCG.2008.166;10.1109/TVCG.2007.70583;10.1109/TVCG.2007.70535;10.1109/INFVIS.1999.801851;10.1109/TVCG.2008.125;10.1109/INFVIS.2005.1532144",8
"10.1109/TVCG.2010.164","How Information Visualization Novices Construct Visualizations","Empirical study, visualization, visualization construction, visual analytics, visual mapping, novices",2010,"It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.","Lars Grammel;Melanie Tory;Margaret-Anne D. Storey","http://dx.doi.org/10.1109/TVCG.2010.164","10.1109/TVCG.2007.70515;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333878;10.1109/TVCG.2008.109;10.1109/VAST.2006.261428;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70594;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2000.885092;10.1109/TVCG.2008.137",9
"10.1109/TVCG.2010.174","Laws of Attraction: From Perceptual Forces to Conceptual Similarity","Perceptual cognition, visualization models, laboratory studies, cognition theory",2010,"Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.","Caroline Ziemkiewicz;Robert Kosara","http://dx.doi.org/10.1109/TVCG.2010.174","10.1109/TVCG.2008.125",10
"10.1109/TVCG.2010.175","ManiWordle: Providing Flexible Control over Wordle","Interaction design, direct manipulation, flexibilty-usability tradeoff, tag-cloud, participatory visualization, user study ",2010,"Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired ""art work,"" harnessing the power behind the ever-increasing popularity of Wordle.","Kyle Koh;Bongshin Lee;Bo Hyoung Kim;Jinwook Seo","http://dx.doi.org/10.1109/TVCG.2010.175","10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.171;10.1109/VAST.2009.5333443;10.1109/INFVIS.2003.1249031",11
"10.1109/TVCG.2010.176","Matching Visual Saliency to Confidence in Plots of Uncertain Data","Uncertainty visualization, brushing, scatter plots, parallel coordinates, multivariate data",2010,"Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.","David Feng;Lester Kwock;Yueh Lee;Russell M. Taylor II","http://dx.doi.org/10.1109/TVCG.2010.176","10.1109/TVCG.2008.119;10.1109/INFVIS.2001.963286;10.1109/TVCG.2008.167;10.1109/TVCG.2009.179;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.131;10.1109/VISUAL.1999.809866;10.1109/TVCG.2009.114;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.3;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.153;10.1109/TVCG.2009.118",12
"10.1109/TVCG.2010.177","Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective","Mental model, model-based reasoning, distributed cognition, interaction, theory, information visualization",2010,"Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.","Zhicheng Liu;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2010.177","10.1109/TVCG.2009.187;10.1109/TVCG.2008.155;10.1109/INFVIS.2001.963289;10.1109/TVCG.2009.109;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.180;10.1109/TVCG.2008.109;10.1109/TVCG.2008.171;10.1109/TVCG.2008.121;10.1109/VAST.2008.4677365",13
"10.1109/TVCG.2010.179","Narrative Visualization: Telling Stories with Data","Narrative visualization, storytelling, design methods, case study, journalism, social data analysis",2010,"Data visualization is regularly promoted for its ability to reveal stories within data, yet these ÔÇ£data storiesÔÇØ differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.","Edward Segel;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2010.179","10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992",14
"10.1109/TVCG.2010.184","Pargnostics: Screen-Space Metrics for Parallel Coordinates","Parallel coordinates, metrics, display optimization, visualization models",2010,"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.","Aritra Dasgupta;Robert Kosara","http://dx.doi.org/10.1109/TVCG.2010.184","10.1109/INFVIS.2005.1532142;10.1109/TVCG.2006.138;10.1109/VISUAL.1990.146402;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729559;10.1109/INFVIS.1997.636793",15
"10.1109/TVCG.2010.185","PedVis: A Structured; Space-Efficient Technique for Pedigree Visualization","Genealogy, Pedigree, H-tree",2010,"Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.","Claurissa Tuttle;Luis Gustavo Nonato;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2010.185","10.1109/TVCG.2008.158;10.1109/TVCG.2008.141;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173152;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.1997.636718",16
"10.1109/TVCG.2010.186","Perceptual Guidelines for Creating Rectangular Treemaps","Graphical Perception, Visualization, Treemaps, Rectangular Area, Visual Encoding, Experiment, Mechanical Turk",2010,"Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.","Nicholas Kong;Jeffrey Heer;Maneesh Agrawala","http://dx.doi.org/10.1109/TVCG.2010.186","10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2004.70;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2007.70583;10.1109/INFVIS.2001.963283;10.1109/INFVIS.2001.963290;10.1109/TVCG.2008.171;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2002.1173153",17
"10.1109/TVCG.2010.191","Rethinking Map Legends with Visualization","Cartography, design, Digimap service, legend, online web mapping, visualization",2010,"This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.","Jason Dykes;Jo Wood;Aidan Slingsby","http://dx.doi.org/10.1109/TVCG.2010.191","10.1109/TVCG.2007.70561;10.1109/TVCG.2008.165;10.1109/TVCG.2007.70539;10.1109/TVCG.2006.202;10.1109/INFVIS.2000.885095;10.1109/TVCG.2007.70589;10.1109/TVCG.2009.128",18
"10.1109/TVCG.2010.194","SparkClouds: Visualizing Trends in Tag Clouds","Tag clouds, trend visualization, multiple line graphs, stacked bar charts, evaluation",2010,"Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.","Bongshin Lee;Nathalie Henry Riche;Amy K. Karlson;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2010.194","10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70589",19
"10.1109/TVCG.2010.197","Stacking Graphic Elements to Avoid Over-Plotting","Dot plots, Parallel coordinate plots, Multidimensional data, Density-based visualization",2010,"An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.","Dang Tuan Nhon;Leland Wilkinson;Anushka Anand","http://dx.doi.org/10.1109/TVCG.2010.197","10.1109/INFVIS.2005.1532139;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.131;10.1109/INFVIS.1995.528685;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2004.68;10.1109/INFVIS.2000.885098",20
"10.1109/TVCG.2010.205","The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration","Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu",2010,"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.","Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica","http://dx.doi.org/10.1109/TVCG.2010.205","10.1109/TVCG.2009.151;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532141;10.1109/TVCG.2006.187;10.1109/INFVIS.2004.47;10.1109/TVCG.2007.70521;10.1109/INFVIS.2003.1249011;10.1109/TVCG.2008.153",21
"10.1109/TVCG.2010.206","The Streams of Our Lives: Visualizing Listening Histories in Context","Information visualization, lifelogging, design study, music, listening history, timelines, photos, calendars",2010,"The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.","Dominikus Baur;Frederik Seiffert;Michael Sedlmair;Sebastian Boring","http://dx.doi.org/10.1109/TVCG.2010.206","10.1109/TVCG.2008.166;10.1109/TVCG.2007.70541;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801851;10.1109/VAST.2006.261421",22
"10.1109/TVCG.2010.210","Untangling Euler Diagrams","Information Visualization, Euler diagrams, Set Visualization, Graph Visualization",2010,"In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.","Nathalie Henry Riche;Tim Dwyer","http://dx.doi.org/10.1109/TVCG.2010.210","10.1109/TVCG.2008.144;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2008.141;10.1109/TVCG.2009.122;10.1109/TVCG.2006.156;10.1109/TVCG.2006.120;10.1109/TVCG.2008.130;10.1109/TVCG.2006.166;10.1109/VISUAL.1993.398863;10.1109/TVCG.2008.153",23
"10.1109/TVCG.2010.216","Visualization of Diversity in Large Multivariate Data Sets","Information visualization, diversity, categorical data, multivariate data, evaluation",2010,"Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity.","Tuan Pham;Rob Hess;Crystal Ju;Eugene Zhang;Ronald A. Metoyer","http://dx.doi.org/10.1109/TVCG.2010.216","10.1109/VISUAL.1990.146402;10.1109/VISUAL.1990.146386;10.1109/INFVIS.2004.15;10.1109/INFVIS.1997.636793;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.68",24
"10.1109/TVCG.2010.222","Visualizations everywhere: A Multiplatform Infrastructure for Linked Visualizations","Visualization systems, toolkit design, data transformation and representation",2010,"In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.","Danyel Fisher;Steven M. Drucker;Roland Fernandez;Scott Ruble","http://dx.doi.org/10.1109/TVCG.2010.222","10.1109/INFVIS.2004.12;10.1109/TVCG.2009.148;10.1109/TVCG.2008.175;10.1109/TVCG.2009.174;10.1109/TVCG.2007.70577;10.1109/INFVIS.2000.885086",25
"10.1109/VAST.2010.5652392","DimStiller: Workflows for dimensional analysis and reduction","",2010,"DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.","Stephen Ingram;Tamara Munzner;Veronika Irvine;Melanie Tory;Steven Bergner;Torsten Möller","http://dx.doi.org/10.1109/VAST.2010.5652392","10.1109/INFVIS.2003.1249013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2006.178;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.71",26
"10.1109/VAST.2010.5652398","Visual exploration of classification models for risk assessment","Visual Analytics, Interactive Visual Exploration, Decision Boundary Visualization, Multi-dimensional Space, Classification",2010,"In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier's performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach.","Malgorzata Migut;Marcel Worring","http://dx.doi.org/10.1109/VAST.2010.5652398","10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532139;10.1109/VAST.2009.5332628;10.1109/INFVIS.1998.729559;10.1109/TVCG.2009.199;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/VAST.2008.4677369;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.153",27
"10.1109/VAST.2010.5652433","Improving the visual analysis of high-dimensional datasets using quality measures","",2010,"Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.","Georgia Albuquerque;Martin Eisemann;Dirk J. Lehmann;Holger Theisel;Marcus A. Magnor","http://dx.doi.org/10.1109/VAST.2010.5652433","10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",28
"10.1109/VAST.2010.5652443","iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction","",2010,"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.","Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park","http://dx.doi.org/10.1109/VAST.2010.5652443","10.1109/VAST.2009.5332629;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2004.60;10.1109/TVCG.2009.153",29
"10.1109/VAST.2010.5652460","Flow-based scatterplots for sensitivity analysis","Uncertainty, Data Transformations, Principal Component Analysis, Model fitting

",2010,"Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.","Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma","http://dx.doi.org/10.1109/VAST.2010.5652460","10.1109/TVCG.2008.119;10.1109/VAST.2008.4677368;10.1109/VAST.2009.5332611;10.1109/VAST.2007.4389000;10.1109/TVCG.2006.166;10.1109/TVCG.2008.153",30
"10.1109/VAST.2010.5652478","Discovering bits of place histories from people's activity traces","event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization 
",2010,"Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.","Gennady L. Andrienko;Natalia V. Andrienko;Martin Mladenov;Michael Mock;Christian Pölitz","http://dx.doi.org/10.1109/VAST.2010.5652478","10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70621",31
"10.1109/VAST.2010.5652520","Multidimensional data dissection using attribute relationship graphs","",2010,"Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools.","Chris Weaver","http://dx.doi.org/10.1109/VAST.2010.5652520","10.1109/TVCG.2008.137;10.1109/TVCG.2006.122;10.1109/VAST.2006.261432;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2002.1173158;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2004.64",32
"10.1109/VAST.2010.5652530","Visual market sector analysis for financial time series data","Visual Analytics, financial Information Visualization, Time Series Data, Time Series Clustering, Explorative Analysis

",2010,"The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.","Hartmut Ziegler;Marco Jenny;Tino Gruse;Daniel A. Keim","http://dx.doi.org/10.1109/VAST.2010.5652530","10.1109/INFVIS.2001.963273;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2001.963288;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2003.1249027",33
"10.1109/VAST.2010.5652879","A closer look at note taking in the co-located collaborative visual analytics process","note taking, recording, collaboration, tabletop, wall display, history, provenance 
",2010,"This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.","Narges Mahyar;Ali Sarvghad;Melanie Tory","http://dx.doi.org/10.1109/VAST.2010.5652879","10.1109/TVCG.2008.137;10.1109/VAST.2008.4677358;10.1109/TVCG.2007.70568;10.1109/VAST.2009.5333020;10.1109/VAST.2008.4677365;10.1109/VAST.2009.5333023;10.1109/TVCG.2007.70577",34
"10.1109/VAST.2010.5652880","An exploratory study of co-located collaborative visual analytics around a tabletop display","",2010,"Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.","Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen Quinn;Mary Czerwinski","http://dx.doi.org/10.1109/VAST.2010.5652880","10.1109/VAST.2006.261439;10.1109/VAST.2007.4389006;10.1109/VAST.2006.261415;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/TVCG.2007.70568",35
"10.1109/VAST.2010.5652885","Click2Annotate: Automated Insight Externalization with rich semantics","Visual Analytics, Decision Making, Annotation, Insight Management, Multidimensional Visualization",2010,"Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.","Yang Chen;Scott Barlowe;Jing Yang 0001","http://dx.doi.org/10.1109/VAST.2010.5652885","10.1109/VISUAL.1990.146375;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70541;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.139",36
"10.1109/VAST.2010.5652910","NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks","Sensemaking, Semantic Graph Layout, Visual Analytics, Network Diagnosis, Information Visualization",2010,"Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.","Zhicheng Liu;Bongshin Lee;Srikanth Kandula;Ratul Mahajan","http://dx.doi.org/10.1109/VAST.2010.5652910","10.1109/TVCG.2006.122;10.1109/TVCG.2007.70522;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389006;10.1109/VAST.2006.261429",37
"10.1109/VAST.2010.5652931","Understanding text corpora with multiple facets","text visualization, multi-facet data visualization",2010,"Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.","Lei Shi;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Michelle X. Zhou","http://dx.doi.org/10.1109/VAST.2010.5652931","10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389005;10.1109/TVCG.2008.172;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2009.165;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801866;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2000.885097",38
"10.1109/VAST.2010.5652932","VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis","Collaborative visualization, text and document data, intelligence analysis",2010,"In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.","Haeyong Chung;Seungwon Yang;Naveed Massjouni;Christopher Andrews;Rahul Kanna;Chris North","http://dx.doi.org/10.1109/VAST.2010.5652932","10.1109/TVCG.2009.148;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333245;10.1109/VAST.2008.4677362;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677366",39
"10.1109/VAST.2010.5652940","Two-stage framework for a topology-based projection and visualization of classified document collections","",2010,"During the last decades, electronic textual information has become the world's largest and most important information source. Daily newspapers, books, scientific and governmental publications, blogs and private messages have grown into a wellspring of endless information and knowledge. Since neither existing nor new information can be read in its entirety, we rely increasingly on computers to extract and visualize meaningful or interesting topics and documents from this huge information reservoir. In this paper, we extend, improve and combine existing individual approaches into an overall framework that supports topologi-cal analysis of high dimensional document point clouds given by the well-known tf-idf document-term weighting method. We show that traditional distance-based approaches fail in very high dimensional spaces, and we describe an improved two-stage method for topology-based projections from the original high dimensional information space to both two dimensional (2-D) and three dimensional (3-D) visualizations. To demonstrate the accuracy and usability of this framework, we compare it to methods introduced recently and apply it to complex document and patent collections.","Patrick Oesterling;Gerik Scheuermann;Sven Teresniak;Gerhard Heyer;Steffen Koch;Thomas Ertl;Gunther H. Weber","http://dx.doi.org/10.1109/VAST.2010.5652940","10.1109/VAST.2009.5333564;10.1109/TVCG.2007.70601;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5332629;10.1109/TVCG.2009.119",40
"10.1109/VAST.2010.5653598","Helping users recall their reasoning process","Visual analytics, visualization, reasoning process ",2010,"The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.","Heather Lipford;Felesia Stukes;Wenwen Dou;Matthew E. Hawkins;Remco Chang","http://dx.doi.org/10.1109/VAST.2010.5653598","10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/VAST.2008.4677365;10.1109/VAST.2008.4677360;10.1109/VAST.2007.4389009",41
"10.1109/VAST.2010.5653599","Comparing different levels of interaction constraints for deriving visual problem isomorphs","Interaction, Visual Isomorph, Problem Solving",2010,"Interaction and manual manipulation have been shown in the cognitive science literature to play a critical role in problem solving. Given different types of interactions or constraints on interactions, a problem can appear to have different degrees of difficulty. While this relationship between interaction and problem solving has been well studied in the cognitive science literatures, the visual analytics community has yet to exploit this understanding for analytical problem solving. In this paper, we hypothesize that constraints on interactions and constraints encoded in visual representations can lead to strategies of varying effectiveness during problem solving. To test our hypothesis, we conducted a user study in which participants were given different levels of interaction constraints when solving a simple math game called Number Scrabble. Number Scrabble is known to have an optimal visual problem isomorph, and the goal of this study is to learn if and how the participants could derive the isomorph and to analyze the strategies that the participants utilize in solving the problem. Our results indicate that constraints on interactions do affect problem solving, and that while the optimal visual isomorph is difficult to derive, certain interaction constraints can lead to a higher chance of deriving the isomorph.","Wenwen Dou;Caroline Ziemkiewicz;Lane Harrison;Dong Hyun Jeong;Roxanne Ryan;William Ribarsky;Xiaoyu Wang;Remco Chang","http://dx.doi.org/10.1109/VAST.2010.5653599","10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121",42
"10.1109/TVCG.2010.132","An Information-theoretic Framework for Visualization","Information theory, theory of visualization, quantitative evaluation",2010,"In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.","Min Chen;Heike Leitte","http://dx.doi.org/10.1109/TVCG.2010.132","10.1109/TVCG.2007.70615;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.152;10.1109/INFVIS.1996.559213;10.1109/VISUAL.2005.1532834;10.1109/INFVIS.2000.885096;10.1109/TVCG.2007.70515;10.1109/TVCG.2006.159;10.1109/INFVIS.2004.59;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2008.121;10.1109/INFVIS.1997.636792;10.1109/VISUAL.2005.1532833;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375;10.1109/VISUAL.2002.1183785",43
"10.1109/TVCG.2010.139","Computing Robustness and Persistence for Images","Voxel arrays, oct-trees, persistent homology, persistence diagrams, level sets, robustness, approximations, plant roots",2010,"We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R3 and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.","Paul Bendich;Herbert Edelsbrunner;Michael Kerber","http://dx.doi.org/10.1109/TVCG.2010.139","10.1109/VISUAL.1997.663875",44
"10.1109/TVCG.2010.145","Direct Interval Volume Visualization","Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",2010,"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.","Marco Ament;Daniel Weiskopf;Hamish Carr","http://dx.doi.org/10.1109/TVCG.2010.145","10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807",45
"10.1109/TVCG.2010.146","Discontinuities in Continuous Scatter Plots","Discontinuity, Scatterplot, Topology, Data Visualization",2010,"The concept of continuous scatterplot (CSP) is a modern visualization technique. The idea is to define a scalar density value based on the map between an n-dimensional spatial domain and an m-dimensional data domain, which describe the CSP space. Usually the data domain is two-dimensional to visually convey the underlying, density coded, data. In this paper we investigate kinds of map-based discontinuities, especially for the practical cases n = m = 2 and n = 3 | m = 2, and we depict relations between them and attributes of the resulting CSP itself. Additionally, we show that discontinuities build critical line structures, and we introduce algorithms to detect them. Further, we introduce a discontinuity-based visualization approach - called contribution map (CM) -which establishes a relationship between the CSP's data domain and the number of connected components in the spatial domain. We show that CMs enhance the CSP-based linking & brushing interaction. Finally, we apply our approaches to a number of synthetic as well as real data sets.","Dirk J. Lehmann;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2010.146","10.1109/TVCG.2006.168;10.1109/TVCG.2008.119;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2009.131",46
"10.1109/TVCG.2010.147","Edge Aware Anisotropic Diffusion for 3D Scalar Data","Anisotropic diffusion, PDE, De-noising, Scale-Space, Principal Curvatures",2010,"In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.","Zahid Hossain 0001;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2010.147","10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.96;10.1109/VISUAL.2001.964516",47
"10.1109/TVCG.2010.148","Efficient High-Quality Volume Rendering of SPH Data","Particle visualization, volume rendering, ray-casting, GPU resampling",2010,"High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.","Roland Fraedrich;Stefan Auer;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2010.148","10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",48
"10.1109/TVCG.2010.152","Exploration and Visualization of Segmentation Uncertainty using Shape and Appearance Prior Information","Uncertainty visualization, Medical imaging, Probabilistic segmentation",2010,"We develop an interactive analysis and visualization tool for probabilistic segmentation in medical imaging. The originality of our approach is that the data exploration is guided by shape and appearance knowledge learned from expert-segmented images of a training population. We introduce a set of multidimensional transfer function widgets to analyze the multivariate probabilistic field data. These widgets furnish the user with contextual information about conformance or deviation from the population statistics. We demonstrate the user's ability to identify suspicious regions (e.g. tumors) and to correct the misclassification results. We evaluate our system and demonstrate its usefulness in the context of static anatomical and time-varying functional imaging datasets.","Ahmed Saad;Ghassan Hamarneh;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2010.152","10.1109/TVCG.2009.189;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70518",49
"10.1109/TVCG.2010.155","Fast High-Quality Volume Ray Casting with Virtual Samplings","Direct volume rendering, GPU, high quality, curve interpolation",2010,"Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.","Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong-Gil Shin;Bo Hyoung Kim","http://dx.doi.org/10.1109/TVCG.2010.155","10.1109/VISUAL.1994.346331;10.1109/VISUAL.2004.70;10.1109/VISUAL.2005.1532810;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384",50
"10.1109/TVCG.2010.157","FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces","Direct-touch interaction, wall displays, 3D navigation and exploration, evaluation, illustrative visualization",2010,"We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.","Lingyun Yu;Pjotr Svetachov;Petra Isenberg;Maarten H. Everts;Tobias Isenberg 0001","http://dx.doi.org/10.1109/TVCG.2010.157","10.1109/VISUAL.2005.1532778;10.1109/TVCG.2007.70515;10.1109/VISUAL.2004.30",51
"10.1109/TVCG.2010.160","Gradient Estimation Revitalized","Derivative, Gradient, Reconstruction, Sampling, Lattice, Interpolation, Approximation, Frequency Error Kernel",2010,"We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.","Usman R. Alim;Torsten Möller;Laurent Condat","http://dx.doi.org/10.1109/TVCG.2010.160","10.1109/VISUAL.2001.964498;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1997.663848;10.1109/VISUAL.2004.65",52
"10.1109/TVCG.2010.166","Illustrative Stream Surfaces","Flow visualization, Stream surfaces, Illustrative rendering, Silhouettes, GPU technique, 3D vector field data",2010,"Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.","Silvia Born;Alexander Wiebel;Jan Friedrich;Gerik Scheuermann;Dirk Bartz","http://dx.doi.org/10.1109/TVCG.2010.166","10.1109/VISUAL.1990.146395;10.1109/TVCG.2009.190;10.1109/TVCG.2007.70565;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.1999.809905;10.1109/TVCG.2008.133;10.1109/TVCG.2009.138;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2005.1532855;10.1109/TVCG.2008.170;10.1109/VISUAL.2004.113;10.1109/VISUAL.2003.1250376",53
"10.1109/TVCG.2010.169","Interactive Separating Streak Surfaces","Unsteady flow visualization, feature extraction, streak surface generation, GPUs",2010,"Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.","Florian Ferstl;Kai Bürger;Holger Theisel;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2010.169","10.1109/TVCG.2009.190;10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.133;10.1109/VISUAL.2001.964506;10.1109/TVCG.2007.70554;10.1109/VISUAL.1993.398875;10.1109/TVCG.2009.177;10.1109/TVCG.2009.154;10.1109/TVCG.2006.151;10.1109/TVCG.2007.70551;10.1109/TVCG.2008.163;10.1109/VISUAL.2005.1532780",54
"10.1109/TVCG.2010.170","Interactive Vector field Feature Identification","Vector field, data clustering, feature classification, high-dimensional data, user interaction",2010,"We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.","Joel Daniels II;Erik W. Anderson;Luis Gustavo Nonato;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2010.170","10.1109/TVCG.2009.138;10.1109/VISUAL.1993.398846;10.1109/TVCG.2007.70579;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1998.745333;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.116;10.1109/TVCG.2009.190;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1991.175771;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2000.885689",55
"10.1109/TVCG.2010.171","Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector","Visualization in physical sciences and engineering, time series data, coordinated multiple views",2010,"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.","Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2010.171","10.1109/TVCG.2009.155;10.1109/INFVIS.2002.1173149;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2002.1173157",56
"10.1109/TVCG.2010.173","IRIS: Illustrative Rendering for Integral Surfaces","Flow visualization, integral surfaces, illustrative rendering",2010,"Integral surfaces are ideal tools to illustrate vector fields and fluid flow structures. However, these surfaces can be visually complex and exhibit difficult geometric properties, owing to strong stretching, shearing and folding of the flow from which they are derived. Many techniques for non-photorealistic rendering have been presented previously. It is, however, unclear how these techniques can be applied to integral surfaces. In this paper, we examine how transparency and texturing techniques can be used with integral surfaces to convey both shape and directional information. We present a rendering pipeline that combines these techniques aimed at faithfully and accurately representing integral surfaces while improving visualization insight. The presented pipeline is implemented directly on the GPU, providing real-time interaction for all rendering modes, and does not require expensive preprocessing of integral surfaces after computation.","Mathias Hummel;Christoph Garth;Bernd Hamann;Hans Hagen;Kenneth I. Joy","http://dx.doi.org/10.1109/TVCG.2010.173","10.1109/TVCG.2006.124;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2008.133;10.1109/VISUAL.1992.235211;10.1109/TVCG.2009.190;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2000.885694;10.1109/TVCG.2008.163;10.1109/TVCG.2009.154",57
"10.1109/TVCG.2010.182","On the Fractal Dimension of Isosurfaces","Isosurfaces, scalar data, fractal dimension",2010,"A (3D) scalar grid is a regular n1 × n2 × n3 grid of vertices where each vertex v is associated with some scalar value sv. Applying trilinear interpolation, the scalar grid determines a scalar function g where g(v) = sv for each grid vertex v. An isosurface with isovalue σ is a triangular mesh which approximates the level set g-1 (σ). The fractal dimension of an isosurface represents the growth in the isosurface as the number of grid cubes increases. We define and discuss the fractal isosurface dimension. Plotting the fractal dimension as a function of the isovalues in a data set provides information about the isosurfaces determined by the data set. We present statistics on the average fractal dimension of 60 publicly available benchmark data sets. We also show the fractal dimension is highly correlated with topological noise in the benchmark data sets, measuring the topological noise by the number of connected components in the isosurface. Lastly, we present a formula predicting the fractal dimension as a function of noise and validate the formula with experimental results.","Marc Khoury;Rephael Wenger","http://dx.doi.org/10.1109/TVCG.2010.182","10.1109/TVCG.2006.168;10.1109/TVCG.2008.160;10.1109/VISUAL.2004.28;10.1109/VISUAL.1996.568103;10.1109/VISUAL.2001.964515;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1997.663875",58
"10.1109/TVCG.2010.187","Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation","Ray casting, pre-integration, Phong shading, volume rendering",2010,"Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.","Amel Guetat;Alexandre Ancel;Stéphane Marchesin;Jean-Michel Dischler","http://dx.doi.org/10.1109/TVCG.2010.187","10.1109/VISUAL.2000.885683;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1990.146391;10.1109/TVCG.2009.149",59
"10.1109/TVCG.2010.190","Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design","Visual exploration, visual effects, clustering, time-dependent volume data",2010,"Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.","Stefan Bruckner;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2010.190","10.1109/VISUAL.1992.235222;10.1109/VISUAL.1999.809871;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.164;10.1109/VISUAL.2003.1250402;10.1109/INFVIS.1998.729559;10.1109/TVCG.2009.200;10.1109/VAST.2007.4389013;10.1109/VISUAL.1993.398859;10.1109/TVCG.2009.153;10.1109/TVCG.2007.70581;10.1109/VAST.2006.261421",60
"10.1109/TVCG.2010.192","Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data","Earth Science Visualization, Multivariate Visualization, Seismic Data, Scalable Visualization",2010,"Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.","Xiaoru Yuan;He Xiao;Hanqi Guo;Peihong Guo;Wesley Kendall;Jian Huang;Yongxian Zhang","http://dx.doi.org/10.1109/TVCG.2010.192","10.1109/TVCG.2009.179;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1990.146402;10.1109/VISUAL.2002.1183814;10.1109/TVCG.2008.170;10.1109/TVCG.2008.184",61
"10.1109/TVCG.2010.198","Streak Lines as Tangent Curves of a Derived Vector field","Unsteady flow visualization, streak lines, streak surfaces, feature extraction",2010,"Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.","Tino Weinkauf;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2010.198","10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2009.154;10.1109/TVCG.2007.70554;10.1109/VISUAL.2004.99;10.1109/TVCG.2008.133;10.1109/TVCG.2009.190;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.163;10.1109/TVCG.2007.70551",62
"10.1109/TVCG.2010.199","Superquadric Glyphs for Symmetric Second-Order Tensors","Tensor Glyphs, Stress Tensors, Rate-of-Deformation Tensors, Geometry Tensors, Glyph Design",2010,"Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.","Thomas Schultz 0001;Gordon L. Kindlmann","http://dx.doi.org/10.1109/TVCG.2010.199","10.1109/VISUAL.1999.809905;10.1109/TVCG.2006.134;10.1109/VISUAL.1998.745294;10.1109/TVCG.2006.181;10.1109/VISUAL.1991.175773;10.1109/TVCG.2009.184;10.1109/TVCG.2006.182;10.1109/TVCG.2009.177;10.1109/TVCG.2010.166;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1997.663929;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2005.1532774;10.1109/VISUAL.2004.80;10.1109/TVCG.2006.115",63
"10.1109/TVCG.2010.207","Two-Phase Mapping for Projecting Massive Data Sets","Dimensionality Reduction,Projection Methods,Visual Data Mining,Streaming Technique",2010,"Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.","Fernando Vieira Paulovich;Cláudio T. Silva;Luis Gustavo Nonato","http://dx.doi.org/10.1109/TVCG.2010.207","10.1109/INFVIS.2002.1173159;10.1109/VISUAL.1996.567787;10.1109/TVCG.2008.138;10.1109/TVCG.2009.131;10.1109/INFVIS.2004.60;10.1109/TVCG.2007.70580;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173161",64
"10.1109/TVCG.2010.211","VDVR: Verifiable Volume Visualization of Projection-Based Data","Direct volume rendering, computed tomography, filtered back-projection, verifiable visualization ",2010,"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.","Ziyi Zheng;Wei Xu;Klaus Mueller","http://dx.doi.org/10.1109/TVCG.2010.211","10.1109/VISUAL.1999.809908;10.1109/VISUAL.1991.175805;10.1109/TVCG.2009.194;10.1109/TVCG.2006.141;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2004.70;10.1109/TVCG.2009.149",65
"10.1109/TVCG.2010.223","World Lines","Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",2010,"In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.","Jürgen Waser;Raphael Fuchs;Hrvoje Ribicic;Benjamin Schindler;Günter Blöschl;Eduard Gröller","http://dx.doi.org/10.1109/TVCG.2010.223","10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",66
"10.1109/TVCG.2011.160","A Study on Dual-Scale Data Charts","Focus+Context, Quantitative Experiment, Dual-Scale Charts",2011,"We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.","Petra Isenberg;Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2011.160","10.1109/INFVIS.1998.729558;10.1109/TVCG.2009.174;10.1109/TVCG.2007.70577",67
"10.1109/TVCG.2011.163","Adaptive Privacy-Preserving Visualization Using Parallel Coordinates","Parallel coordinates, privacy, clustering",2011,"Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.","Aritra Dasgupta;Robert Kosara","http://dx.doi.org/10.1109/TVCG.2011.163","10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2010.184;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170",68
"10.1109/TVCG.2011.166","Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data","Parallel Coordinates, Angular Histogram, Attribute Curves",2011,"Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.","Zhao Geng;Zhenmin Peng;Robert S. Laramee;Jonathan C. Roberts;Rick Walker","http://dx.doi.org/10.1109/TVCG.2011.166","10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559216;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.184;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.170;10.1109/TVCG.2008.131",69
"10.1109/TVCG.2011.169","Asymmetric Relations in Longitudinal Social Networks","Network visualization, Social networks, Time series data, visual knolwedge discovery and representation, glyph-based techniques",2011,"In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.","Ulrik Brandes;Bobo Nick","http://dx.doi.org/10.1109/TVCG.2011.169","10.1109/TVCG.2006.163;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.116;10.1109/TVCG.2006.122;10.1109/TVCG.2010.215",70
"10.1109/TVCG.2011.175","Benefitting InfoVis with Visual Difficulties","Desirable difficulites, cognitive efficiency, active processing, engagement, individual differences ",2011,"Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative ""chartjunk"" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.","Jessica Hullman;Eytan Adar;Priti Shah","http://dx.doi.org/10.1109/TVCG.2011.175","10.1109/INFVIS.1995.528688;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.177;10.1109/INFVIS.2001.963279;10.1109/TVCG.2009.111",71
"10.1109/TVCG.2011.176","BirdVis: Visualizing and Understanding Bird Populations","Ornithology, species distribution models, multiscale analysis, spatial data, temporal data",2011,"Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case s- udies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.","Nivan Ferreira;Lauro Didier Lins;Daniel Fink;Steve Kelling;Christopher Wood;Juliana Freire;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2011.176","10.1109/VISUAL.2001.964510;10.1109/VISUAL.1990.146361;10.1109/TVCG.2010.194;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70570;10.1109/TVCG.2008.153",72
"10.1109/TVCG.2011.178","Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data","Interactive visual analysis, High-dimensional data analysis",2011,"In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.","Cagatay Turkay;Peter Filzmoser;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2011.178","10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2009.199;10.1109/VISUAL.1995.485139;10.1109/VAST.2009.5332611;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/VAST.2009.5333431",73
"10.1109/TVCG.2011.179","CloudLines: Compact Display of Event Episodes in Multiple Time-Series","Incremental Visualization, Event-based Data, Lens Distortion",2011,"We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.","Milos Krstajic;Enrico Bertini;Daniel A. Keim","http://dx.doi.org/10.1109/TVCG.2011.179","10.1109/TVCG.2010.193;10.1109/VAST.2006.261431;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2007.70539",74
"10.1109/TVCG.2011.183","Context-Preserving Visual Links","Visual links, highlighting, connectedness, routing, image-based, saliency",2011,"Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.","Markus Steinberger;Manuela Waldner;Marc Streit;Alexander Lex;Dieter Schmalstieg","http://dx.doi.org/10.1109/TVCG.2011.183","10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521",75
"10.1109/TVCG.2011.185","D&#x0B3; Data-Driven Documents","Information visualization, user interfaces, toolkits, 2D graphics",2011,"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.","Michael Bostock;Vadim Ogievetsky;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2011.185","10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",76
"10.1109/TVCG.2011.186","Design Study of LineSets, a Novel Set Visualization Technique","Set visualization, clustering, faceted data visualization, graph visualization 

",2011,"Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.","Basak Alper;Nathalie Henry Riche;Gonzalo Ramos;Mary Czerwinski","http://dx.doi.org/10.1109/TVCG.2011.186","10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",77
"10.1109/TVCG.2011.187","Developing and Evaluating Quilts for the Depiction of Large Layered Graphs","Graph drawing, layered graphs, matrix based depiction, node-link diagram",2011,"Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).","Juhee Bae;Benjamin Watson","http://dx.doi.org/10.1109/TVCG.2011.187","10.1109/TVCG.2010.159;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70582",78
"10.1109/TVCG.2011.188","DICON: Interactive Visual Analysis of Multidimensional Clusters","Visual Analysis, Clustering, Information Visualization",2011,"Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.","Nan Cao;David Gotz;Jimeng Sun;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2011.188","10.1109/INFVIS.2005.1532128;10.1109/TVCG.2006.147;10.1109/TVCG.2009.179;10.1109/VISUAL.1995.485141;10.1109/TVCG.2007.70582;10.1109/VISUAL.1990.146402;10.1109/VAST.2009.5332628;10.1109/INFVIS.2001.963283;10.1109/INFVIS.1998.729559;10.1109/TVCG.2010.216;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.153;10.1109/TVCG.2008.165;10.1109/TVCG.2009.153",79
"10.1109/TVCG.2011.190","Divided Edge Bundling for Directional Network Data","Graph visualization, aggregation, node-link diagrams, edge bundling, physical simulation",2011,"The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten & van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.","David Selassie;Brandon Heller;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2011.190","10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70535;10.1109/TVCG.2006.147",80
"10.1109/TVCG.2011.191","Drawing Road Networks with Focus Regions","cartography, schematic maps, fish-eye view, graph drawing, optimization, quadratic programming",2011,"Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.","Jan-Henrik Haunert;Leon Sering","http://dx.doi.org/10.1109/TVCG.2011.191","10.1109/TVCG.2008.132;10.1109/INFVIS.2004.66",81
"10.1109/TVCG.2011.192","Evaluation of Artery Visualizations for Heart Disease Diagnosis","Quantitative evaluation, qualitative evaluation, biomedical and medical visualization",2011,"Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.","Michelle Borkin;Krzysztof Z. Gajos;Amanda Peters Randles;Dimitris Mitsouras;Simone Melchionna;Frank J. Rybicki;Charles L. Feldman;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2011.192","10.1109/TVCG.2009.169;10.1109/VISUAL.2002.1183788;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964510;10.1109/VISUAL.2004.104;10.1109/TVCG.2006.172;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.126;10.1109/VISUAL.2001.964538;10.1109/TVCG.2009.126;10.1109/VISUAL.1992.235201;10.1109/VISUAL.1996.568118;10.1109/VISUAL.2000.885731;10.1109/TVCG.2007.70550;10.1109/TVCG.2007.70596",82
"10.1109/TVCG.2011.195","Exploratory Analysis of Time-Series with ChronoLenses","Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques",2011,"Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.","Jian Zhao;Fanny Chevalier;Emmanuel Pietriga;Ravin Balakrishnan","http://dx.doi.org/10.1109/TVCG.2011.195","10.1109/TVCG.2010.162;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389007;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2007.70583;10.1109/TVCG.2010.193",83
"10.1109/TVCG.2011.196","Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback","Ambient visualization, informative art, casual infovis, sustainability, distributed visualization",2011,"Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.","Johnny Rodgers;Lyn Bartram","http://dx.doi.org/10.1109/TVCG.2011.196","10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031",84
"10.1109/TVCG.2011.197","Exploring Uncertainty in Geodemographics with Interactive Graphics","Geodemographics, OAC, classification, cartography, uncertainty",2011,"Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.","Aidan Slingsby;Jason Dykes;Jo Wood","http://dx.doi.org/10.1109/TVCG.2011.197","10.1109/INFVIS.1996.559216;10.1109/TVCG.2010.191;10.1109/TVCG.2007.70574;10.1109/TVCG.2010.186;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.165;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12",85
"10.1109/TVCG.2011.201","Flexible Linked Axes for Multivariate Data Visualization","Multivariate data, visualization, scatterplot, Parallel Coordinates Plot",2011,"Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.","Jarry H. T. Claessen;Jarke J. van Wijk","http://dx.doi.org/10.1109/TVCG.2011.201","10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2006.138;10.1109/TVCG.2010.205;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70521;10.1109/VISUAL.1991.175790;10.1109/TVCG.2008.153",86
"10.1109/TVCG.2011.202","Flow Map Layout via Spiral Trees","Flow maps, Automated Cartography, Spiral Trees",2011,"Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.","Kevin Buchin;Bettina Speckmann;Kevin Verbeek","http://dx.doi.org/10.1109/TVCG.2011.202","10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.1996.559226;10.1109/TVCG.2006.147",87
"10.1109/TVCG.2011.212","Improved Similarity Trees and their Application to Visual Data Classification","Similarity Trees, Multidimensional Projections, Image Classification",2011,"An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.","Jose Gustavo Paiva;Laura Florian;Hélio Pedrini;Guilherme P. Telles;Rosane Minghim","http://dx.doi.org/10.1109/TVCG.2011.212","10.1109/INFVIS.1999.801855;10.1109/TVCG.2009.140;10.1109/VAST.2007.4389002;10.1109/TVCG.2008.138;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173148",88
"10.1109/TVCG.2011.213","In Situ Exploration of Large Dynamic Networks","Dynamic graph data, multiform visualization, multi-focus+context",2011,"The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.","Steffen Hadlak;Hans-Jörg Schulz;Heidrun Schumann","http://dx.doi.org/10.1109/TVCG.2011.213","10.1109/TVCG.2009.151;10.1109/TVCG.2008.114;10.1109/INFVIS.2004.18;10.1109/TVCG.2007.70582;10.1109/INFVIS.2000.885087;10.1109/INFVIS.2004.66;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2002.1173160;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70529;10.1109/TVCG.2006.166",89
"10.1109/TVCG.2011.223","MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots","Semantic lenses, magic lenses, graph bundling, attribute filtering",2011,"We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.","Christophe Hurter;Alexandru Telea;Ozan Ersoy","http://dx.doi.org/10.1109/TVCG.2011.223","10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2004.66;10.1109/INFVIS.2003.1249008",90
"10.1109/TVCG.2011.226","Parallel Edge Splatting for Scalable Dynamic Graph Visualization","Dynamic graph visualization, graph splatting, software visualization, software evolution",2011,"We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.","Michael Burch;Corinna Vehlow;Fabian Beck;Stephan Diehl 0001;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2011.226","10.1109/TVCG.2009.123;10.1109/TVCG.2008.131;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.176;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2009.131;10.1109/INFVIS.1999.801866;10.1109/INFVIS.2002.1173160;10.1109/INFVIS.2004.68",91
"10.1109/TVCG.2011.227","Product Plots","Statistics, joint distribution, conditional distribution, treemap, bar chart, mosaic plot",2011,"We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.","Hadley Wickham;Heike Hofmann","http://dx.doi.org/10.1109/TVCG.2011.227","10.1109/TVCG.2007.70594;10.1109/TVCG.2006.200;10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1990.146386;10.1109/TVCG.2010.186;10.1109/INFVIS.2005.1532128;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.209;10.1109/TVCG.2009.128;10.1109/INFVIS.2005.1532145",92
"10.1109/TVCG.2011.229","Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization","Quality Metrics, High-Dimensional Data Visualization",2011,"In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.","Enrico Bertini","http://dx.doi.org/10.1109/TVCG.2011.229","10.1109/INFVIS.2005.1532145;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249006;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.138;10.1109/INFVIS.2004.59;10.1109/VAST.2009.5332628;10.1109/INFVIS.2003.1249015;10.1109/VAST.2010.5652450;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153;10.1109/INFVIS.1997.636794",93
"10.1109/TVCG.2011.232","Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization","Bioinformatics Visualization, Perception Theory, Scalability Issues, Visual Design",2011,"In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.","Danielle Albers Szafir;Colin N. Dewey;Michael Gleicher","http://dx.doi.org/10.1109/TVCG.2011.232","10.1109/TVCG.2007.70623;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2009.128;10.1109/TVCG.2009.167",94
"10.1109/TVCG.2011.233","Skeleton-Based Edge Bundling for Graph Visualization","Graph layouts, edge bundles, image-based information visualization",2011,"In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.","Ozan Ersoy;Christophe Hurter;Fernando Vieira Paulovich;Gabriel Cantareiro;Alexandru Telea","http://dx.doi.org/10.1109/TVCG.2011.233","10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/TVCG.2006.120;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030",95
"10.1109/TVCG.2011.237","Synthetic Generation of High-Dimensional Datasets","Synthetic data generation, multivariate data, high-dimensional data, interaction",2011,"Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.","Georgia Albuquerque;Thomas Löwe;Marcus A. Magnor","http://dx.doi.org/10.1109/TVCG.2011.237","10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1994.346302;10.1109/VAST.2010.5652433;10.1109/VAST.2009.5332628;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153",96
"10.1109/TVCG.2011.239","TextFlow: Towards Better Understanding of Evolving Topics in Text","Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event",2011,"Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.","Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong","http://dx.doi.org/10.1109/TVCG.2011.239","10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333443;10.1109/TVCG.2006.156;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2010.129;10.1109/VAST.2008.4677364;10.1109/INFVIS.2005.1532122;10.1109/VAST.2009.5333437;10.1109/INFVIS.2005.1532152",97
"10.1109/TVCG.2011.247","TreeNetViz: Revealing Patterns of Networks over Tree Structures","Compound graph, network and tree, TreeNetViz, visualization, multiscale and cross-scale",2011,"Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.","Liang Gou;Xiaolong Zhang","http://dx.doi.org/10.1109/TVCG.2011.247","10.1109/INFVIS.2004.1;10.1109/INFVIS.2003.1249011;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2002.1173151;10.1109/TVCG.2009.167;10.1109/TVCG.2006.192;10.1109/TVCG.2008.135;10.1109/TVCG.2006.120;10.1109/INFVIS.2000.885091;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521;10.1109/TVCG.2006.147",98
"10.1109/TVCG.2011.250","VisBricks: Multiform Visualization of Large, Inhomogeneous Data","Inhomogeneous data, multiple coordinated views, multiform visualization",2011,"Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.","Alexander Lex;Hans-Jörg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg","http://dx.doi.org/10.1109/TVCG.2011.250","10.1109/INFVIS.2005.1532129;10.1109/TVCG.2010.138;10.1109/TVCG.2006.120;10.1109/TVCG.2007.70582;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2006.147;10.1109/TVCG.2009.167;10.1109/TVCG.2010.216;10.1109/TVCG.2006.166",99
"10.1109/TVCG.2011.251","Visual Thinking In Action: Visualizations As Used On Whiteboards","Visualization, diagrams, whiteboards, observational study",2011,"While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.","Jagoda Walny;M. Sheelagh T. Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett","http://dx.doi.org/10.1109/TVCG.2011.251","10.1109/TVCG.2010.144;10.1109/TVCG.2010.179;10.1109/TVCG.2006.156;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.155;10.1109/INFVIS.2004.10;10.1109/INFVIS.2002.1173148;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.164",100
"10.1109/TVCG.2011.253","Visualization of Parameter Space for Image Analysis","Information visualization, visual analytics, parameter space, image analysis, sampling",2011,"Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.","A. Johannes Pretorius;Mark-Anthony Bray;Anne E. Carpenter;Roy A. Ruddle","http://dx.doi.org/10.1109/TVCG.2011.253","10.1109/INFVIS.2004.70;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1999.809871;10.1109/VISUAL.2000.885678;10.1109/INFVIS.2001.963290",101
"10.1109/TVCG.2011.255","Visualization Rhetoric: Framing Effects in Narrative Visualization","Rhetoric, narrative visualization, framing effects, semiotics, denotation, connotation ",2011,"Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that ""tell a story"" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.","Jessica Hullman;Nicholas Diakopoulos","http://dx.doi.org/10.1109/TVCG.2011.255","10.1109/TVCG.2010.179;10.1109/TVCG.2007.70577;10.1109/TVCG.2010.177;10.1109/TVCG.2009.111",102
"10.1109/VAST.2011.6102435","Visual analytic roadblocks for novice investigators","Visual analytics, investigative analysis, cognitive 
model, framework, roadblock, qualitative experiment 

",2011,"We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users' perspectives is still limited. Therefore, we attempted to identify such â€œvisual analytic roadblocksâ€ for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.","Bum Chul Kwon;Brian D. Fisher;Ji Soo Yi","http://dx.doi.org/10.1109/VAST.2011.6102435","10.1109/INFVIS.2004.10;10.1109/VAST.2007.4389006;10.1109/TVCG.2010.164;10.1109/VAST.2009.5333878;10.1109/TVCG.2010.179;10.1109/TVCG.2008.121;10.1109/INFVIS.2004.5;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.177;10.1109/VAST.2006.261416;10.1109/TVCG.2008.171;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70535;10.1109/VAST.2008.4677361;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70594",103
"10.1109/VAST.2011.6102437","Perception-based visual quality measures","",2011,"In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.","Georgia Albuquerque;Martin Eisemann;Marcus A. Magnor","http://dx.doi.org/10.1109/VAST.2011.6102437","10.1109/INFVIS.2005.1532142;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153",104
"10.1109/VAST.2011.6102438","Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study"," Intelligence analysis, qualitatvie user study ",2011,"While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community's understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis.","Youn ah Kang;John T. Stasko","http://dx.doi.org/10.1109/VAST.2011.6102438","10.1109/VAST.2008.4677362;10.1109/VISUAL.1992.235203;10.1109/VAST.2008.4677358;10.1109/TVCG.2009.111;10.1109/VAST.2007.4389006",105
"10.1109/VAST.2011.6102440","Network-based visual analysis of tabular data","",2011,"Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience.","Zhicheng Liu;Shamkant B. Navathe;John T. Stasko","http://dx.doi.org/10.1109/VAST.2011.6102440","10.1109/TVCG.2006.122;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520;10.1109/INFVIS.2000.885086;10.1109/VAST.2007.4389006",106
"10.1109/VAST.2011.6102441","Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks","Social network analysis, data management, data transformation, graphs, visualization, end-user programming
",2011,"The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.","Jeffrey Heer;Adam Perer","http://dx.doi.org/10.1109/VAST.2011.6102441","10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.166;10.1109/VAST.2006.261426;10.1109/INFVIS.2000.885086",107
"10.1109/VAST.2011.6102442","G-PARE: A visual analytic tool for comparative analysis of uncertain graphs","Uncertain Graphs, Comparative Analysis, Model Comparison, Visualizing Uncertainty",2011,"There are a growing number of machine learning algorithms which operate on graphs. Example applications for these algorithms include predicting which customers will recommend products to their friends in a viral marketing campaign using a customer network, predicting the topics of publications in a citation network, or predicting the political affiliations of people in a social network. It is important for an analyst to have tools to help compare the output of these machine learning algorithms. In this work, we present G-PARE, a visual analytic tool for comparing two uncertain graphs, where each uncertain graph is produced by a machine learning algorithm which outputs probabilities over node labels. G-PARE provides several different views which allow users to obtain a global overview of the algorithms output, as well as focused views that show subsets of nodes of interest. By providing an adaptive exploration environment, G-PARE guides the users to places in the graph where two algorithms predictions agree and places where they disagree. This enables the user to follow cascades of misclassifications by comparing the algorithms outcome with the ground truth. After describing the features of G-PARE, we illustrate its utility through several use cases based on networks from different domains.","Hossam Sharara;Awalin Sopan;Galileo Namata;Lise Getoor;Lisa Singh","http://dx.doi.org/10.1109/VAST.2011.6102442","10.1109/TVCG.2006.122;10.1109/VAST.2010.5652398;10.1109/VAST.2010.5652910;10.1109/VAST.2006.261429;10.1109/VAST.2010.5652443;10.1109/TVCG.2007.70582",108
"10.1109/VAST.2011.6102443","Visual social network analytics for relationship discovery in the enterprise"," information discovery, social networks, social data mining, social visualization",2011,"As people continue to author and share increasing amounts of information in social media, the opportunity to leverage such information for relationship discovery tasks increases. In this paper, we describe a set of systems that mine, aggregate, and infer a social graph from social media inside an enterprise, resulting in over 73 million relationships between 450,000 people. We then describe SaNDVis, a novel visual analytics tool that supports people-centric tasks like expertise location, team building, and team coordination in the enterprise. We also provide details of a 12-month-long, large-scale deployment to almost 1,800 users from which we extract dominant use cases from log and interview data. By integrating social position, evidence, and facets into SaNDVis, we demonstrate how users can use a visual analytics tool to reflect on existing relationships as well as build new relationships in an enterprise setting.","Adam Perer;Ido Guy;Erel Uziel;Inbal Ronen;Michal Jacovi","http://dx.doi.org/10.1109/VAST.2011.6102443","10.1109/TVCG.2006.122;10.1109/TVCG.2007.70582;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2006.166",109
"10.1109/VAST.2011.6102446","Obvious: A meta-toolkit to encapsulate information visualization toolkits - One toolkit to bind them all","",2011,"This article describes â€œObviousâ€: a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics.","Jean-Daniel Fekete;Pierre-Luc Hemery;Thomas Baudel;Jo Wood","http://dx.doi.org/10.1109/VAST.2011.6102446","10.1109/INFVIS.2004.12;10.1109/TVCG.2009.152;10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/TVCG.2010.159;10.1109/INFVIS.2004.64;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2002.1173148",110
"10.1109/VAST.2011.6102447","Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics","Visual analytics, asynchronous collaboration, insight, multidimensional visualization",2011,"Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness.","Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang 0001;Ye Zhao","http://dx.doi.org/10.1109/VAST.2011.6102447","10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333023;10.1109/TVCG.2007.70577;10.1109/VAST.2010.5652879;10.1109/VAST.2008.4677358;10.1109/VAST.2010.5652932;10.1109/VAST.2007.4389011;10.1109/VAST.2008.4677365;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652885",111
"10.1109/VAST.2011.6102448","Guiding feature subset selection with an interactive visualization","",2011,"We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.","Thorsten May;Andreas Bannach;James Davey;Tobias Ruppert;Jörn Kohlhammer","http://dx.doi.org/10.1109/VAST.2011.6102448","10.1109/VAST.2010.5652392;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153",112
"10.1109/VAST.2011.6102451","Interactive decision making using dissimilarity to visually represented prototypes","dissimilarity based classication, dissimilarity based
visualization, prototypes, interactive visualization, visual analytics",2011,"To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.","Malgorzata Migut;Jan C. van Gemert;Marcel Worring","http://dx.doi.org/10.1109/VAST.2011.6102451","10.1109/TVCG.2007.70515;10.1109/TVCG.2009.174;10.1109/TVCG.2009.199;10.1109/VAST.2010.5652398;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885086",113
"10.1109/VAST.2011.6102453","BaobabView: Interactive construction and analysis of decision trees","",2011,"We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data.","Stef van den Elzen;Jarke J. van Wijk","http://dx.doi.org/10.1109/VAST.2011.6102453","10.1109/TVCG.2008.166;10.1109/INFVIS.2001.963292;10.1109/INFVIS.2001.963290",114
"10.1109/VAST.2011.6102455","Visual analysis of route diversity","",2011,"Route suggestion is an important feature of GPS navigation systems. Recently, Microsoft T-drive has been enabled to suggest routes chosen by experienced taxi drivers for given source/destination pairs in given time periods, which often take less time than the routes calculated according to distance. However, in real environments, taxi drivers may use different routes to reach the same destination, which we call route diversity. In this paper we first propose a trajectory visualization method that examines the regions where the diversity exists and then develop several novel visualization techniques to display the high dimensional attributes and statistics associated with different routes to help users analyze diversity patterns. Our techniques have been applied to the real trajectory data of thousands of taxis and some interesting findings about route diversity have been obtained. We further demonstrate that our system can be used not only to suggest better routes for drivers but also to analyze traffic bottlenecks for transportation management.","He Liu;Yuan Gao;Lu Lu;Siyuan Liu;Huamin Qu;Lionel M. Ni","http://dx.doi.org/10.1109/VAST.2011.6102455","10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2008.149;10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70574;10.1109/TVCG.2006.202;10.1109/VAST.2009.5332593;10.1109/TVCG.2007.70561;10.1109/TVCG.2009.145;10.1109/TVCG.2010.180",115
"10.1109/VAST.2011.6102457","Visual analytics decision support environment for epidemic modeling and response evaluation","",2011,"In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time.","Shehzad Afzal;Ross Maciejewski;David S. Ebert","http://dx.doi.org/10.1109/VAST.2011.6102457","10.1109/TVCG.2008.137;10.1109/TVCG.2007.70594;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5333020;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/TVCG.2010.206;10.1109/TVCG.2009.187;10.1109/TVCG.2010.171;10.1109/VAST.2006.261450;10.1109/INFVIS.2000.885086",116
"10.1109/VAST.2011.6102458","SAVE: Sensor anomaly visualization engine","",2011,"Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.","Lei Shi;Qi Liao;Yuan He;Rui Li;Aaron Striegel;Zhong Su","http://dx.doi.org/10.1109/VAST.2011.6102458","10.1109/TVCG.2009.182;10.1109/VAST.2009.5333880;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.1;10.1109/VAST.2010.5652910",117
"10.1109/VAST.2011.6102460","A visual analytics process for maritime resource allocation and risk assessment","Visual analytics, risk assessment, Coast Guard",2011,"In this paper, we present our collaborative work with the U.S. Coast Guard's Ninth District and Atlantic Area Commands where we developed a visual analytics system to analyze historic response operations and assess the potential risks in the maritime environment associated with the hypothetical allocation of Coast Guard resources. The system includes linked views and interactive displays that enable the analysis of trends, patterns and anomalies among the U.S. Coast Guard search and rescue (SAR) operations and their associated sorties. Our system allows users to determine the potential change in risks associated with closing certain stations in terms of response time, potential lives and property lost and provides optimal direction as to the nearest available station. We provide maritime risk assessment tools that allow analysts to explore Coast Guard coverage for SAR operations and identify regions of high risk. The system also enables a thorough assessment of all SAR operations conducted by each Coast Guard station in the Great Lakes region. Our system demonstrates the effectiveness of visual analytics in analyzing risk within the maritime domain and is currently being used by analysts at the Coast Guard Atlantic Area.","Abish Malik;Ross Maciejewski;Ben Maule;David S. Ebert","http://dx.doi.org/10.1109/VAST.2011.6102460","10.1109/VISUAL.1993.398870;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5333920;10.1109/VAST.2008.4677363;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5332611",118
"10.1109/VAST.2011.6102461","ParallelTopics: A probabilistic approach to exploring document collections","",2011,"Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.","Wenwen Dou;Xiaoyu Wang;Remco Chang;William Ribarsky","http://dx.doi.org/10.1109/VAST.2011.6102461","10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333428;10.1109/TVCG.2010.184;10.1109/VAST.2010.5652940;10.1109/TVCG.2009.140;10.1109/INFVIS.2000.885098",119
"10.1109/VAST.2011.6102462","Analysis of large digital collections with interactive visualization","Digital collections, archival analysis, visual anaytics, data curation",2011,"To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections' contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions.","Weijia Xu;Maria Esteva;Suyog Dott Jain;Varun Jain","http://dx.doi.org/10.1109/VAST.2011.6102462","10.1109/INFVIS.2000.885091;10.1109/TVCG.2008.172;10.1109/TVCG.2009.176;10.1109/VAST.2007.4389006;10.1109/INFVIS.2004.64;10.1109/VAST.2010.5652931;10.1109/INFVIS.1999.801860",120
"10.1109/VAST.2011.6102463","A two-stage framework for designing visual analytics system in organizational environments","Design Theory, Visual Analytics, HCI",2011,"A perennially interesting research topic in the field of visual analytics is how to effectively develop systems that support organizational users' decision-making and reasoning processes. The problem is, however, most domain analytical practices generally vary from organization to organization. This leads to diverse designs of visual analytics systems in incorporating domain analytical processes, making it difficult to generalize the success from one domain to another. Exacerbating this problem is the dearth of general models of analytical workflows available to enable such timely and effective designs. To alleviate these problems, we present a two-stage framework for informing the design of a visual analytics system. This design framework builds upon and extends current practices pertaining to analytical workflow and focuses, in particular, on incorporating both general domain analysis processes as well as individual's analytical activities. We illustrate both stages and their design components through examples, and hope this framework will be useful for designing future visual analytics systems. We validate the soundness of our framework with two visual analytics systems, namely Entity Workspace [8] and PatViz [37].","Xiaoyu Wang;Wenwen Dou;Thomas Butkiewicz;Eric A. Bier;William Ribarsky","http://dx.doi.org/10.1109/VAST.2011.6102463","10.1109/VAST.2008.4677362;10.1109/VAST.2009.5333020;10.1109/TVCG.2008.137;10.1109/VAST.2006.261416;10.1109/VAST.2007.4389009;10.1109/TVCG.2009.139;10.1109/VAST.2008.4677361;10.1109/TVCG.2009.111;10.1109/VISUAL.2005.1532781;10.1109/VAST.2008.4677352;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70515;10.1109/VAST.2008.4677360;10.1109/VAST.2008.4677365;10.1109/VAST.2009.5333564",121
"10.1109/TVCG.2011.162","Adaptive Extraction and Quantification of Geophysical Vortices","Vortex extraction, feature extraction, statistical data analysis",2011,"We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.","Sean Williams;Mark Petersen;Peer-Timo Bremer;Matthew Hecht;Valerio Pascucci;James P. Ahrens;Mario Hlawitschka;Bernd Hamann","http://dx.doi.org/10.1109/TVCG.2011.162","10.1109/VISUAL.1994.346327;10.1109/TVCG.2008.143;10.1109/VISUAL.1993.398877",122
"10.1109/TVCG.2011.170","Asymmetric Tensor field Visualization for Surfaces","Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",2011,"Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.","Darrel Palke;Zhongzang Lin;Guoning Chen;Harry Yeh;Paul Vincent;Robert S. Laramee;Eugene Zhang","http://dx.doi.org/10.1109/TVCG.2011.170","10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",123
"10.1109/TVCG.2011.173","Automatic Transfer Functions Based on Informational Divergence","Transfer function, Information theory, Informational divergence, Kullback-Leibler distance",2011,"In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.","Marc Ruiz;Anton Bardera;Imma Boada;Ivan Viola","http://dx.doi.org/10.1109/TVCG.2011.173","10.1109/TVCG.2010.132;10.1109/TVCG.2006.137;10.1109/TVCG.2006.159;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70576;10.1109/TVCG.2009.120;10.1109/VISUAL.1996.568113;10.1109/TVCG.2008.140;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2002.1183785;10.1109/TVCG.2006.148",124
"10.1109/TVCG.2011.194","Evaluation of Trend Localization with Multi-Variate Visualizations","User study, multi-variate visualization, visual task design, visual analytics",2011,"Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn't require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.","Mark A. Livingston;Jonathan W. Decker","http://dx.doi.org/10.1109/TVCG.2011.194","10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70623;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362",125
"10.1109/TVCG.2011.198","Extinction-Based Shading and Illumination in GPU Volume Ray-Casting","Volume Rendering, Shadows, Ambient Occlusion, GPU Ray-Casting, Exponential Extinction",2011,"Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.","Philipp Schlegel;Maxim Makhinya;Renato Pajarola","http://dx.doi.org/10.1109/TVCG.2011.198","10.1109/TVCG.2007.70555;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2003.1250384",126
"10.1109/TVCG.2011.199","Feature-Based Statistical Analysis of Combustion Simulation Data","Topology, Statistics, Data analysis, Data exploration, Visualization in Physical Sciences and Engineering, Multi-variate Data",2011,"We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.","Janine Bennett;Vaidyanathan Krishnamoorthy;Shusen Liu;Ray W. Grout;Evatt R. Hawkes;Jacqueline Chen;Jason F. Shepherd;Valerio Pascucci;Peer-Timo Bremer","http://dx.doi.org/10.1109/TVCG.2011.199","10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250386;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/VISUAL.1997.663875",127
"10.1109/TVCG.2011.200","Features in Continuous Parallel Coordinates","Features, Parallel Coordinates, Topology, Visualization",2011,"Continuous Parallel Coordinates (CPC) are a contemporary visualization technique in order to combine several scalar fields, given over a common domain. They facilitate a continuous view for parallel coordinates by considering a smooth scalar field instead of a finite number of straight lines. We show that there are feature curves in CPC which appear to be the dominant structures of a CPC. We present methods to extract and classify them and demonstrate their usefulness to enhance the visualization of CPCs. In particular, we show that these feature curves are related to discontinuities in Continuous Scatterplots (CSP). We show this by exploiting a curve-curve duality between parallel and Cartesian coordinates, which is a generalization of the well-known point-line duality. Furthermore, we illustrate the theoretical considerations. Concluding, we discuss relations and aspects of the CPC's/CSP's features concerning the data analysis.","Dirk J. Lehmann;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2011.200","10.1109/TVCG.2008.119;10.1109/TVCG.2010.146;10.1109/VISUAL.1998.745284;10.1109/TVCG.2009.131;10.1109/VISUAL.1999.809896",128
"10.1109/TVCG.2011.203","Flow Radar Glyphs&amp;#8212;Static Visualization of Unsteady Flow with Uncertainty","Visualization, glyph, uncertainty, unsteady flow",2011,"A new type of glyph is introduced to visualize unsteady flow with static images, allowing easier analysis of time-dependent phenomena compared to animated visualization. Adopting the visual metaphor of radar displays, this glyph represents flow directions by angles and time by radius in spherical coordinates. Dense seeding of flow radar glyphs on the flow domain naturally lends itself to multi-scale visualization: zoomed-out views show aggregated overviews, zooming-in enables detailed analysis of spatial and temporal characteristics. Uncertainty visualization is supported by extending the glyph to display possible ranges of flow directions. The paper focuses on 2D flow, but includes a discussion of 3D flow as well. Examples from CFD and the field of stochastic hydrogeology show that it is easy to discriminate regions of different spatiotemporal flow behavior and regions of different uncertainty variations in space and time. The examples also demonstrate that parameter studies can be analyzed because the glyph design facilitates comparative visualization. Finally, different variants of interactive GPU-accelerated implementations are discussed.","Marcel Hlawatsch;Philipp C. Leube;Wolfgang Nowak;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2011.203","10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1993.398849;10.1109/INFVIS.2001.963273;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1996.568139;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.1991.175792;10.1109/VISUAL.1995.480819;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.182",129
"10.1109/TVCG.2011.207","GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation","Radiofrequency ablation, ablation zone visualization, distance field, volume rendering, GPU, interaction",2011,"Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.","Christian Rieder;Tim Kröger;Christian Schumann;Horst K. Hahn","http://dx.doi.org/10.1109/TVCG.2011.207","10.1109/TVCG.2010.208;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2000.885694",130
"10.1109/TVCG.2011.208","Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization","Multimedia visualization, Time series data, Illustrative visualization",2011,"Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.","Matthew L. Parry;Philip A. Legg;David H. S. Chung;Iwan W. Griffiths;Min Chen","http://dx.doi.org/10.1109/TVCG.2011.208","10.1109/TVCG.2008.185;10.1109/INFVIS.2004.27;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2007.70544;10.1109/TVCG.2006.194",131
"10.1109/TVCG.2011.211","Image Plane Sweep Volume Illumination","Interactive volume rendering, GPU-based ray-casting, Advanced illumination",2011,"In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.","Erik Sundén;Anders Ynnerman;Timo Ropinski","http://dx.doi.org/10.1109/TVCG.2011.211","10.1109/TVCG.2011.161;10.1109/VISUAL.2002.1183761;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2002.1183764;10.1109/TVCG.2007.70573;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.164",132
"10.1109/TVCG.2011.215","Interactive Virtual Probing of 4D MRI Blood-Flow","Probing, Flow visualization, Illustrative visualization, Multivalued images, Phase-contrast cine MRI",2011,"Better understanding of hemodynamics conceivably leads to improved diagnosis and prognosis of cardiovascular diseases. Therefore, an elaborate analysis of the blood-flow in heart and thoracic arteries is essential. Contemporary MRI techniques enable acquisition of quantitative time-resolved flow information, resulting in 4D velocity fields that capture the blood-flow behavior. Visual exploration of these fields provides comprehensive insight into the unsteady blood-flow behavior, and precedes a quantitative analysis of additional blood-flow parameters. The complete inspection requires accurate segmentation of anatomical structures, encompassing a time-consuming and hard-to-automate process, especially for malformed morphologies. We present a way to avoid the laborious segmentation process in case of qualitative inspection, by introducing an interactive virtual probe. This probe is positioned semi-automatically within the blood-flow field, and serves as a navigational object for visual exploration. The difficult task of determining position and orientation along the view-direction is automated by a fitting approach, aligning the probe with the orientations of the velocity field. The aligned probe provides an interactive seeding basis for various flow visualization approaches. We demonstrate illustration-inspired particles, integral lines and integral surfaces, conveying distinct characteristics of the unsteady blood-flow. Lastly, we present the results of an evaluation with domain experts, valuing the practical use of our probe and flow visualization techniques.","Roy van Pelt;Javier Oliván Bescós;Marcel Breeuwer;Rachel E. Clough;Eduard Gröller;Bart M. ter Haar Romeny;Anna Vilanova","http://dx.doi.org/10.1109/TVCG.2011.215","10.1109/VISUAL.1993.398849;10.1109/TVCG.2009.154;10.1109/TVCG.2010.173;10.1109/TVCG.2010.153;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.133;10.1109/TVCG.2009.138;10.1109/VISUAL.2005.1532847;10.1109/TVCG.2010.166;10.1109/VISUAL.2005.1532857",133
"10.1109/TVCG.2011.217","Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics","Visual Analytics, Fluorescence Microscopy, Toponomics, Protein Interaction, Graph Visualization",2011,"In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.","Steffen Oeltze-Jafra;Wolfgang Freiler","http://dx.doi.org/10.1109/TVCG.2011.217","10.1109/VAST.2009.5333911;10.1109/TVCG.2006.195;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70569;10.1109/TVCG.2009.167",134
"10.1109/TVCG.2011.218","iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization","Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization",2011,"The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.","Ziyi Zheng;Nafees Ahmed;Klaus Mueller","http://dx.doi.org/10.1109/TVCG.2011.218","10.1109/TVCG.2009.156;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.162;10.1109/TVCG.2008.159;10.1109/TVCG.2010.214;10.1109/TVCG.2009.172;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.124;10.1109/TVCG.2009.185;10.1109/TVCG.2009.189;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2005.1532834",135
"10.1109/TVCG.2011.225","Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations","Emergency/Disaster Management, Visual Knowledge Discovery, Visualization System and Toolkit Design, Data-Flow, Meta-Flow, Parameter Study, Uncertainty, Visualization of Control",2011,"Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.","Jürgen Waser;Hrvoje Ribicic;Raphael Fuchs;Christian Hirsch;Benjamin Schindler;Günter Blöschl;Eduard Gröller","http://dx.doi.org/10.1109/TVCG.2011.225","10.1109/TVCG.2010.223;10.1109/TVCG.2007.70584;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2010.214;10.1109/INFVIS.2004.12;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2009.195;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2010.190;10.1109/TVCG.2010.223",136
"10.1109/TVCG.2011.230","Quasi Interpolation With Voronoi Splines","Voronoi Spline, Quasi Interpolation, Volume Visualization, Box spline",2011,"We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.","Mahsa Mirzargar;Alireza Entezari","http://dx.doi.org/10.1109/TVCG.2011.230","10.1109/TVCG.2008.115;10.1109/VISUAL.2004.65;10.1109/TVCG.2007.70573;10.1109/VISUAL.2001.964498;10.1109/VISUAL.2005.1532810;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1994.346331",137
"10.1109/TVCG.2011.248","Tuner: Principled Parameter finding for Image Segmentation Algorithms Using Visual Response Surface Exploration","Parameter exploration, Image segmentation, Gaussian Process Model",2011,"In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the ""goodness"" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.","Thomas Torsney-Weir;Ahmed Saad;Torsten Möller;Hans-Christian Hege;Britta Weber;Jean-Marc Verbavatz","http://dx.doi.org/10.1109/TVCG.2011.248","10.1109/TVCG.2007.70584;10.1109/TVCG.2008.119;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/VISUAL.1994.346302;10.1109/TVCG.2010.130;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809871;10.1109/TVCG.2011.253;10.1109/VISUAL.2000.885678",138
"10.1109/TVCG.2011.252","Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation","Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",2011,"We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates ""stitching cells"" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.","Patrick J. Moran;David Ellsworth","http://dx.doi.org/10.1109/TVCG.2011.252","10.1109/VISUAL.1991.175782;10.1109/TVCG.2009.149;10.1109/VISUAL.2002.1183820",139
"10.1109/TVCG.2011.254","Visualization of Topological Structures in Area-Preserving Maps","Poincare map, dynamical systems, topology, chaos, area-preserving maps, invariant manifolds",2011,"Area-preserving maps are found across a wide range of scientific and engineering problems. Their study is made challenging by the significant computational effort typically required for their inspection but more fundamentally by the fractal complexity of salient structures. The visual inspection of these maps reveals a remarkable topological picture consisting of fixed (or periodic) points embedded in so-called island chains, invariant manifolds, and regions of ergodic behavior. This paper is concerned with the effective visualization and precise topological analysis of area-preserving maps with two degrees of freedom from numerical or analytical data. Specifically, a method is presented for the automatic extraction and characterization of fixed points and the computation of their invariant manifolds, also known as separatrices, to yield a complete picture of the structures present within the scale and complexity bounds selected by the user. This general approach offers a significant improvement over the visual representations that are so far available for area-preserving maps. The technique is demonstrated on a numerical simulation of magnetic confinement in a fusion reactor.","Xavier Tricoche;Christoph Garth;Allen R. Sanderson","http://dx.doi.org/10.1109/TVCG.2011.254","10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2004.107;10.1109/VISUAL.2000.885716;10.1109/TVCG.2007.70601;10.1109/TVCG.2010.133;10.1109/VISUAL.2005.1532770;10.1109/VISUAL.2002.1183786;10.1109/VISUAL.1994.346326",140
"10.1109/TVCG.2011.261","WYSIWYG (What You See is What You Get) Volume Visualization","Volume rendering, Sketching input, Human-computer interaction, Transfer functions, Feature space",2011,"In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.","Hanqi Guo;Ningyu Mao;Xiaoru Yuan","http://dx.doi.org/10.1109/TVCG.2011.261","10.1109/TVCG.2010.145;10.1109/VISUAL.1998.745319;10.1109/TVCG.2008.120;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.1996.568113;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.1997.663875;10.1109/TVCG.2006.148",141
"10.1109/TVCG.2012.189","A User Study on Curved Edges in Graph Visualization","Graph, visualization, curved edges, evaluation",2012,"Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.","Kai Xu 0003;Chris Rooney;Peter J. Passmore;Dong-Han Ham;Phong H. Nguyen","http://dx.doi.org/10.1109/TVCG.2012.189","10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166",142
"10.1109/TVCG.2012.199","Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing","Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing",2012,"People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.","Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2012.199","10.1109/TVCG.2010.210;10.1109/TVCG.2009.122",143
"10.1109/TVCG.2012.204","Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions","Design considerations, interaction, post-WIMP, NUI (Natural User Interface)",2012,"The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more â€œnaturalâ€ interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more â€œnatural,â€ interaction techniques for InfoVis.","Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2012.204","10.1109/TVCG.2010.164;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121;10.1109/TVCG.2009.162;10.1109/TVCG.2010.206;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70568",144
"10.1109/TVCG.2012.205","Capturing the Design Space of Sequential Space-filling Layouts","Layout, visualization models, tables & tree layouts, grids, treemaps, mosaic plots, dimensional stacking",2012,"We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.","Thomas Baudel;Bertjan Broeksema","http://dx.doi.org/10.1109/TVCG.2012.205","10.1109/VISUAL.1991.175815;10.1109/TVCG.2006.178;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.200;10.1109/TVCG.2011.227;10.1109/INFVIS.1998.729560;10.1109/TVCG.2010.186;10.1109/TVCG.2008.165;10.1109/TVCG.2009.128",145
"10.1109/TVCG.2012.208","Compressed Adjacency Matrices: Untangling Gene Regulatory Networks","Network, gene regulation, scale-free, adjacency matrix",2012,"We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.","Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk","http://dx.doi.org/10.1109/TVCG.2012.208","10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030",146
"10.1109/TVCG.2012.212","Design Considerations for Optimizing Storyline Visualizations","Layout algorithm, timeline visualization, storyline visualization, design study",2012,"Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's â€œMovie Narrative Chartsâ€ [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.","Yuzuru Tanahashi;Kwan-Liu Ma","http://dx.doi.org/10.1109/TVCG.2012.212","10.1109/TVCG.2008.166;10.1109/TVCG.2008.135;10.1109/TVCG.2011.190;10.1109/TVCG.2011.239;10.1109/TVCG.2006.193;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.125;10.1109/INFVIS.2002.1173160",147
"10.1109/TVCG.2012.213","Design Study Methodology: Reflections from the Trenches and the Stacks","Design study, methodology, visualization, framework",2012,"Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.","Michael Sedlmair;Miriah D. Meyer;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2012.213","10.1109/INFVIS.1999.801869;10.1109/INFVIS.1996.559226;10.1109/TVCG.2008.117;10.1109/TVCG.2009.152;10.1109/TVCG.2010.206;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.193;10.1109/VAST.2011.6102443;10.1109/TVCG.2011.174;10.1109/VAST.2007.4389008;10.1109/TVCG.2009.116;10.1109/TVCG.2011.192;10.1109/TVCG.2009.128;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.167;10.1109/TVCG.2009.111;10.1109/TVCG.2011.209",148
"10.1109/TVCG.2012.215","Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making","Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision",2012,"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.","Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi","http://dx.doi.org/10.1109/TVCG.2012.215","10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.193;10.1109/VAST.2008.4677363;10.1109/TVCG.2010.149;10.1109/TVCG.2011.183;10.1109/VAST.2009.5333920",149
"10.1109/TVCG.2012.221","Evaluating the Effect of Style in Information Visualization","Visualization, design, style, aesthetics, evaluation, online study, user experience",2012,"This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.","Andrew Vande Moere;Martin Tomitsch;Christoph Wimmer;Christoph Bösch;Thomas Grechenig","http://dx.doi.org/10.1109/TVCG.2012.221","10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.122",150
"10.1109/TVCG.2012.225","Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization","Outflow, information visualization, temporal event sequences, state diagram, state transition",2012,"Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.","Krist Wongsuphasawat;David Gotz","http://dx.doi.org/10.1109/TVCG.2012.225","10.1109/TVCG.2009.181;10.1109/VAST.2011.6102453;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532150;10.1109/VAST.2009.5332595;10.1109/TVCG.2009.117;10.1109/INFVIS.2005.1532152;10.1109/VAST.2006.261421",151
"10.1109/TVCG.2012.226","Facilitating Discourse Analysis with Interactive Visualization","Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques",2012,"A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.","Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan","http://dx.doi.org/10.1109/TVCG.2012.226","10.1109/VAST.2011.6102439;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.122;10.1109/INFVIS.1999.801869;10.1109/INFVIS.2003.1249030",152
"10.1109/TVCG.2012.229","Graphical Overlays: Using Layered Elements to Aid Chart Reading","Visualization, overlays, graphical perception, graph comprehension",2012,"Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.","Nicholas Kong;Maneesh Agrawala","http://dx.doi.org/10.1109/TVCG.2012.229","10.1109/TVCG.2011.242;10.1109/VISUAL.1991.175820;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183",153
"10.1109/TVCG.2012.230","Graphical Tests for Power Comparison of Competing Designs","Lineups, Visual inference, Power comparison, Efficiency of displays",2012,"Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.","Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook","http://dx.doi.org/10.1109/TVCG.2012.230","10.1109/TVCG.2009.111;10.1109/TVCG.2010.161",154
"10.1109/TVCG.2012.237","Interaction Support for Visual Comparison Inspired by Natural Behavior","Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction",2012,"Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.","Christian Tominski;Camilla Forsell;Jimmy Johansson","http://dx.doi.org/10.1109/TVCG.2012.237","10.1109/TVCG.2008.109;10.1109/TVCG.2007.70568;10.1109/TVCG.2011.201;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.151;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2011.223;10.1109/TVCG.2007.70582;10.1109/TVCG.2008.153",155
"10.1109/TVCG.2012.238","Interactive Level-of-Detail Rendering of Large Graphs","Graph visualization, OpenGL, edge aggregation",2012,"We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.","Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt","http://dx.doi.org/10.1109/TVCG.2012.238","10.1109/INFVIS.2005.1532150;10.1109/TVCG.2006.120;10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.187;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/INFVIS.2004.66",156
"10.1109/TVCG.2012.250","Organizing Search Results with a Reference Map","Search results, mental map, voronoi treemaps, dynamic graph layout, multidimensional scaling, edge bundling",2012,"We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.","Arlind Nocaj;Ulrik Brandes","http://dx.doi.org/10.1109/TVCG.2012.250","10.1109/INFVIS.2005.1532128;10.1109/INFVIS.1997.636718;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/TVCG.2009.176",157
"10.1109/TVCG.2012.252","PivotPaths: Strolling through Faceted Information Spaces","Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search",2012,"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.","Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan T. Dumais","http://dx.doi.org/10.1109/TVCG.2012.252","10.1109/VAST.2009.5333443;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677370;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.175",158
"10.1109/TVCG.2012.253","RankExplorer: Visualization of Ranking Changes in Large Time Series Data","Time-series data, ranking change, Themeriver, interaction techniques",2012,"For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.","Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen 0001;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2012.253","10.1109/TVCG.2008.166;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.193;10.1109/VAST.2010.5652530;10.1109/INFVIS.2000.885098;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2010.129;10.1109/TVCG.2008.181;10.1109/TVCG.2009.187;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.194;10.1109/TVCG.2011.239;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195;10.1109/TVCG.2009.180",159
"10.1109/TVCG.2012.255","RelEx: Visualization for Actively Changing Overlay Network Specifications","Network visualization, change management, traffic routing, traffic optimization, automotive, design study",2012,"We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.","Michael Sedlmair;Annika Frank;Tamara Munzner;Andreas Butz","http://dx.doi.org/10.1109/TVCG.2012.255","10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102443;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/INFVIS.1999.801869;10.1109/TVCG.2008.141;10.1109/TVCG.2008.117;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/INFVIS.2003.1249030;10.1109/VAST.2006.261426",160
"10.1109/TVCG.2012.256","Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data","Interactive visual analysis, high-dimensional data analysis",2012,"Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.","Cagatay Turkay;Arvid Lundervold;Astri J. Lundervold;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2012.256","10.1109/TVCG.2009.199;10.1109/INFVIS.2005.1532142;10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70569;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153",161
"10.1109/TVCG.2012.263","SnapShot: Visualization to Propel Ice Hockey Analytics","Visual knowledge discovery, visual knowledge representation, hypothesis testing, visual evidence, human computer interaction",2012,"Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.","Hannah Pileggi;Charles D. Stolper;J. Michael Boyle;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2012.263","10.1109/TVCG.2010.179;10.1109/TVCG.2007.70537;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.1996.559229",162
"10.1109/TVCG.2012.264","Spatial Text Visualization Using Automatic Typographic Maps","Geovisualization, spatial data, text visualization, label placement",2012,"We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.","Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert","http://dx.doi.org/10.1109/TVCG.2012.264","10.1109/VAST.2010.5652931;10.1109/TVCG.2010.191;10.1109/TVCG.2010.175;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2002.1173144;10.1109/TVCG.2008.165;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171;10.1109/INFVIS.2000.885095",163
"10.1109/TVCG.2012.265","Stacking-Based Visualization of Trajectory Attribute Data","Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data",2012,"Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.","Christian Tominski;Heidrun Schumann;Gennady L. Andrienko;Natalia V. Andrienko","http://dx.doi.org/10.1109/TVCG.2012.265","10.1109/TVCG.2010.197;10.1109/VAST.2011.6102455;10.1109/VAST.2009.5332593;10.1109/VISUAL.1995.480803;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532144;10.1109/VAST.2011.6102454",164
"10.1109/TVCG.2012.271","Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments","Glyph-based techniques, taxonomies, design methodologies, bioinformatics visualization",2012,"Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.","Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen","http://dx.doi.org/10.1109/TVCG.2012.271","10.1109/TVCG.2006.134;10.1109/TVCG.2012.197;10.1109/TVCG.2010.132;10.1109/VISUAL.1995.485141;10.1109/INFVIS.1998.729568",165
"10.1109/TVCG.2012.272","The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning","Informal science education, collaborative learning, large tree visualizations, multi-touch interaction",2012,"In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.","Florian Block;Michael S. Horn;Brenda Caldwell Phillips;Judy Diamond;E. Margaret Evans;Chia Shen","http://dx.doi.org/10.1109/TVCG.2012.272","10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541",166
"10.1109/TVCG.2012.285","Visualizing Flow of Uncertainty through Analytical Processes","Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion",2012,"Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.","Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma","http://dx.doi.org/10.1109/TVCG.2012.285","10.1109/TVCG.2008.137;10.1109/TVCG.2011.178;10.1109/INFVIS.2004.2;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2009.114;10.1109/TVCG.2011.197;10.1109/TVCG.2010.176",167
"10.1109/TVCG.2012.286","Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations","Performance analysis, network traffic visualization, projected graph layouts",2012,"The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.","Aaditya G. Landge;Joshua A. Levine;Abhinav Bhatele;Katherine E. Isaacs;Todd Gamblin;Martin Schulz 0001;Steve H. Langer;Peer-Timo Bremer;Valerio Pascucci","http://dx.doi.org/10.1109/TVCG.2012.286","10.1109/TVCG.2009.196;10.1109/INFVIS.2004.66",168
"10.1109/TVCG.2012.291","Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time","Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns",2012,"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, â€œWhisperâ€, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.","Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2012.291","10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188",169
"10.1109/TVCG.2012.219","Enterprise Data Analysis and Visualization: An Interview Study","Data, analysis, visualization, enterprise",2012,"Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.","Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2012.219","10.1109/TVCG.2008.137;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5652880;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102435",170
"10.1109/TVCG.2012.224","Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts","Visual analytics, case study, qualitative evaluation",2012,"While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems.","Youn ah Kang;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2012.224","10.1109/VAST.2008.4677362;10.1109/VAST.2006.261416;10.1109/INFVIS.2004.5;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333878",171
"10.1109/TVCG.2012.254","Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data","Large categorical data, contingency table analysis, information interfaces and representation, visual analytics",2012,"Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.","Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Eduard Gröller","http://dx.doi.org/10.1109/TVCG.2012.254","10.1109/INFVIS.2005.1532139;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2002.1173157",172
"10.1109/TVCG.2012.258","Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results","Scatter/gather clustering, alternative clustering, constrained clustering",2012,"Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.","M. Shahriar Hossain;Praveen Kumar Reddy Ojili;Cindy Grimm;Rolf Mueller;Layne T. Watson;Naren Ramakrishnan","http://dx.doi.org/10.1109/TVCG.2012.258","10.1109/VAST.2009.5332584;10.1109/VAST.2007.4388999;10.1109/VAST.2008.4677350;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332629",173
"10.1109/TVCG.2012.260","Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering","User Interaction, visualization, sensemaking, analytic reasoning, visual analytics",2012,"Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.","Alex Endert;Patrick Fiaux;Chris North","http://dx.doi.org/10.1109/TVCG.2012.260","10.1109/INFVIS.1995.528686;10.1109/VAST.2012.6400559;10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102438;10.1109/VAST.2007.4389006",174
"10.1109/TVCG.2012.273","The User Puzzle---Explaining the Interaction with Visual Analytics Systems","Cognitive theory, visual knowledge discovery, interaction design, reasoning, problem solving",2012,"Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.","Margit Pohl;Michael Smuc;Eva Mayr","http://dx.doi.org/10.1109/TVCG.2012.273","10.1109/TVCG.2008.121;10.1109/TVCG.2007.70515;10.1109/VAST.2010.5653598;10.1109/VAST.2008.4677361;10.1109/VAST.2011.6102445",175
"10.1109/TVCG.2012.276","Visual Analytics Methodology for Eye Movement Studies","Visual analytics, eye tracking, movement data, trajectory analysis",2012,"Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.","Gennady L. Andrienko;Natalia V. Andrienko;Michael Burch;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2012.276","10.1109/VAST.2009.5332593;10.1109/TVCG.2011.193;10.1109/INFVIS.2005.1532150",176
"10.1109/TVCG.2012.277","Visual Classifier Training for Text Document Retrieval","Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",2012,"Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.","Florian Heimerl;Steffen Koch;Harald Bosch;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2012.277","10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",177
"10.1109/VAST.2012.6400485","LeadLine: Interactive visual analysis of text data through event identification and exploration","",2012,"Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data.","Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou","http://dx.doi.org/10.1109/VAST.2012.6400485","10.1109/VAST.2011.6102456;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/TVCG.2011.185;10.1109/TVCG.2010.179;10.1109/VAST.2007.4389006;10.1109/INFVIS.2000.885098",178
"10.1109/VAST.2012.6400486","Dis-function: Learning distance functions interactively","",2012,"The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.","Eli T. Brown;Jingjing Liu;Carla E. Brodley;Remco Chang","http://dx.doi.org/10.1109/VAST.2012.6400486","10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443",179
"10.1109/VAST.2012.6400487","Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations","Just-in-time descriptive analytics, feature identification and characterization, point-based visualizations",2012,"We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.","Eser Kandogan","http://dx.doi.org/10.1109/VAST.2012.6400487","10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3;10.1109/TVCG.2011.220;10.1109/INFVIS.2004.15;10.1109/INFVIS.1998.729559;10.1109/VAST.2006.261423;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.229",180
"10.1109/VAST.2012.6400488","Subspace search and visualization to make sense of alternative clusterings in high-dimensional data","",2012,"In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.","Andrada Tatu;Fabian Maass;Ines Färber;Enrico Bertini;Tobias Schreck;Thomas Seidl 0001;Daniel A. Keim","http://dx.doi.org/10.1109/VAST.2012.6400488","10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652392;10.1109/INFVIS.2004.71;10.1109/VAST.2010.5652450;10.1109/VAST.2011.6102439;10.1109/TVCG.2011.188;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153",181
"10.1109/VAST.2012.6400489","iLAMP: Exploring high-dimensional spacing through backward multidimensional projection","",2012,"Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space.","Elisa Portes dos Santos;Emilio Vital Brazil;Joel Daniels II;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa","http://dx.doi.org/10.1109/VAST.2012.6400489","10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/TVCG.2010.213;10.1109/TVCG.2009.140;10.1109/TVCG.2011.220;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.170;10.1109/TVCG.2007.70580;10.1109/TVCG.2010.207;10.1109/INFVIS.2002.1173161",182
"10.1109/VAST.2012.6400490","Visual pattern discovery using random projections","Random Projections, High-dimensional Data",2012,"An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems.","Anushka Anand;Leland Wilkinson;Dang Tuan Nhon","http://dx.doi.org/10.1109/VAST.2012.6400490","10.1109/VAST.2010.5652433;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/VAST.2009.5332629",183
"10.1109/VAST.2012.6400491","A correlative analysis process in a visual analytics environment","Visual analytics, correlative analysis",2012,"Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.","Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang","http://dx.doi.org/10.1109/VAST.2012.6400491","10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801851;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195",184
"10.1109/VAST.2012.6400493","An adaptive parameter space-filling algorithm for highly interactive cluster exploration","",2012,"For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.","Zafar Ahmed;Chris Weaver","http://dx.doi.org/10.1109/VAST.2012.6400493","10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12;10.1109/VAST.2009.5332629;10.1109/VAST.2008.4677357;10.1109/TVCG.2011.188;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VAST.2007.4388999",185
"10.1109/VAST.2012.6400494","Visual cluster exploration of web clickstream data","",2012,"Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system's effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.","Jishang Wei;Zeqian Shen;Neel Sundaresan;Kwan-Liu Ma","http://dx.doi.org/10.1109/VAST.2012.6400494","10.1109/INFVIS.2005.1532145;10.1109/VAST.2007.4389008;10.1109/VAST.2011.6102462;10.1109/VISUAL.1991.175815",186
"10.1109/VAST.2012.6400552","Watch this: A taxonomy for dynamic data visualization","Dynamic Data, Interpretation",2012,"Visualizations embody design choices about data access, data transformation, visual representation, and interaction. To interpret a static visualization, a person must identify the correspondences between the visual representation and the underlying data. These correspondences become moving targets when a visualization is dynamic. Dynamics may be introduced in a visualization at any point in the analysis and visualization process. For example, the data itself may be streaming, shifting subsets may be selected, visual representations may be animated, and interaction may modify presentation. In this paper, we focus on the impact of dynamic data. We present a taxonomy and conceptual framework for understanding how data changes influence the interpretability of visual representations. Visualization techniques are organized into categories at various levels of abstraction. The salient characteristics of each category and task suitability are discussed through examples from the scientific literature and popular practices. Examining the implications of dynamically updating visualizations warrants attention because it directly impacts the interpretability (and thus utility) of visualizations. The taxonomy presented provides a reference point for further exploration of dynamic data visualization techniques.","Joseph A. Cottam;Andrew Lumsdaine;Chris Weaver","http://dx.doi.org/10.1109/VAST.2012.6400552","10.1109/TVCG.2009.123;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885092",187
"10.1109/VAST.2012.6400553","Visual analytics methods for categoric spatio-temporal data","",2012,"We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.","Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova","http://dx.doi.org/10.1109/VAST.2012.6400553","10.1109/TVCG.2011.174;10.1109/TVCG.2009.117;10.1109/TVCG.2009.181;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2001.963281;10.1109/TVCG.2008.165;10.1109/TVCG.2009.153",188
"10.1109/VAST.2012.6400554","Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems","",2012,"Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.","Leishi Zhang;Andreas Stoffel;Michael Behrisch;Sebastian Mittelstädt;Tobias Schreck;René Pompl;Stefan Weber 0004;Holger Last;Daniel A. Keim","http://dx.doi.org/10.1109/VAST.2012.6400554","10.1109/INFVIS.2004.12;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885098",189
"10.1109/VAST.2012.6400556","AlVis: Situation awareness in the surveillance of road tunnels","",2012,"In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.","Harald Piringer;Matthias Buchetics;Rudolf Benedik","http://dx.doi.org/10.1109/VAST.2012.6400556","10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2005.1532134;10.1109/VAST.2011.6102456;10.1109/TVCG.2007.70544;10.1109/TVCG.2007.70521;10.1109/TVCG.2007.70621;10.1109/INFVIS.2004.27;10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.185;10.1109/VAST.2007.4388994;10.1109/VAST.2007.4388998;10.1109/VAST.2008.4677353",190
"10.1109/VAST.2012.6400558","SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization","Social network, visualization, sensemaking, visual analytics, SocialNetSense",2012,"Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.","Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson","http://dx.doi.org/10.1109/VAST.2012.6400558","10.1109/INFVIS.1999.801853;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532126;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.192;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102440;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.2;10.1109/TVCG.2008.137;10.1109/TVCG.2006.166;10.1109/TVCG.2006.160;10.1109/VAST.2008.4677365;10.1109/TVCG.2006.147;10.1109/VAST.2007.4389006",191
"10.1109/VAST.2012.6400559","Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays","Embodiment, distributed cognition, large and high-resolution display, sensemaking, space",2012,"Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.","Christopher Andrews;Chris North","http://dx.doi.org/10.1109/VAST.2012.6400559","10.1109/TVCG.2008.121;10.1109/VAST.2008.4677362;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677358;10.1109/TVCG.2006.184;10.1109/VAST.2007.4388992;10.1109/VAST.2010.5652880;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878",192
"10.1109/TVCG.2012.190","A Visual Analysis Concept for the Validation of Geoscientific Simulation Models","Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators",2012,"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","Andrea Unger;Sven Schulte;Volker Klemann;Doris Dransch","http://dx.doi.org/10.1109/TVCG.2012.190","10.1109/TVCG.2010.192;10.1109/VAST.2010.5652895;10.1109/TVCG.2011.248;10.1109/TVCG.2008.145;10.1109/TVCG.2011.225;10.1109/TVCG.2010.223;10.1109/TVCG.2010.171;10.1109/TVCG.2010.190;10.1109/VISUAL.1993.398859;10.1109/TVCG.2010.181;10.1109/TVCG.2008.139",193
"10.1109/TVCG.2012.198","Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains","Vector field topology, flow visualization, feature extraction, uncertainty",2012,"Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.","Wieland Reich;Gerik Scheuermann","http://dx.doi.org/10.1109/TVCG.2012.198","10.1109/VISUAL.1999.809896",194
"10.1109/TVCG.2012.203","Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization","Direct volume rendering, transfer functions, vessel visualization",2012,"Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.","Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga","http://dx.doi.org/10.1109/TVCG.2012.203","10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.120;10.1109/VISUAL.2001.964516;10.1109/VISUAL.1996.568113;10.1109/TVCG.2008.162;10.1109/TVCG.2010.195;10.1109/TVCG.2008.123",195
"10.1109/TVCG.2012.211","Derived Metric Tensors for Flow Surface Visualization","Vector field, integral surfaces, metric tensor, deformation, velocity gradient, continuum mechanics",2012,"Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.","Harald Obermaier;Kenneth I. Joy","http://dx.doi.org/10.1109/TVCG.2012.211","10.1109/TVCG.2008.163;10.1109/TVCG.2010.173;10.1109/TVCG.2011.170;10.1109/TVCG.2006.134;10.1109/TVCG.2008.133;10.1109/VISUAL.1992.235211;10.1109/TVCG.2007.70551;10.1109/VISUAL.2004.80;10.1109/TVCG.2009.190;10.1109/TVCG.2010.166;10.1109/TVCG.2009.154;10.1109/TVCG.2007.70554",196
"10.1109/TVCG.2012.216","Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization","Display characteristics, diffusion tensor MRI, virtual environment",2012,"We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.","Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw","http://dx.doi.org/10.1109/TVCG.2012.216","10.1109/TVCG.2009.126;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.111;10.1109/TVCG.2009.138;10.1109/TVCG.2006.183",197
"10.1109/TVCG.2012.217","Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input","3D interaction, spatial selection, direct-touch interaction",2012,"Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.","Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001","http://dx.doi.org/10.1109/TVCG.2012.217","10.1109/TVCG.2010.157;10.1109/TVCG.2012.292;10.1109/TVCG.2008.153",198
"10.1109/TVCG.2012.222","Evaluation of Fast-Forward Video Visualization","Video visualization, adaptive fast-forward, controlled laboratory user study",2012,"We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.","Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2012.222","10.1109/TVCG.2007.70542;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2006.194",199
"10.1109/TVCG.2012.223","Evaluation of Multivariate Visualization on a Multivariate Task","Quantitative evaluation, multivariate visualization, visual task design, texture perception",2012,"Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.","Mark A. Livingston;Jonathan W. Decker;Zhuming Ai","http://dx.doi.org/10.1109/TVCG.2012.223","10.1109/TVCG.2011.194;10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/TVCG.2007.70623;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362",200
"10.1109/TVCG.2012.240","Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach","Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience",2012,"This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.","Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2012.240","10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161",201
"10.1109/TVCG.2012.269","Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets","Multifield, time-varying, surface structures",2012,"This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.","Samer S. Barakat;Markus Rütten;Xavier Tricoche","http://dx.doi.org/10.1109/TVCG.2012.269","10.1109/TVCG.2007.70615;10.1109/TVCG.2007.70523;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.140;10.1109/VISUAL.1995.485139;10.1109/TVCG.2009.177;10.1109/TVCG.2008.148",202
"10.1109/TVCG.2012.274","Turbulence Visualization at the Terascale on Desktop PCs","Visualization system and toolkit design, vector fields, volume rendering, data streaming, data compression",2012,"Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.","Marc Treib;Kai Bürger;Florian Reichl;Charles Meneveau;Alexander S. Szalay;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2012.274","10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/TVCG.2006.143;10.1109/VISUAL.2005.1532808;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964531;10.1109/VISUAL.2004.55;10.1109/VISUAL.2003.1250385",203
"10.1109/TVCG.2012.280","Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research","Dimension reduction, mass spectrometry data, matrix factorization, visual encodings of numerical error metrics, multi-dimensional data visualization",2012,"The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.","Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony S. Wexler;Bernd Hamann;Hans Hagen","http://dx.doi.org/10.1109/TVCG.2012.280","10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/VISUAL.2000.885734;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2010.223;10.1109/VISUAL.2005.1532850;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2008.153",204
"10.1109/TVCG.2012.281","Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography","Astronomical visualization, distributed volume reconstruction, direct volume rendering",2012,"The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.","Stephan Wenger;Marco Ament;Stefan Guthe;Dirk A. Lorenz;Andreas M. Tillmann;Daniel Weiskopf;Marcus A. Magnor","http://dx.doi.org/10.1109/TVCG.2012.281","10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18;10.1109/VISUAL.1994.346331",205
"10.1109/TVCG.2012.292","WYSIWYP: What You See Is What You Pick","Picking, volume rendering, WYSIWYG",2012,"Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (â€œwhat you see is what you pickâ€) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.","Alexander Wiebel;Frans Vos;David Foerster;Hans-Christian Hege","http://dx.doi.org/10.1109/TVCG.2012.292","10.1109/TVCG.2012.217;10.1109/VISUAL.1998.745337;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70576;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2009.121",206
"10.1109/TVCG.2013.119","A Deeper Understanding of Sequence in Narrative Visualization","Data storytelling, narrative visualization, narrative structure",2013,"Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.","Jessica Hullman;Steven M. Drucker;Nathalie Henry Riche;Bongshin Lee;Danyel Fisher;Eytan Adar","http://dx.doi.org/10.1109/TVCG.2013.119","10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/TVCG.2008.137;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70539;10.1109/INFVIS.2000.885086",207
"10.1109/TVCG.2013.120","A Design Space of Visualization Tasks","Task taxonomy, design space, climate impact research, visualization recommendation",2013,"Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.","Hans-Jörg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann","http://dx.doi.org/10.1109/TVCG.2013.120","10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375",208
"10.1109/TVCG.2013.122","A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays","Comparative visualization, small-multiple displays, trellis displays, categorical data",2013,"Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.","Johannes Kehrer;Harald Piringer;Wolfgang Berger;Eduard Gröller","http://dx.doi.org/10.1109/TVCG.2013.122","10.1109/TVCG.2010.138;10.1109/TVCG.2007.70594;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.125;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102439;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885086;10.1109/TVCG.2012.237;10.1109/TVCG.2007.70521",209
"10.1109/TVCG.2013.124","A Multi-Level Typology of Abstract Visualization Tasks","Typology, visualization models, task and requirements analysis, qualitative evaluation",2013,"The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.","Matthew Brehmer;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2013.124","10.1109/TVCG.2007.70541;10.1109/TVCG.2012.219;10.1109/INFVIS.1996.559213;10.1109/TVCG.2012.213;10.1109/TVCG.2012.273;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2008.137;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2012.252;10.1109/VISUAL.1990.146375",210
"10.1109/TVCG.2013.130","An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization","Science of interaction, interaction primitives, interactive maps, geovisualization, interaction techniques",2013,"Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, & delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, & prescribe) and interaction operands (space-alone, attributes-in-space, & space-in-time; elementary & general). The operator sort suggested five enabling operators (import, export, save, edit, & annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, & calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.","Robert E. Roth","http://dx.doi.org/10.1109/TVCG.2013.130","10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5653599;10.1109/INFVIS.2000.885092",211
"10.1109/TVCG.2013.134","An Interaction Model for Visualizations Beyond The Desktop","Information visualization, interaction model, notational system, physical visualization",2013,"We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.","Yvonne Jansen;Pierre Dragicevic","http://dx.doi.org/10.1109/TVCG.2013.134","10.1109/TVCG.2010.177;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2006.178;10.1109/TVCG.2009.162;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1990.146375",212
"10.1109/TVCG.2013.137","Automatic Layout of Structured Hierarchical Reports","Hierarchy data, tabular data, nested relations, layout management",2013,"Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.","Eirik Bakke;David R. Karger;Rob Miller","http://dx.doi.org/10.1109/TVCG.2013.137","10.1109/VAST.2011.6102445;10.1109/INFVIS.2004.1;10.1109/INFVIS.1995.528693;10.1109/TVCG.2007.70594;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636761",213
"10.1109/TVCG.2013.140","Common Angle Plots as Perception-True Visualizations of Categorical Associations","Linewidth illusion, data visualization, high-dimensional displays, parallel sets, hammock plots, Muller-Lyer illusion",2013,"Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue.","Heike Hofmann;Marie Vendettuoli","http://dx.doi.org/10.1109/TVCG.2013.140","10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532128;10.1109/TVCG.2010.186;10.1109/TVCG.2011.185;10.1109/TVCG.2009.128",214
"10.1109/TVCG.2013.145","Creative User-Centered Visualization Design for Energy Analysts and Modelers","Creativity techniques, user-centered design, data visualization, smart home, energy consumption",2013,"We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.","Sarah Goodwin;Jason Dykes;Sara Jones;Iain Dillingham;Graham Dove;Alison Duffy;Alexander Kachkaev;Aidan Slingsby;Jo Wood","http://dx.doi.org/10.1109/TVCG.2013.145","10.1109/TVCG.2010.191;10.1109/TVCG.2012.213;10.1109/TVCG.2011.196;10.1109/TVCG.2007.70539;10.1109/INFVIS.1999.801851;10.1109/TVCG.2011.209",215
"10.1109/TVCG.2013.149","DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation","Dynamic networks, hybrid visualization, taxonomy, evolution, animation, difference map",2013,"Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.","Sébastien Rufiange;Michael J. McGuffin","http://dx.doi.org/10.1109/TVCG.2013.149","10.1109/VAST.2012.6400552;10.1109/TVCG.2011.169;10.1109/INFVIS.2005.1532151;10.1109/TVCG.2011.226;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.213;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70582;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173160;10.1109/TVCG.2007.70539",216
"10.1109/TVCG.2013.150","Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data","High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix",2013,"For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.","Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo","http://dx.doi.org/10.1109/TVCG.2013.150","10.1109/INFVIS.2005.1532142;10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VAST.2012.6400488;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.184;10.1109/TVCG.2009.128;10.1109/VAST.2006.261422;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173151",217
"10.1109/TVCG.2013.151","Edge Compression Techniques for Visualization of Dense Directed Graphs","Directed graphs, networks, modular decomposition, power graph analysis",2013,"We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.","Tim Dwyer;Nathalie Henry Riche;Kim Marriott;Christopher Mears","http://dx.doi.org/10.1109/TVCG.2013.151","10.1109/TVCG.2009.165;10.1109/TVCG.2011.233;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.66",218
"10.1109/TVCG.2013.153","Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices","Dimensionality reduction, scatterplots, quantitative study",2013,"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.","Michael Sedlmair;Tamara Munzner;Melanie Tory","http://dx.doi.org/10.1109/TVCG.2013.153","10.1109/TVCG.2009.127;10.1109/TVCG.2011.229;10.1109/TVCG.2007.70596;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1997.636793;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2008.109;10.1109/VAST.2009.5332628",219
"10.1109/TVCG.2013.154","Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets","Pathway visualization, biological networks, subsets, graphs, biomolecular data",2013,"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","Alexander Lex;Christian Partl;Denis Kalkofen;Marc Streit;Samuel Gratzl;Anne Mai Wassermann;Dieter Schmalstieg;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2013.154","10.1109/VAST.2009.5333443;10.1109/TVCG.2011.250;10.1109/TVCG.2011.213;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087",220
"10.1109/TVCG.2013.155","Evaluation of filesystem Provenance Visualization Tools","Provenance data, graph/network data, hierarchy data, quantitative evaluation, gender differences",2013,"Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.","Michelle Borkin;Chelsea S. Yeh;Madelaine Boyd;Peter Macko;Krzysztof Z. Gajos;Margo I. Seltzer;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2013.155","10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2006.120;10.1109/TVCG.2009.167;10.1109/INFVIS.2004.66;10.1109/INFVIS.2004.1;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532134",221
"10.1109/TVCG.2013.160","GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data","Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence",2013,"Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.","Jean-Francois Im;Michael J. McGuffin;Rock Leung","http://dx.doi.org/10.1109/TVCG.2013.160","10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/TVCG.2007.70594;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2010.205;10.1109/TVCG.2011.183;10.1109/VISUAL.1993.398859;10.1109/TVCG.2011.201;10.1109/TVCG.2010.164;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/VISUAL.1991.175796",222
"10.1109/TVCG.2013.163","Hybrid-Image Visualization for Large Viewing Environments","Multi-scale, large displays, hybrid images, collaboration, visualization",2013,"We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.","Petra Isenberg;Pierre Dragicevic;Wesley Willett;Anastasia Bezerianos;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2013.163","10.1109/TVCG.2012.251;10.1109/TVCG.2012.264;10.1109/TVCG.2006.184;10.1109/TVCG.2007.70582;10.1109/INFVIS.2001.963288;10.1109/TVCG.2007.70583;10.1109/INFVIS.2005.1532131",223
"10.1109/TVCG.2013.166","Information Visualization and Proxemics: Design Opportunities and Empirical findings","Proxemics, information visualization, user study, large displays, user tracking, movement, orientation, distance",2013,"People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.","Mikkel Rønne Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk","http://dx.doi.org/10.1109/TVCG.2013.166","10.1109/TVCG.2006.184;10.1109/TVCG.2012.204;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136",224
"10.1109/TVCG.2013.173","LineUp: Visual Analysis of Multi-Attribute Rankings","Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts",2013,"Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.","Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit","http://dx.doi.org/10.1109/TVCG.2013.173","10.1109/TVCG.2012.253;10.1109/TVCG.2008.166;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.181;10.1109/TVCG.2007.70539",225
"10.1109/TVCG.2013.179","Nanocubes for Real-Time Exploration of Spatiotemporal Datasets","Data cube, Data structures, Interactive exploration",2013,"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.","Lauro Didier Lins;James T. Klosowski;Carlos Eduardo Scheidegger","http://dx.doi.org/10.1109/TVCG.2013.179","10.1109/TVCG.2006.161;10.1109/INFVIS.2002.1173141;10.1109/TVCG.2009.191;10.1109/VAST.2008.4677357;10.1109/TVCG.2007.70594;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185",226
"10.1109/TVCG.2013.184","Radial Sets: Interactive Visual Analysis of Large Overlapping Sets","Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability",2013,"In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.","Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2013.184","10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157",227
"10.1109/TVCG.2013.191","SketchStory: Telling More Engaging Stories with Data through Freeform Sketching","Storytelling, data presentation, sketch, pen and touch, interaction, visualization",2013,"Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.","Bongshin Lee;Rubaiat Habib Kazi;Greg Smith","http://dx.doi.org/10.1109/TVCG.2013.191","10.1109/TVCG.2007.70577;10.1109/TVCG.2012.262;10.1109/TVCG.2010.179;10.1109/TVCG.2012.275;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992",228
"10.1109/TVCG.2013.192","SoccerStories: A Kick-off for Visual Soccer Analysis","Visual knowledge discovery, visual knowledge representation, sport analytics, visual aggregation",2013,"This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.","Charles Perin;Romain Vuillemot;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2013.192","10.1109/TVCG.2007.70582;10.1109/TVCG.2011.169;10.1109/TVCG.2011.185;10.1109/TVCG.2012.263",229
"10.1109/TVCG.2013.196","StoryFlow: Tracking the Evolution of Stories","Storylines, story-telling visualization, user interactions, level-of-detail, optimization",2013,"Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.","Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu 0014","http://dx.doi.org/10.1109/TVCG.2013.196","10.1109/TVCG.2012.253;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/TVCG.2011.226;10.1109/VAST.2008.4677364;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/VAST.2006.261421;10.1109/VAST.2009.5333437;10.1109/TVCG.2011.239",230
"10.1109/TVCG.2013.209","Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization","Business ecosystems, market research, strategic analysis, design study, interaction, network visualization",2013,"Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.","Rahul C. Basole;Trustin Clear;Mengdie Hu;Harshit Mehrotra;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2013.209","10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/INFVIS.2003.1249027;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652530;10.1109/TVCG.2006.166",231
"10.1109/TVCG.2013.214","Variant View: Visualizing Sequence Variants in their Gene Context","Information visualization, design study, bioinformatics, genetic variants",2013,"Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.","Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2013.214","10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/TVCG.2012.213;10.1109/TVCG.2011.185;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.116;10.1109/TVCG.2009.167;10.1109/TVCG.2011.209",232
"10.1109/TVCG.2013.225","Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs","Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm",2013,"This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.","Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen","http://dx.doi.org/10.1109/TVCG.2013.225","10.1109/TVCG.2007.70584;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.147;10.1109/TVCG.2009.195;10.1109/TVCG.2012.271;10.1109/VISUAL.1996.567752;10.1109/TVCG.2008.174;10.1109/TVCG.2006.166",233
"10.1109/TVCG.2013.227","Visual Sedimentation","Design, Information Visualization, Dynamic visualization, Dynamic data, Data stream, Real time, Metaphor",2013,"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.","Samuel Huron;Romain Vuillemot;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2013.227","10.1109/VAST.2012.6400552;10.1109/TVCG.2012.291;10.1109/TVCG.2011.179;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.185;10.1109/TVCG.2008.166;10.1109/TVCG.2008.171;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539",234
"10.1109/TVCG.2013.231","Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView","Information visualization, Tree comparison",2013,"To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.","John Alexis Guerra Gómez;Michael L. Pack;Catherine Plaisant;Ben Shneiderman","http://dx.doi.org/10.1109/TVCG.2013.231","10.1109/VAST.2011.6102439;10.1109/TVCG.2006.147;10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70556;10.1109/INFVIS.2002.1173150;10.1109/VAST.2006.261450;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2003.1249026;10.1109/TVCG.2007.70529",235
"10.1109/TVCG.2013.232","Visualizing Fuzzy Overlapping Communities in Networks","Overlapping community visualization, fuzzy clustering, graph visualization, uncertainty visualization",2013,"An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.","Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2013.232","10.1109/VISUAL.1993.398872;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2004.43;10.1109/TVCG.2009.113",236
"10.1109/TVCG.2013.233","Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems","Distributed systems, human factors, problem diagnosis, visualization",2013,"Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.","Raja R. Sambasivan;Ilari Shafer;Michelle L. Mazurek;Gregory R. Ganger","http://dx.doi.org/10.1109/TVCG.2013.233","10.1109/VAST.2010.5652910;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/VAST.2011.6102442",237
"10.1109/TVCG.2013.126","A Systematic Review on the Practice of Evaluating Visualization","Evaluation, validation, systematic review, visualization, scientific visualization, information visualization",2013,"We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.","Tobias Isenberg 0001;Petra Isenberg;Jian Chen;Michael Sedlmair;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2013.126","10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223",238
"10.1109/TVCG.2013.127","Acuity-Driven Gigapixel Visualization","Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display",2013,"We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.","Charilaos Papadopoulos;Arie E. Kaufman","http://dx.doi.org/10.1109/TVCG.2013.127","10.1109/TVCG.2011.231;10.1109/INFVIS.2004.66",239
"10.1109/TVCG.2013.129","Ambient Volume Scattering","Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading",2013,"We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.","Marco Ament;Filip Sadlo;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2013.129","10.1109/TVCG.2011.211;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2000.885683;10.1109/TVCG.2010.187;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250406;10.1109/TVCG.2010.145;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2005.1532803;10.1109/TVCG.2009.204",240
"10.1109/TVCG.2013.133","An Information-Aware Framework for Exploring Multivariate Data Sets","Information theory, framework, isosurface, multivariate uncertainty",2013,"Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.","Ayan Biswas;Soumya Dutta;Han-Wei Shen;Jonathan Woodring","http://dx.doi.org/10.1109/TVCG.2013.133","10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785",241
"10.1109/TVCG.2013.138","Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging","Uncertainty visualization, numerical ensembles, statistical visualization",2013,"Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.","Luke J. Gosink;Kevin Bensema;Trenton Pulsipher;Harald Obermaier;Michael Henry;Hank Childs;Kenneth I. Joy","http://dx.doi.org/10.1109/TVCG.2013.138","10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181",242
"10.1109/TVCG.2013.141","Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles","Ensemble, flow field, time-varying, comparison, visualization, Lagrangian, variance, principal components analysis",2013,"Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.","Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy","http://dx.doi.org/10.1109/TVCG.2013.141","10.1109/TVCG.2011.203;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2007.70551",243
"10.1109/TVCG.2013.142","ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data","Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis",2013,"This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.","Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger","http://dx.doi.org/10.1109/TVCG.2013.142","10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2009.178;10.1109/TVCG.2012.240;10.1109/TVCG.2006.195;10.1109/VISUAL.1995.485139;10.1109/TVCG.2007.70560;10.1109/TVCG.2009.118;10.1109/TVCG.2009.121",244
"10.1109/TVCG.2013.143","Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles","Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics",2013,"Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.","Ross T. Whitaker;Mahsa Mirzargar;Robert Michael Kirby","http://dx.doi.org/10.1109/TVCG.2013.143","10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.181",245
"10.1109/TVCG.2013.144","Coupled Ensemble Flow Line Advection and Analysis","Ensemble analysis, parallel processing, field line advection",2013,"Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.","Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu","http://dx.doi.org/10.1109/TVCG.2013.144","10.1109/VISUAL.2005.1532853;10.1109/TVCG.2011.219;10.1109/TVCG.2011.203;10.1109/TVCG.2006.116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/VISUAL.1996.568116;10.1109/TVCG.2007.70551",246
"10.1109/TVCG.2013.158","Fast Blending Scheme for Molecular Surface Representation","Molecular visualization, geometry-based techniques, implicit surfaces",2013,"Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.","Július Parulek;Andrea Brambilla","http://dx.doi.org/10.1109/TVCG.2013.158","10.1109/TVCG.2009.157;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2006.115",247
"10.1109/TVCG.2013.159","Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy","Digitally reconstructed radiographs, volume rendering, mesh deformation, statistical shape and intensity models, image registration, GPU acceleration",2013,"We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.","Moritz Ehlke;Heiko Ramm;Hans Lamecker;Hans-Christian Hege;Stefan Zachow","http://dx.doi.org/10.1109/TVCG.2013.159","10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2005.1532815;10.1109/TVCG.2006.110;10.1109/VISUAL.2003.1250384",248
"10.1109/TVCG.2013.161","GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data","Design studies, methodology design, task and requirements analysis, integrating spatial and non-spatial data visualization, visual comparison, high-dimensional data, applications of visualization",2013,"We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.","Adrian Maries;Nathan Mays;MeganOlson Hunt;Kim F. Wong;William J. Layton;Robert Boudreau;Caterina Rosano;G. Elisabeta Marai","http://dx.doi.org/10.1109/TVCG.2013.161","10.1109/TVCG.2009.141;10.1109/VISUAL.2000.885739;10.1109/VAST.2006.261438;10.1109/TVCG.2009.111;10.1109/TVCG.2010.137;10.1109/TVCG.2009.114;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.162",249
"10.1109/TVCG.2013.177","MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data","3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects",2013,"This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.","Andreas Reh;Christian Gusenbauer;Johann Kastner;Eduard Gröller;Christoph Heinzl","http://dx.doi.org/10.1109/TVCG.2013.177","10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809871;10.1109/TVCG.2009.121;10.1109/TVCG.2012.227;10.1109/TVCG.2011.248;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.190;10.1109/TVCG.2010.214;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1997.663875",250
"10.1109/TVCG.2013.189","Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates","4D pc-mri, cardiac blood flow, hemodynamics, line predicates, vortex extraction",2013,"Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.","Benjamin Köhler;Rocco Gasteiger;Uta Preim;Holger Theisel;Matthias Gutberlet;Bernhard Preim","http://dx.doi.org/10.1109/TVCG.2013.189","10.1109/TVCG.2011.260;10.1109/VISUAL.1999.809869;10.1109/TVCG.2010.153;10.1109/VISUAL.1999.809896;10.1109/TVCG.2011.243;10.1109/TVCG.2007.70545;10.1109/VISUAL.2004.99;10.1109/TVCG.2010.173",251
"10.1109/TVCG.2013.208","Uncertainty Quantification in Linear Interpolation for Isosurface Extraction","Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes",2013,"We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.","Tushar Athawale;Alireza Entezari","http://dx.doi.org/10.1109/TVCG.2013.208","10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70602;10.1109/VISUAL.1991.175782;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.194;10.1109/TVCG.2011.203",252
"10.1109/TVCG.2013.125","A Partition-Based Framework for Building and Validating Regression Models","Regression, model building, visual knowledge discovery, feature selection, data partitioning, guided visualization",2013,"Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.","Thomas Mühlbacher;Harald Piringer","http://dx.doi.org/10.1109/TVCG.2013.125","10.1109/TVCG.2012.219;10.1109/TVCG.2009.128;10.1109/VISUAL.1993.398859;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102453;10.1109/VAST.2009.5333431;10.1109/TVCG.2010.213;10.1109/TVCG.2012.205;10.1109/VAST.2009.5332628;10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102450;10.1109/VAST.2008.4677368;10.1109/VAST.2010.5652460;10.1109/TVCG.2011.248;10.1109/INFVIS.2005.1532142;10.1109/VAST.2007.4388999;10.1109/INFVIS.2004.10;10.1109/TVCG.2009.110;10.1109/VAST.2011.6102448;10.1109/INFVIS.2004.3",253
"10.1109/TVCG.2013.132","An Extensible Framework for Provenance in Human Terrain Visual Analytics","Human terrain analysis, provenance, framework, bookmarks, narratives",2013,"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.","Rick Walker;Aidan Slingsby;Jason Dykes;Kai Xu 0003;Jo Wood;Phong H. Nguyen;Derek Stephens;B. L. William Wong;Yongjun Zheng","http://dx.doi.org/10.1109/TVCG.2013.132","10.1109/TVCG.2012.252;10.1109/TVCG.2010.191;10.1109/VAST.2007.4388992;10.1109/TVCG.2006.142;10.1109/VAST.2006.261431;10.1109/TVCG.2010.154;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677366;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4388992;10.1109/TVCG.2009.128;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919;10.1109/TVCG.2011.209;10.1109/TVCG.2009.139;10.1109/TVCG.2008.175",254
"10.1109/TVCG.2013.146","Decision Exploration Lab: A Visual Analytics Solution for Decision Management","Decision support systems, model validation and analysis, multivariate Statistics, program analysis",2013,"We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.","Bertjan Broeksema;Thomas Baudel;Arthur G. Telea;Paolo Crisafulli","http://dx.doi.org/10.1109/TVCG.2013.146","10.1109/VISUAL.1991.175815;10.1109/VAST.2011.6102463;10.1109/VAST.2010.5652398;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677363;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102457",255
"10.1109/TVCG.2013.157","Explainers: Expert Explorations with Crafted Projections","High-dimensional spaces, exploration, support vector machines",2013,"This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.","Michael Gleicher","http://dx.doi.org/10.1109/TVCG.2013.157","10.1109/VAST.2012.6400487;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.71;10.1109/TVCG.2012.256;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2011.220;10.1109/INFVIS.1998.729559;10.1109/VAST.2011.6102448;10.1109/TVCG.2009.153",256
"10.1109/TVCG.2013.162","HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies","Hierarchical topic representation, topic modeling, visual analytics, rose tree",2013,"Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.","Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;William Ribarsky","http://dx.doi.org/10.1109/TVCG.2013.162","10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485",257
"10.1109/TVCG.2013.164","Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis","Crowdsourcing, social data analysis",2013,"We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.","Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala","http://dx.doi.org/10.1109/TVCG.2013.164","10.1109/TVCG.2007.70577",258
"10.1109/TVCG.2013.167","Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets","Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics",2013,"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.","Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan","http://dx.doi.org/10.1109/TVCG.2013.167","10.1109/TVCG.2008.137;10.1109/VAST.2011.6102440;10.1109/TVCG.2011.213;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.205;10.1109/TVCG.2012.252;10.1109/TVCG.2006.166;10.1109/INFVIS.2000.885086",259
"10.1109/TVCG.2013.168","Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization","Video visual analytics, surveillance video, video visualization, video summarization, video browsing and exploration",2013,"We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.","Amir H. Meghdadi;Pourang Irani","http://dx.doi.org/10.1109/TVCG.2013.168","10.1109/INFVIS.2004.27;10.1109/TVCG.2012.222;10.1109/VISUAL.2003.1250401",260
"10.1109/TVCG.2013.186","ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering","Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",2013,"The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.","Harald Bosch;Dennis Thom;Florian Heimerl;Edwin Puttmann;Steffen Koch;Robert Krüger;Michael Wörner;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2013.186","10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",261
"10.1109/TVCG.2013.188","Semantics of Directly Manipulating Spatializations","Visual to parametric interaction, visual analytics, statistical models",2013,"When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.","Xinran Hu;Lauren Bradel;Dipayan Maiti;Leanna House;Chris North;Scotland Leman","http://dx.doi.org/10.1109/TVCG.2013.188","10.1109/VAST.2011.6102449;10.1109/INFVIS.1995.528686;10.1109/TVCG.2012.260;10.1109/VAST.2012.6400486;10.1109/VAST.2008.4677358",262
"10.1109/TVCG.2013.193","Space Transformation for Understanding Group Movement","Visual analytics, movement data, collective movement",2013,"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.","Natalia V. Andrienko;Gennady L. Andrienko;Louise Barrett;Marcus Dostie;S. Peter Henzi","http://dx.doi.org/10.1109/TVCG.2013.193","10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.27",263
"10.1109/TVCG.2013.197","Supporting Awareness through Collaborative Brushing and Linking of Tabular Data","Collaboration, awareness, attentionally ambient visualization, brushing and linking, linked views, user study",2013,"Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing & linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing & linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.","Amir Hossein Hajizadeh;Melanie Tory;Rock Leung","http://dx.doi.org/10.1109/TVCG.2013.197","10.1109/TVCG.2011.196;10.1109/TVCG.2007.70541;10.1109/TVCG.2011.185;10.1109/VAST.2010.5652880;10.1109/INFVIS.2003.1249020;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102447",264
"10.1109/TVCG.2013.198","Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes","Dynamic networks, visualization, supergraph clustering",2013,"The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.","Steffen Hadlak;Heidrun Schumann;Clemens H. Cap;Till Wollenberg","http://dx.doi.org/10.1109/TVCG.2013.198","10.1109/INFVIS.2005.1532151;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.18;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213;10.1109/TVCG.2006.193;10.1109/VAST.2012.6400493;10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70529;10.1109/INFVIS.2002.1173160",265
"10.1109/TVCG.2013.200","Temporal Event Sequence Simplification","Event sequences, simplification, electronic heath records, temporal query",2013,"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.","Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman","http://dx.doi.org/10.1109/TVCG.2013.200","10.1109/TVCG.2009.117;10.1109/TVCG.2012.213;10.1109/VAST.2010.5652890",266
"10.1109/TVCG.2013.206","TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data","Visual Analytics, information visualization, toolkits, software infrastructure, time, temporal data",2013,"Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.","Alexander Rind;Tim Lammarsch;Wolfgang Aigner;Bilal Alsallakh;Silvia Miksch","http://dx.doi.org/10.1109/TVCG.2013.206","10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102446;10.1109/VAST.2006.261428;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.144;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.64;10.1109/TVCG.2013.222;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.185;10.1109/TVCG.2010.126;10.1109/INFVIS.1997.636792",267
"10.1109/TVCG.2013.207","Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop","Visual knowledge discovery, data clustering, machine learning, multimedia visualization",2013,"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.","Philip A. Legg;David H. S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen","http://dx.doi.org/10.1109/TVCG.2013.207","10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208",268
"10.1109/TVCG.2013.211","Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design","Visual analytics, sense-making, dataframe mode, evaluation, reasoning, analysis, interaction, interface design",2013,"This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.","Neesha Kodagoda;Simon Attfield;B. L. William Wong;Chris Rooney;Sharmin (Tinni) Choudhury","http://dx.doi.org/10.1109/TVCG.2013.211","10.1109/VAST.2009.5333020;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.252",269
"10.1109/TVCG.2013.212","UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization","Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics

",2013,"Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.","Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park","http://dx.doi.org/10.1109/TVCG.2013.212","10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443",270
"10.1109/TVCG.2013.219","Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations","Cultural heritage, wall paintings, degradation, visual analytics",2013,"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.","Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;E. Yanli","http://dx.doi.org/10.1109/TVCG.2013.219","10.1109/TVCG.2011.239;10.1109/INFVIS.2004.1;10.1109/TVCG.2008.173;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2012.244;10.1109/VAST.2007.4389013;10.1109/TVCG.2008.153;10.1109/INFVIS.2000.885098",271
"10.1109/TVCG.2013.220","Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System","Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities",2013,"Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","Rachel Shadoan;Chris Weaver","http://dx.doi.org/10.1109/TVCG.2013.220","10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520",272
"10.1109/TVCG.2013.221","Visual Analysis of Topic Competition on Social Media","Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",2013,"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.","Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2013.221","10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851",273
"10.1109/TVCG.2013.222","Visual Analytics for Model Selection in Time Series Analysis","Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views",2013,"Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.","Markus Bögl;Wolfgang Aigner;Peter Filzmoser;Tim Lammarsch;Silvia Miksch;Alexander Rind","http://dx.doi.org/10.1109/TVCG.2013.222","10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539",274
"10.1109/TVCG.2013.223","Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists","Design study, user-centered design, node-link diagrams, multimodal graphs, interaction, qualitative evaluation",2013,"Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.","Sohaib Ghani;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Niklas Elmqvist","http://dx.doi.org/10.1109/TVCG.2013.223","10.1109/TVCG.2011.247;10.1109/VAST.2011.6102440;10.1109/TVCG.2012.213;10.1109/TVCG.2011.201;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70521;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173155;10.1109/VAST.2006.261430;10.1109/TVCG.2006.166;10.1109/TVCG.2011.209",275
"10.1109/TVCG.2013.224","Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration","Heuristic-based spatial clustering, interactive visual clustering, k-order a-(alpha)-shapes",2013,"We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.","Eli Packer;Peter Bak;Mikko Nikkilä;Valentin Polishchuk;Harold J. Ship","http://dx.doi.org/10.1109/TVCG.2013.224","10.1109/VAST.2011.6102449;10.1109/INFVIS.2003.1249015;10.1109/VAST.2012.6400486;10.1109/TVCG.2009.122;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.186",276
"10.1109/TVCG.2013.226","Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips","Spatio-temporal queries, urban data, taxi movement data, visual exploration",2013,"As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.","Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2013.226","10.1109/INFVIS.2004.12;10.1109/VAST.2008.4677356;10.1109/VAST.2011.6102454;10.1109/TVCG.2007.70535;10.1109/VAST.2010.5652467;10.1109/INFVIS.2005.1532150;10.1109/VAST.2008.4677370;10.1109/INFVIS.2000.885086",277
"10.1109/TVCG.2013.228","Visual Traffic Jam Analysis Based on Trajectory Data","Traffic visualization, traffic jam propagation",2013,"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.","Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering","http://dx.doi.org/10.1109/TVCG.2013.228","10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455",278
"10.1109/TVCG.2014.2346248","UpSet: Visualization of Intersecting Sets","Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data",2014,"Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.","Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2014.2346248","10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183",279
"10.1109/TVCG.2014.2346249","OnSet: A Visualization Technique for Large-scale Binary Set Data","Set visualization, information visualization, direct manipulation, Euler diagrams, interaction, logical operations",2014,"Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.","Ramik Sadana;Timothy Major;Alistair D. M. Dove;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2014.2346249","10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/TVCG.2013.184",280
"10.1109/TVCG.2014.2346250","DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation","Time navigation, direct manipulation, information visualization",2014,"We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.","Brittany Kondo;Christopher Collins","http://dx.doi.org/10.1109/TVCG.2014.2346250","10.1109/TVCG.2013.147;10.1109/TVCG.2012.204;10.1109/TVCG.2012.260;10.1109/TVCG.2008.175;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.265;10.1109/TVCG.2013.149;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2008.125;10.1109/TVCG.2011.195",281
"10.1109/TVCG.2014.2346258","Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots","Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection",2014,"Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.","Manuel Rubio-Sánchez;Alberto Sanchez","http://dx.doi.org/10.1109/TVCG.2014.2346258","10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663916",282
"10.1109/TVCG.2014.2346260","Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets","Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data",2014,"Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.","Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit","http://dx.doi.org/10.1109/TVCG.2014.2346260","10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2012.207;10.1109/TVCG.2011.250;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.173;10.1109/TVCG.2011.183;10.1109/TVCG.2013.160;10.1109/TVCG.2011.201;10.1109/TVCG.2006.166;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2004.15;10.1109/TVCG.2007.70521",283
"10.1109/TVCG.2014.2346265","Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data","Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis",2014,"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.","Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes","http://dx.doi.org/10.1109/TVCG.2014.2346265","10.1109/TVCG.2013.173;10.1109/TVCG.2011.178;10.1109/TVCG.2013.226;10.1109/TVCG.2011.197;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.149;10.1109/INFVIS.2004.12;10.1109/TVCG.2012.256;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677350;10.1109/TVCG.2008.125;10.1109/TVCG.2013.122",284
"10.1109/TVCG.2014.2346271","Origin-Destination Flow Data Smoothing and Mapping","flow mapping, kernel smoothing, generalization, multi-resolution mapping, graph drawing, spatial data mining",2014,"This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.","Diansheng Guo;Xi Zhu","http://dx.doi.org/10.1109/TVCG.2014.2346271","10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2011.202;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/VISUAL.2005.1532819",285
"10.1109/TVCG.2014.2346276","Nmap: A Novel Neighborhood Preservation Space-filling Algorithm","Space-filling techniques, treemaps, distance-similarity preservation",2014,"Space-filling techniques seek to use as much as possible the visual space to represent a dataset, splitting it into regions that represent the data elements. Amongst those techniques, Treemaps have received wide attention due to its simplicity, reduced visual complexity, and compact use of the available space. Several different Treemap algorithms have been proposed, however the core idea is the same, to divide the visual space into rectangles with areas proportional to some data attribute or weight. Although pleasant layouts can be effectively produced by the existing techniques, most of them do not take into account relationships that might exist between different data elements when partitioning the visual space. This violates the distance-similarity metaphor, that is, close rectangles do not necessarily represent similar data elements. In this paper, we propose a novel approach, called Neighborhood Treemap (Nmap), that seeks to solve this limitation by employing a slice and scale strategy where the visual space is successively bisected on the horizontal or vertical directions and the bisections are scaled until one rectangle is defined per data element. Compared to the current techniques with the same similarity preservation goal, our approach presents the best results while being two to three orders of magnitude faster. The usefulness of Nmap is shown by two applications involving the organization of document collections and the construction of cartograms illustrating its effectiveness on different scenarios.","Felipe S. L. G. Duarte;Fabio Sikansi;Francisco M. Fatore;Samuel G. Fadel;Fernando Vieira Paulovich","http://dx.doi.org/10.1109/TVCG.2014.2346276","10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/TVCG.2007.70522;10.1109/TVCG.2009.128;10.1109/TVCG.2007.70529;10.1109/VISUAL.1991.175815;10.1109/TVCG.2008.165",286
"10.1109/TVCG.2014.2346277","Tree Colors: Color Schemes for Tree-Structured Data","Color schemes, statistical graphics, hierarchical data",2014,"We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.","Martijn Tennekes;Edwin de Jonge","http://dx.doi.org/10.1109/TVCG.2014.2346277","10.1109/TVCG.2011.193;10.1109/INFVIS.2000.885091;10.1109/INFVIS.2002.1173151",287
"10.1109/TVCG.2014.2346291","iVisDesigner: Expressive Interactive Design of Information Visualizations","Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization",2014,"We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.","Donghao Ren;Tobias Höllerer;Xiaoru Yuan","http://dx.doi.org/10.1109/TVCG.2014.2346291","10.1109/INFVIS.2004.12;10.1109/TVCG.2010.144;10.1109/TVCG.2009.179;10.1109/TVCG.2009.174;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.126;10.1109/TVCG.2013.191;10.1109/INFVIS.1997.636792;10.1109/TVCG.2011.201;10.1109/TVCG.2011.261;10.1109/TVCG.2012.275;10.1109/INFVIS.1997.636761",288
"10.1109/TVCG.2014.2346292","Constructing Visual Representations: Investigating the Use of Tangible Tokens","Constructive visualization, Physical visualization, Dynamic visualization, Empirical study, Token, Visualization authoring, Information visualization, Visual mapping, Novices, Visualization construction, Visual analytics",2014,"The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.","Samuel Huron;Yvonne Jansen;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2014.2346292","10.1109/TVCG.2009.176;10.1109/TVCG.2011.185;10.1109/TVCG.2013.227;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2011.251;10.1109/VISUAL.1997.663890;10.1109/TVCG.2012.275;10.1109/TVCG.2013.134;10.1109/TVCG.2010.164;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.199",289
"10.1109/TVCG.2014.2346293","PanoramicData: Data Analysis through Pen & Touch","Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views",2014,"Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.","Emanuel Zgraggen;Robert C. Zeleznik;Steven M. Drucker","http://dx.doi.org/10.1109/TVCG.2014.2346293","10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.162;10.1109/TVCG.2010.164;10.1109/TVCG.2011.251;10.1109/TVCG.2013.191;10.1109/TVCG.2012.275;10.1109/VAST.2007.4389013;10.1109/TVCG.2013.150;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.137;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70594;10.1109/TVCG.2012.204",290
"10.1109/TVCG.2014.2346297","Visualizing Statistical Mix Effects and Simpson's Paradox","Mix effects, Omitted variable bias, Simpson's paradox, Statistics",2014,"We discuss how ÔÇ£mix effectsÔÇØ can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as ÔÇ£omitted variable biasÔÇØ or, in extreme cases, as ÔÇ£Simpson's paradoxÔÇØ) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the ÔÇ£comet chart,ÔÇØ that is meant to ameliorate some of these issues.","Zan Armstrong;Martin Wattenberg","http://dx.doi.org/10.1109/TVCG.2014.2346297","10.1109/TVCG.2012.213;10.1109/TVCG.2007.70577",291
"10.1109/TVCG.2014.2346311","MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data","Information visualization, Design study, Human-Computer Interaction",2014,"In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.","Gregorio Palmas;Myroslav Bachynskyi;Antti Oulasvirta;Hans-Peter Seidel;Tino Weinkauf","http://dx.doi.org/10.1109/TVCG.2014.2346311","10.1109/TVCG.2009.152;10.1109/TVCG.2012.213;10.1109/TVCG.2012.204;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2004.12",292
"10.1109/TVCG.2014.2346321","Visual Parameter Space Analysis: A Conceptual Framework","Parameter space analysis, input-output model, simulation, task characterization, literature analysis",2014,"Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.","Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2014.2346321","10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253",293
"10.1109/TVCG.2014.2346323","Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization","Movement visualization, visual analytics, bikeshare, impact, visualization models, design study",2014,"We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.","Jo Wood;Roger Beecham;Jason Dykes","http://dx.doi.org/10.1109/TVCG.2014.2346323","10.1109/TVCG.2012.272;10.1109/TVCG.2012.262;10.1109/TVCG.2012.213;10.1109/TVCG.2011.175;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/TVCG.2013.132;10.1109/INFVIS.2004.59;10.1109/TVCG.2011.209;10.1109/TVCG.2013.145;10.1109/TVCG.2008.127",294
"10.1109/TVCG.2014.2346325","An Algebraic Process for Visualization Design","Visualization Design, Symmetries, Visualization Theory",2014,"We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.","Gordon L. Kindlmann;Carlos Eduardo Scheidegger","http://dx.doi.org/10.1109/TVCG.2014.2346325","10.1109/TVCG.2013.173;10.1109/INFVIS.1999.801860;10.1109/TVCG.2010.132;10.1109/TVCG.2010.199;10.1109/VISUAL.1996.568118;10.1109/TVCG.2013.124;10.1109/TVCG.2009.125;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594;10.1109/TVCG.2013.119;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2004.59;10.1109/VISUAL.1996.567784;10.1109/TVCG.2013.126;10.1109/TVCG.2008.121;10.1109/TVCG.2012.230;10.1109/TVCG.2010.161",295
"10.1109/TVCG.2014.2346331","Design Activity Framework for Visualization Design","Design, frameworks, process, cybersecurity, nested model, decisions, models, evaluation, visualization",2014,"An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.","Sean McKenna;Dominika Mazur;James Agutter;Miriah D. Meyer","http://dx.doi.org/10.1109/TVCG.2014.2346331","10.1109/TVCG.2012.213;10.1109/TVCG.2011.209;10.1109/TVCG.2009.111;10.1109/TVCG.2013.126;10.1109/TVCG.2013.145",296
"10.1109/TVCG.2014.2346420","Comparative Eye Tracking Study on Node-Link Visualizations of Trajectories","User study, eye tracking, evaluation, trajectory visualization, node-link visualization, direction encoding, node splatting, halo rendering",2014,"We present the results of an eye tracking study that compares different visualization methods for long, dense, complex, and piecewise linear spatial trajectories. Typical sources of such data are from temporally discrete measurements of the positions of moving objects, for example, recorded GPS tracks of animals in movement ecology. In the repeated-measures within-subjects user study, four variants of node-link visualization techniques are compared, with the following representations of directed links: standard arrow, tapered, equidistant arrows, and equidistant comets. In addition, we investigate the effect of rendering order for the halo visualization of those links as well as the usefulness of node splatting. All combinations of link visualization techniques are tested for different trajectory density levels. We used three types of tasks: tracing of paths, identification of longest links, and estimation of the density of trajectory clusters. Results are presented in the form of the statistical evaluation of task completion time, task solution accuracy, and two eye tracking metrics. These objective results are complemented by a summary of subjective feedback from the participants. The main result of our study is that tapered links perform very well. However, we discuss that equidistant comets and equidistant arrows are a good option to perceive direction information independent of zoom-level of the display.","Rudolf Netzel;Michael Burch;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2014.2346420","10.1109/INFVIS.2004.1;10.1109/TVCG.2011.193;10.1109/TVCG.2011.226",297
"10.1109/TVCG.2014.2346422","Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation","graphs, networks, maps, scatter plots",2014,"Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.","Bahador Saket;Paolo Simonetto;Stephen G. Kobourov;Katy Börner","http://dx.doi.org/10.1109/TVCG.2014.2346422","10.1109/INFVIS.2003.1249011;10.1109/TVCG.2011.186;10.1109/TVCG.2008.155;10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70596;10.1109/TVCG.2009.122;10.1109/TVCG.2013.187;10.1109/TVCG.2013.124",298
"10.1109/TVCG.2014.2346424","The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking","Animated transitions, staggered animation, visual tracking",2014,"Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.","Fanny Chevalier;Pierre Dragicevic;Steven Franconeri","http://dx.doi.org/10.1109/TVCG.2014.2346424","10.1109/TVCG.2012.199;10.1109/INFVIS.1999.801854;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539",299
"10.1109/TVCG.2014.2346426","The Influence of Contour on Similarity Perception of Star Glyphs","Glyphs, star glyphs, contours, perception, quantitative evaluation, similarity detection, visual comparison",2014,"We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyp- s.","Johannes Fuchs;Petra Isenberg;Anastasia Bezerianos;Fabian Fischer;Enrico Bertini","http://dx.doi.org/10.1109/TVCG.2014.2346426","10.1109/TVCG.2012.220;10.1109/TVCG.2008.136;10.1109/TVCG.2011.242;10.1109/INFVIS.2004.15",300
"10.1109/TVCG.2014.2346428","Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection","Orders of magnitude, bar charts, logarithmic scale",2014,"In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types.","Rita Borgo;Joel Dearden;Mark W. Jones","http://dx.doi.org/10.1109/TVCG.2014.2346428","10.1109/TVCG.2013.187;10.1109/TVCG.2012.229;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.160;10.1109/TVCG.2010.130;10.1109/TVCG.2013.234",301
"10.1109/TVCG.2014.2346431","Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists","Design study, investigative journalism, task and requirements analysis, text and document data, text analysis",2014,"For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system ÔÇ£in the wildÔÇØ, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of ÔÇ£exploringÔÇØ a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.","Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2014.2346431","10.1109/TVCG.2009.127;10.1109/INFVIS.2004.19;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2012.260;10.1109/TVCG.2009.140;10.1109/TVCG.2013.162;10.1109/TVCG.2013.153;10.1109/TVCG.2009.148;10.1109/TVCG.2013.124;10.1109/TVCG.2011.239;10.1109/VAST.2010.5652940;10.1109/TVCG.2011.209",302
"10.1109/TVCG.2014.2346433","How Hierarchical Topics Evolve in Large Text Corpora","Hierarchical topic visualization, evolutionary tree clustering, data transformation",2014,"Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.","Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei","http://dx.doi.org/10.1109/TVCG.2014.2346433","10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200",303
"10.1109/TVCG.2014.2346435","Exploring the Placement and Design of Word-Scale Visualizations","Information visualization, text visualization, sparklines, glyphs, design space, word-scale visualizations",2014,"We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.","Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg","http://dx.doi.org/10.1109/TVCG.2014.2346435","10.1109/TVCG.2013.192;10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70589;10.1109/TVCG.2011.183;10.1109/TVCG.2013.120;10.1109/TVCG.2010.194;10.1109/INFVIS.2005.1532144",304
"10.1109/TVCG.2014.2346441","Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations","Multivariate Networks, Selections of Interest, Interaction, Direct Manipulation",2014,"Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.","Stef van den Elzen;Jarke J. van Wijk","http://dx.doi.org/10.1109/TVCG.2014.2346441","10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.122;10.1109/TVCG.2009.145;10.1109/TVCG.2013.223;10.1109/VAST.2007.4389013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.153;10.1109/TVCG.2009.108;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147",305
"10.1109/TVCG.2014.2346444","GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration","Graph-level operations, graph visualization, visualization technique specification, graph analysis, information visualization",2014,"The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.","Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin 0001;Florian Foerster;Aakash Goel;John T. Stasko;Duen Horng Chau","http://dx.doi.org/10.1109/TVCG.2014.2346444","10.1109/TVCG.2008.137;10.1109/VAST.2011.6102441;10.1109/TVCG.2010.144;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/VAST.2011.6102440;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/TVCG.2010.205;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.233;10.1109/TVCG.2011.185;10.1109/TVCG.2006.166;10.1109/TVCG.2009.108;10.1109/TVCG.2013.192",306
"10.1109/TVCG.2014.2346445","TenniVis: Visualization for Tennis Match Analysis","Visual knowledge discovery, sports analytics, tennis visualization",2014,"Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.","Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao","http://dx.doi.org/10.1109/TVCG.2014.2346445","10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/VISUAL.2001.964496;10.1109/INFVIS.1996.559229;10.1109/INFVIS.2002.1173148",307
"10.1109/TVCG.2014.2346454","LiveGantt: Interactively Visualizing a Large Manufacturing Schedule","Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation",2014,"In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.","Jaemin Jo;Jaeseok Huh;Jonghun Park;Bo Hyoung Kim;Jinwook Seo","http://dx.doi.org/10.1109/TVCG.2014.2346454","10.1109/TVCG.2013.200;10.1109/TVCG.2012.213;10.1109/TVCG.2009.117;10.1109/TVCG.2012.225",308
"10.1109/TVCG.2014.2346978","Learning Perceptual Kernels for Visualization Design","Visualization, design, encoding, perception, model, crowdsourcing, automated visualization, visual embedding",2014,"Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.","Çagatay Demiralp;Michael S. Bernstein;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2014.2346978","10.1109/TVCG.2010.186;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70583;10.1109/TVCG.2008.125;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70539",309
"10.1109/TVCG.2014.2346979","Ranking Visualizations of Correlation Using Weber's Law","Perception, Visualization, Evaluation",2014,"Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.","Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang","http://dx.doi.org/10.1109/TVCG.2014.2346979","10.1109/TVCG.2013.187;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594",310
"10.1109/TVCG.2014.2346983","The relation between visualization size, grouping, and user performance","information visualization, graphical perception, size, layout",2014,"In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (ÔÇ£pop-outÔÇØ), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.","Connor Gramazio;Karen B. Schloss;David H. Laidlaw","http://dx.doi.org/10.1109/TVCG.2014.2346983","10.1109/TVCG.2012.233;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/VAST.2007.4389009;10.1109/TVCG.2013.187;10.1109/TVCG.2011.175;10.1109/TVCG.2013.183;10.1109/TVCG.2006.184;10.1109/TVCG.2010.186;10.1109/VISUAL.1996.568118;10.1109/TVCG.2012.220;10.1109/TVCG.2013.170;10.1109/TVCG.2013.234",311
"10.1109/TVCG.2014.2352953","Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity","Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change",2014,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.","Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz","http://dx.doi.org/10.1109/TVCG.2014.2352953","10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031;10.1109/TVCG.2013.134",312
"10.1109/TVCG.2014.2346318","ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization","Domain-specific languages, Volume visualization, Volume visualization framework",2014,"Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.","Peter Rautek;Stefan Bruckner;Eduard Gröller;Markus Hadwiger","http://dx.doi.org/10.1109/TVCG.2014.2346318","10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.174;10.1109/TVCG.2014.2346322;10.1109/VISUAL.2004.95;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1992.235202;10.1109/TVCG.2008.184",313
"10.1109/TVCG.2014.2346412","A Robust Parity Test for Extracting Parallel Vectors in 3D","Parallel vectors, feature curve extraction, ridges and valleys, parity test",2014,"Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.","Tao Ju;Minxin Cheng;Xu Wang;Ye Duan","http://dx.doi.org/10.1109/TVCG.2014.2346412","10.1109/VISUAL.2002.1183786;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1999.809896",314
"10.1109/TVCG.2014.2346415","Vortex Cores of Inertial Particles","Inertial particles, flow visualization, vortex cores",2014,"The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.","Tobias Günther;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2014.2346415","10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296",315
"10.1109/TVCG.2014.2346416","FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis","Flow visualization, Topic model, Latent Dirichlet allocation (LDA)",2014,"In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.","Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li","http://dx.doi.org/10.1109/TVCG.2014.2346416","10.1109/TVCG.2008.131;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2006.165;10.1109/TVCG.2008.116;10.1109/TVCG.2006.164;10.1109/TVCG.2010.190;10.1109/TVCG.2011.246;10.1109/TVCG.2008.167;10.1109/TVCG.2009.112;10.1109/TVCG.2010.170;10.1109/TVCG.2013.133",316
"10.1109/TVCG.2014.2346442","Escape Maps","Streamline behavior, vector field topology, isocline surfaces, coronal hole extraction",2014,"We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.","Gustavo Mello Machado;Filip Sadlo;Thomas Müller 0005;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2014.2346442","10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2003.1250376",317
"10.1109/TVCG.2014.2346448","Multi-Charts for Comparative 3D Ensemble Visualization","Ensemble visualization, brushing and linking, statistical analysis",2014,"A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.","Ismail Demir;Christian Dick;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2014.2346448","10.1109/TVCG.2013.143;10.1109/VISUAL.2000.885739;10.1109/TVCG.2006.159;10.1109/TVCG.2008.139;10.1109/TVCG.2007.70518;10.1109/TVCG.2010.181;10.1109/TVCG.2009.198;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809921",318
"10.1109/TVCG.2014.2346455","Curve Boxplot: Generalization of Boxplot for Ensembles of Curves","Uncertainty visualization, boxplots, ensemble visualization, order statistics, data depth, nonparametric statistic, functional data, parametric curves",2014,"In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.","Mahsa Mirzargar;Ross T. Whitaker;Robert Michael Kirby","http://dx.doi.org/10.1109/TVCG.2014.2346455","10.1109/TVCG.2013.143;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1996.568105;10.1109/TVCG.2013.141;10.1109/TVCG.2010.212;10.1109/TVCG.2013.126;10.1109/TVCG.2010.181",319
"10.1109/TVCG.2014.2346481","Knowledge Generation Model for Visual Analytics","Visual Analytics, Knowledge Generation, Reasoning, Visualization Taxonomies and Models, Interaction",2014,"Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.","Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim","http://dx.doi.org/10.1109/TVCG.2014.2346481","10.1109/VISUAL.2005.1532781;10.1109/TVCG.2013.124;10.1109/VAST.2009.5333023;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677365;10.1109/VAST.2010.5652879;10.1109/TVCG.2012.273;10.1109/VAST.2008.4677358;10.1109/TVCG.2008.121;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102435;10.1109/TVCG.2013.120",320
"10.1109/TVCG.2014.2346482","INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data","Predictive modeling, feature selection, classification, visual analytics, high-dimensional data",2014,"Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.","Josua Krause;Adam Perer;Enrico Bertini","http://dx.doi.org/10.1109/TVCG.2014.2346482","10.1109/INFVIS.2004.71;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2011.229;10.1109/VAST.2011.6102448;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102453;10.1109/TVCG.2013.125;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652443",321
"10.1109/TVCG.2014.2346572","Transforming Scagnostics to Reveal Hidden Features","Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics",2014,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.","Dang Tuan Nhon;Leland Wilkinson","http://dx.doi.org/10.1109/TVCG.2014.2346572","10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.187;10.1109/TVCG.2011.167;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006",322
"10.1109/TVCG.2014.2346573","Supporting Communication and Coordination in Collaborative Sensemaking","Sensemaking, Collaboration, Externalization, Linked common work, Collaborative thinking space",2014,"When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.","Narges Mahyar;Melanie Tory","http://dx.doi.org/10.1109/TVCG.2014.2346573","10.1109/VAST.2009.5333245;10.1109/VAST.2006.261439;10.1109/VAST.2008.4677358;10.1109/TVCG.2013.197;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878;10.1109/VAST.2006.261430;10.1109/VAST.2007.4389011;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102447",323
"10.1109/TVCG.2014.2346575","Finding Waldo: Learning about Users from their Interactions","User Interactions, Analytic Provenance, Visualization, Applied Machine Learning",2014,"Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.","Eli T. Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang","http://dx.doi.org/10.1109/TVCG.2014.2346575","10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352",324
"10.1109/TVCG.2014.2346578","Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations","Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision",2014,"An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.","Thomas Mühlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit","http://dx.doi.org/10.1109/TVCG.2014.2346578","10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229",325
"10.1109/TVCG.2014.2346591","Interactive Visual Analysis of Image-Centric Cohort Study Data","Interactive Visual Analysis, Epidemiology, Spine",2014,"Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.","Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim","http://dx.doi.org/10.1109/TVCG.2014.2346591","10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569",326
"10.1109/TVCG.2014.2346594","Visual Abstraction and Exploration of Multi-class Scatterplots","Scatterplot, overdraw reduction, sampling, visual abstraction",2014,"Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.","Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma","http://dx.doi.org/10.1109/TVCG.2014.2346594","10.1109/TVCG.2013.150;10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745301;10.1109/TVCG.2008.120;10.1109/TVCG.2010.197;10.1109/TVCG.2006.187;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.180;10.1109/INFVIS.2004.52;10.1109/VAST.2010.5652460;10.1109/TVCG.2009.112;10.1109/TVCG.2009.122;10.1109/TVCG.2011.181;10.1109/TVCG.2012.238;10.1109/TVCG.2010.176;10.1109/TVCG.2013.212;10.1109/TVCG.2011.261;10.1109/TVCG.2008.153;10.1109/TVCG.2013.183",327
"10.1109/TVCG.2014.2346626","Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees","Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis",2014,"Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.","Michael Beham;Wolfgang Herzner;Eduard Gröller;Johannes Kehrer","http://dx.doi.org/10.1109/TVCG.2014.2346626","10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581",328
"10.1109/TVCG.2014.2346660","Visual Methods for Analyzing Probabilistic Classification Data","Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection",2014,"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.","Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber","http://dx.doi.org/10.1109/TVCG.2014.2346660","10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5332628;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.184;10.1109/TVCG.2012.254;10.1109/VAST.2011.6102448;10.1109/VAST.2011.6102453;10.1109/VAST.2012.6400492;10.1109/VAST.2010.5652443",329
"10.1109/TVCG.2014.2346665","A Five-Level Design Framework for Bicluster Visualizations","Biclusters, interactive visual analytics, coordinated relationships, design framework",2014,"Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.","Maoyuan Sun;Chris North;Naren Ramakrishnan","http://dx.doi.org/10.1109/TVCG.2014.2346665","10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582",330
"10.1109/TVCG.2014.2346677","VarifocalReader -- In-Depth Visual Analysis of Large Text Documents","visual analytics, document analysis, literary analysis, natural language processing, text mining, machine learning, distant reading",2014,"Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.","Steffen Koch;Markus John;Michael Wörner;Andreas Müller;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2014.2346677","10.1109/VAST.2010.5652926;10.1109/TVCG.2008.172;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.188;10.1109/TVCG.2007.70577;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/TVCG.2009.165;10.1109/TVCG.2013.162;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333248;10.1109/TVCG.2012.260;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333919;10.1109/VAST.2007.4389004",331
"10.1109/TVCG.2014.2346743","Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking","discovery search visualization, visual cues, discoverage, coverage tracking, document triage, interactive histograms",2014,"Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity ÔÇ£discoverage,ÔÇØ discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.","Ellen Isaacs;Kelly Domico;Shane Ahern;Eugene Bart;Mudita Singhal","http://dx.doi.org/10.1109/TVCG.2014.2346743","10.1109/VAST.2009.5333443;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4389006;10.1109/INFVIS.2001.963287;10.1109/TVCG.2007.70589;10.1109/VAST.2006.261426;10.1109/TVCG.2007.70577",332
"10.1109/TVCG.2014.2346746","Visual Exploration of Sparse Traffic Trajectory Data","Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion",2014,"In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.","Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu","http://dx.doi.org/10.1109/TVCG.2014.2346746","10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265",333
"10.1109/TVCG.2014.2346747","DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios","visual analytics, portfolio mining, web-based visualization, casual visualization, design study",2014,"We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.","Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri","http://dx.doi.org/10.1109/TVCG.2014.2346747","10.1109/TVCG.2007.70541;10.1109/TVCG.2011.174;10.1109/TVCG.2010.177;10.1109/TVCG.2012.255;10.1109/TVCG.2009.123;10.1109/TVCG.2013.223;10.1109/INFVIS.2001.963283;10.1109/TVCG.2012.213;10.1109/VAST.2008.4677361",334
"10.1109/TVCG.2014.2346752","ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery","Multi-relational data, visual data analysis, drug discovery",2014,"Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.","Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg","http://dx.doi.org/10.1109/TVCG.2014.2346752","10.1109/TVCG.2013.167;10.1109/TVCG.2012.213;10.1109/TVCG.2012.252;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/TVCG.2013.223",335
"10.1109/TVCG.2014.2346753","Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks","Web-based visualization, gene regulatory network",2014,"Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).","Bowen Yu;Harish Doraiswamy;Xi Chen;Emily R. Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2014.2346753","10.1109/TVCG.2008.117;10.1109/TVCG.2009.146;10.1109/TVCG.2011.185;10.1109/TVCG.2009.167",336
"10.1109/TVCG.2014.2346754","The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals","Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies",2014,"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the cur- ent workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.","Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;Eduard Gröller;Kresimir Matkovic","http://dx.doi.org/10.1109/TVCG.2014.2346754","10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.155;10.1109/VISUAL.1995.485139",337
"10.1109/TVCG.2014.2346755","Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling","Similarity, clustering, matrix, optimization, climate model",2014,"Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.","Jorge Poco;Aritra Dasgupta;Yaxing Wei;William W. Hargrove;Christopher R. Schwalm;Deborah N. Huntzinger;Robert B. Cook;Enrico Bertini;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2014.2346755","10.1109/TVCG.2008.139;10.1109/TVCG.2012.256;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.157;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.188;10.1109/TVCG.2013.224;10.1109/VAST.2008.4677350;10.1109/TVCG.2013.120",338
"10.1109/TVCG.2014.2346893","Visualizing Mobility of Public Transportation System","Mobility, public transportation, visual analytics",2014,"Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.","Wei Zeng;Chi-Wing Fu;Stefan Müller Arisona;Alexander Erath;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2014.2346893","10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.202;10.1109/TVCG.2011.205;10.1109/TVCG.2009.143;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/INFVIS.2005.1532150",339
"10.1109/TVCG.2014.2346898","Visual Analysis of Public Utility Service Problems in a Metropolis","utility services, evidence-based decision making, visual analytics, aggregate",2014,"Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.","Jiawan Zhang;E. Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan","http://dx.doi.org/10.1109/TVCG.2014.2346898","10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400556;10.1109/TVCG.2013.228;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677356;10.1109/TVCG.2012.291;10.1109/TVCG.2013.132;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/VAST.2011.6102460;10.1109/TVCG.2009.122",340
"10.1109/TVCG.2014.2346911","VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure","Computational steering, visual analytics, critical infrastructure, homeland security",2014,"We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.","Sungahn Ko;Jieqiong Zhao;Jing Xia;Shehzad Afzal;Xiaoyu Wang;Greg Abram;Niklas Elmqvist;Len Kne;David Van Riper;Kelly P. Gaither;Shaun Kennedy;William J. Tolone;William Ribarsky;David S. Ebert","http://dx.doi.org/10.1109/TVCG.2014.2346911","10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.225;10.1109/TVCG.2012.260;10.1109/TVCG.2007.70541;10.1109/TVCG.2010.223;10.1109/TVCG.2013.146;10.1109/TVCG.2010.171;10.1109/VAST.2011.6102460;10.1109/VAST.2011.6102457",341
"10.1109/TVCG.2014.2346912","LoyalTracker: Visualizing Loyalty Dynamics in Search Engines","Time-series visualization, stacked graphs, log data visualization, text visualization",2014,"The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.","Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2014.2346912","10.1109/VAST.2010.5652931;10.1109/TVCG.2009.171;10.1109/VAST.2007.4389008;10.1109/TVCG.2012.253;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2012.225;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400494;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.166",342
"10.1109/TVCG.2014.2346919","EvoRiver: Visual Analysis of Topic Coopetition on Social Media","Topic coopetition, information diffusion, information propagation, time-based visualization",2014,"Cooperation and competition (jointly called ÔÇ£coopetitionÔÇØ) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., ÔÇ£topic leadersÔÇØ) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).","Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang","http://dx.doi.org/10.1109/TVCG.2014.2346919","10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",343
"10.1109/TVCG.2014.2346920","OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media","Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail",2014,"It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.","Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu","http://dx.doi.org/10.1109/TVCG.2014.2346920","10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919",344
"10.1109/TVCG.2014.2346922","#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media","Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization",2014,"We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.","Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins","http://dx.doi.org/10.1109/TVCG.2014.2346922","10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162",345
"10.1109/TVCG.2014.2346926","Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement","Visual Analytics, Natural Scales, Seasonal Trend decomposition based on Loess (STL), Law Enforcement",2014,"In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.","Abish Malik;Ross Maciejewski;Sherry Towers;Sean McCullough;David S. Ebert","http://dx.doi.org/10.1109/TVCG.2014.2346926","10.1109/TVCG.2013.125;10.1109/TVCG.2013.206;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.200",346
"10.1109/VAST.2014.7042476","Towards Interactive, Intelligent, and Integrated Multimedia Analytics","Multimedia (image/video/music) visualization, machine learning",2014,"The size and importance of visual multimedia collections grew rapidly over the last years, creating a need for sophisticated multimedia analytics systems enabling large-scale, interactive, and insightful analysis. These systems need to integrate the human's natural expertise in analyzing multimedia with the machine's ability to process large-scale data. The paper starts off with a comprehensive overview of representation, learning, and interaction techniques from both the human's and the machine's point of view. To this end, hundreds of references from the related disciplines (visual analytics, information visualization, computer vision, multimedia information retrieval) have been surveyed. Based on the survey, a novel general multimedia analytics model is synthesized. In the model, the need for semantic navigation of the collection is emphasized and multimedia analytics tasks are placed on the exploration-search axis. The axis is composed of both exploration and search in a certain proportion which changes as the analyst progresses towards insight. Categorization is proposed as a suitable umbrella task realizing the exploration-search axis in the model. Finally, the pragmatic gap, defined as the difference between the tight machine categorization model and the flexible human categorization model is identified as a crucial multimedia analytics topic.","Jan Zahálka;Marcel Worring","http://dx.doi.org/10.1109/VAST.2014.7042476","10.1109/VAST.2006.261425;10.1109/VAST.2007.4389003;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.136;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70541;10.1109/TVCG.2013.168",347
"10.1109/VAST.2014.7042479","A System for Visual Analysis of Radio Signal Data","Intelligence Analysis, Coordinated and Multiple Views, Time-varying data, Geographic/Geospatial Visualization",2014,"Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform.","Tarik Crnovrsanin;Chris Muelder;Kwan-Liu Ma","http://dx.doi.org/10.1109/VAST.2014.7042479","10.1109/TVCG.2012.286;10.1109/VAST.2009.5332596;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1998.745302;10.1109/VAST.2009.5332593",348
"10.1109/VAST.2014.7042480","Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier","View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model",2014,"The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.","Michael Behrisch;Fatih Korkmaz;Lin Shao;Tobias Schreck","http://dx.doi.org/10.1109/VAST.2014.7042480","10.1109/INFVIS.2005.1532142;10.1109/TVCG.2012.277;10.1109/TVCG.2010.184;10.1109/VAST.2012.6400486;10.1109/VAST.2007.4389001;10.1109/TVCG.2013.160;10.1109/VAST.2012.6400488",349
"10.1109/VAST.2014.7042482","An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics","Evaluation methodology, insight-based evaluation, visual analytics, network visualization, information visualization",2014,"We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.","Steven R. Gomez;Hua Guo;Caroline Ziemkiewicz;David H. Laidlaw","http://dx.doi.org/10.1109/VAST.2014.7042482","10.1109/TVCG.2012.233;10.1109/TVCG.2007.70617;10.1109/TVCG.2013.124;10.1109/TVCG.2010.154;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.128;10.1109/TVCG.2011.185;10.1109/TVCG.2010.163;10.1109/TVCG.2013.120",350
"10.1109/VAST.2014.7042483","Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation","Pixel-oriented techniques, task and requirements analysis, multidimensional data, network security and intrusion",2014,"We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the Carpet""). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to defne areas of interest for closer inspection.""","Johannes Landstorfer;Ivo Herrmann;Jan-Erik Stange;Marian Dörk;Reto Wettach","http://dx.doi.org/10.1109/VAST.2014.7042483","10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/VISUAL.1991.175795;10.1109/VAST.2006.261436;10.1109/TVCG.2009.111;10.1109/INFVIS.1995.528685",351
"10.1109/VAST.2014.7042484","Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration","",2014,"This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.","Sungahn Ko;Shehzad Afzal;Simon J. Walton;Yang Yang;Junghoon Chae;Abish Malik;Yun Jang;Min Chen 0001;David S. Ebert","http://dx.doi.org/10.1109/VAST.2014.7042484","10.1109/VAST.2012.6400554;10.1109/TVCG.2010.150;10.1109/TVCG.2007.70582;10.1109/TVCG.2011.190;10.1109/VAST.2011.6102440;10.1109/TVCG.2009.143;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389013",352
"10.1109/VAST.2014.7042485","Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs","Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization",2014,"Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.","Olav Lenz;Frank Keul;Sebastian Bremm;Kay Hamacher;Tatiana von Landesberger","http://dx.doi.org/10.1109/VAST.2014.7042485","10.1109/TVCG.2013.225;10.1109/VAST.2011.6102439;10.1109/VAST.2009.5333893;10.1109/TVCG.2009.167;10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70529",353
"10.1109/VAST.2014.7042487","Using Visualizations to Monitor Changes and Harvest Insights from a Global-Scale Logging Infrastructure at Twitter","Information Visualization, Visual Analytics, Log Analysis, Log Visualization, Session Analysis, Funnel Analysis",2014,"Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter.","Krist Wongsuphasawat;Jimmy J. Lin","http://dx.doi.org/10.1109/VAST.2014.7042487","10.1109/INFVIS.2000.885091;10.1109/TVCG.2009.117;10.1109/INFVIS.1997.636718;10.1109/VAST.2007.4389008;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70529;10.1109/VAST.2012.6400494;10.1109/TVCG.2013.231;10.1109/INFVIS.2004.64;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421;10.1109/TVCG.2011.185",354
"10.1109/VAST.2014.7042489","Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes","climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics",2014,"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.","Jie Li;Kang Zhang;Zhao-Peng Meng","http://dx.doi.org/10.1109/VAST.2014.7042489","10.1109/VAST.2012.6400491;10.1109/TVCG.2010.194;10.1109/INFVIS.2000.885098;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.199;10.1109/TVCG.2010.183;10.1109/VAST.2012.6400553;10.1109/TVCG.2010.180;10.1109/TVCG.2009.197",355
"10.1109/VAST.2014.7042490","BoundarySeer: Visual Analysis of 2D Boundary Changes","Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization",2014,"Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.","Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Eduard Gröller;Lionel M. Ni","http://dx.doi.org/10.1109/VAST.2014.7042490","10.1109/TVCG.2013.230;10.1109/INFVIS.2004.27;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.239;10.1109/TVCG.2008.166;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2013.213;10.1109/TVCG.2012.265;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70561",356
"10.1109/VAST.2014.7042491","YMCA - Your Mesh Comparison Application","Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison",2014,"Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.","Johanna Schmidt;Reinhold Preiner;Thomas Auzinger;Michael Wimmer;Eduard Gröller;Stefan Bruckner","http://dx.doi.org/10.1109/VAST.2014.7042491","10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.213;10.1109/VISUAL.2002.1183790",357
"10.1109/VAST.2014.7042492","Multi-Model Semantic Interaction for Text Analytics","Visual analytics, Semantic Interaction, Sensemaking, Text Analytics",2014,"Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.","Lauren Bradel;Chris North;Leanna House;Scotland Leman","http://dx.doi.org/10.1109/VAST.2014.7042492","10.1109/VAST.2011.6102449;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400559;10.1109/VAST.2012.6400486;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389006",358
"10.1109/VAST.2014.7042493","Serendip: Topic Model-Driven Visual Exploration of Text Corpora","Text visualization, topic modeling",2014,"Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.","Eric C. Alexander;Joe Kohlmann;Robin Valenza;Michael Witmore;Michael Gleicher","http://dx.doi.org/10.1109/VAST.2014.7042493","10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1998.729568;10.1109/TVCG.2011.239;10.1109/TVCG.2011.220;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.157;10.1109/TVCG.2013.162;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389004",359
"10.1109/VAST.2014.7042494","TopicPanorama: A Full Picture of Relevant Topics","Topic graph, graph matching, graph visualization, user interactions, level-of-detail",2014,"We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.","Shixia Liu;Xiting Wang;Jianfei Chen;Jim Zhu;Baining Guo","http://dx.doi.org/10.1109/VAST.2014.7042494","10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919",360
"10.1109/VAST.2014.7042495","Integrating Predictive Analytics and Social Media","Social Media, Predictive Analytics, Feature Selection",2014,"A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.","Yafeng Lu;Robert Krüger;Dennis Thom;Feng Wang;Steffen Koch;Thomas Ertl;Ross Maciejewski","http://dx.doi.org/10.1109/VAST.2014.7042495","10.1109/VAST.2012.6400557;10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/TVCG.2013.125;10.1109/INFVIS.2004.10;10.1109/VAST.2011.6102448;10.1109/VAST.2010.5652443;10.1109/INFVIS.2004.3",361
"10.1109/VAST.2014.7042496","PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media","Personal emotion analytics, affective and mood modeling, social media text, Twitter, information visualization",2014,"Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person's demographics and opinions, but also reveal one's emotional style. Emotional style captures a person's patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one's emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person's emotional style derived from this person's social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person's expressed emotions at different time points and summarize those emotions to reveal the person's emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one's emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results.","Jian Zhao;Liang Gou;Fei Wang;Michelle X. Zhou","http://dx.doi.org/10.1109/VAST.2014.7042496","10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2010.129;10.1109/TVCG.2011.185;10.1109/TVCG.2010.183",362
"10.1109/TVCG.2015.2466971","Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis","Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views",2015,"The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.","Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2015.2466971","10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2008.166;10.1109/TVCG.2013.145;10.1109/TVCG.2013.173;10.1109/TVCG.2010.162;10.1109/TVCG.2007.70583;10.1109/TVCG.2011.209;10.1109/TVCG.2014.2346331;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2011.196;10.1109/TVCG.2012.213;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122",363
"10.1109/TVCG.2015.2466992","Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research","Survey, evaluation, guidelines, parallel coordinates",2015,"The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.","Jimmy Johansson;Camilla Forsell","http://dx.doi.org/10.1109/TVCG.2015.2466992","10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.201;10.1109/VISUAL.1999.809866;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.5;10.1109/TVCG.2011.197;10.1109/VISUAL.1997.663867",364
"10.1109/TVCG.2015.2467035","SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams","Fisheye, vector-scaling, content-aware, network schematics, interactive zoom, navigation, information visualization",2015,"System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.","Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James R. Eagan;Eric Lecolinet","http://dx.doi.org/10.1109/TVCG.2015.2467035","10.1109/INFVIS.2004.66;10.1109/TVCG.2012.245;10.1109/INFVIS.2003.1249008",365
"10.1109/TVCG.2015.2467051","AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations","Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability",2015,"Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.","Mehmet Adil Yalçin;Niklas Elmqvist;Benjamin B. Bederson","http://dx.doi.org/10.1109/TVCG.2015.2467051","10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2011.185;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.144;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.141;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210;10.1109/TVCG.2014.2346249",366
"10.1109/TVCG.2015.2467091","Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization","Information visualization, systems, toolkits, declarative specification, optimization, interaction, streaming data",2015,"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.","Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2015.2467091","10.1109/VISUAL.1995.480821;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2010.144;10.1109/TVCG.2014.2346250;10.1109/TVCG.2013.179;10.1109/TVCG.2010.177;10.1109/VISUAL.1996.567752;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70515",367
"10.1109/TVCG.2015.2467112","Visualization, Selection, and Analysis of Traffic Flows","Moving Object Visualization, traffic flows, interaction",2015,"Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.","Roeland Scheepens;Christophe Hurter;Huub van de Wetering;Jarke J. van Wijk","http://dx.doi.org/10.1109/TVCG.2015.2467112","10.1109/TVCG.2011.185;10.1109/TVCG.2011.261;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294",368
"10.1109/TVCG.2015.2467132","Optimal Sets of Projections of High-Dimensional Data","Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data",2015,"Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.","Dirk J. Lehmann;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2015.2467132","10.1109/VAST.2010.5652433;10.1109/VAST.2011.6102437;10.1109/TVCG.2011.229;10.1109/VISUAL.1997.663916;10.1109/TVCG.2011.220;10.1109/TVCG.2013.182;10.1109/TVCG.2010.207;10.1109/VAST.2006.261423;10.1109/INFVIS.2005.1532142",369
"10.1109/TVCG.2015.2467191","Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems",2015,"General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.","Kanit Wongsuphasawat;Dominik Moritz;Anushka Anand;Jock D. Mackinlay;Bill Howe;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2015.2467191","10.1109/TVCG.2014.2346297;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346291;10.1109/INFVIS.2000.885086",370
"10.1109/TVCG.2015.2467195","How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice&#x0027;s Information Visualization Sensemaking","Sensemaking model, information visualization, novice users, grounded theory, qualitative study",2015,"In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.","Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn ah Kang;Ji Soo Yi","http://dx.doi.org/10.1109/TVCG.2015.2467195","10.1109/TVCG.2013.234;10.1109/TVCG.2014.2346984;10.1109/TVCG.2010.164;10.1109/VAST.2011.6102435;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.177;10.1109/TVCG.2014.2346481;10.1109/TVCG.2010.179;10.1109/TVCG.2007.70515",371
"10.1109/TVCG.2015.2467199","Visualizing Multiple Variables Across Scale and Geography","Scale, Geography, Multivariate, Sensitivity Analysis, Variable Selection, Local Statistics, Geodemographics, Energy",2015,"Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.","Sarah Goodwin;Jason Dykes;Aidan Slingsby;Cagatay Turkay","http://dx.doi.org/10.1109/TVCG.2015.2467199","10.1109/TVCG.2007.70558;10.1109/TVCG.2013.145;10.1109/TVCG.2007.70539;10.1109/TVCG.2014.2346482;10.1109/VAST.2011.6102448;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321;10.1109/TVCG.2009.128;10.1109/TVCG.2011.197;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346265",372
"10.1109/TVCG.2015.2467201","Suggested Interactivity: Seeking Perceived Affordances for Information Visualization","Suggested interactivity, perceived affordances, information visualization for the people, online visualization",2015,"In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.","Jeremy Boy;Louis Eveillard;Françoise Détienne;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2015.2467201","10.1109/TVCG.2014.2346984;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/INFVIS.2005.1532122",373
"10.1109/TVCG.2015.2467271","Sketching Designs Using the Five Design-Sheet Methodology","Lo-fidelity prototyping, User-centred design, Sketching for visualization, Ideation",2015,"Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching.","Jonathan C. Roberts;Christopher James Headleand;Panagiotis D. Ritsos","http://dx.doi.org/10.1109/TVCG.2015.2467271","10.1109/TVCG.2010.132;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.178;10.1109/VISUAL.1994.346304;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.171",374
"10.1109/TVCG.2015.2467321","Acquired Codes of Meaning in Data Visualization and Infographics: Beyond Perceptual Primitives","Visual Design, Taxonomies, Illustrative Visualization, Design Methodologies",2015,"While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88% of the infographics and 71% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.","Lydia Byrne;Daniel Angus;Janet Wiles","http://dx.doi.org/10.1109/TVCG.2015.2467321","10.1109/TVCG.2013.234;10.1109/TVCG.2010.126;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.221;10.1109/TVCG.2008.171",375
"10.1109/TVCG.2015.2467322","Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators","Visualization evaluation, radial layout design, composite indicator visualization, experiment",2015,"A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.","Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli","http://dx.doi.org/10.1109/TVCG.2015.2467322","10.1109/TVCG.2010.209;10.1109/TVCG.2008.125",376
"10.1109/TVCG.2015.2467323","Automatic Selection of Partitioning Variables for Small Multiple Displays","Small multiple displays, Visualization selection, Multidimensional data",2015,"Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets.","Anushka Anand;Justin Talbot","http://dx.doi.org/10.1109/TVCG.2015.2467323","10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/TVCG.2011.229;10.1109/TVCG.2006.161;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70594;10.1109/VAST.2006.261423;10.1109/INFVIS.2000.885086;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.161;10.1109/INFVIS.2005.1532142",377
"10.1109/TVCG.2015.2467324","A comparative study between RadViz and Star Coordinates","RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection",2015,"RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.","Manuel Rubio-Sánchez;Laura Raya;Francisco Diaz;Alberto Sanchez","http://dx.doi.org/10.1109/TVCG.2015.2467324","10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2014.2346258;10.1109/TVCG.2008.173",378
"10.1109/TVCG.2015.2467325","TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients","Multi-dimensional data, Temporal event sequences, Electronic health records",2015,"We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.","Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2015.2467325","10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70515",379
"10.1109/TVCG.2015.2467451","HOLA: Human-like Orthogonal Network Layout","Graph layout, orthogonal layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics",2015,"Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new ΓÇ£human-centredΓÇ¥ methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.","Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow","http://dx.doi.org/10.1109/TVCG.2015.2467451","10.1109/TVCG.2006.120;10.1109/TVCG.2012.208;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/TVCG.2008.141;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/TVCG.2008.155",380
"10.1109/TVCG.2015.2467452","Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections","Digital Humanities, Interlinked Visualization, Literary Studies, Cultural Collections, Science Fiction",2015,"In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.","Uta Hinrichs;Stefania Forlini;Bridget Moynihan","http://dx.doi.org/10.1109/TVCG.2015.2467452","10.1109/TVCG.2012.272;10.1109/TVCG.2014.2346431;10.1109/TVCG.2008.175;10.1109/TVCG.2008.127;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2008.4677370",381
"10.1109/TVCG.2015.2467691","AmbiguityVis: Visualization of Ambiguity in Graph Layouts","Visual Ambiguity, Visualization, Node-link diagram, Graph layout, Graph visualization",2015,"Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.","Yong Wang;Qiaomu Shen;Daniel Archambault;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2015.2467691","10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.155;10.1109/TVCG.2012.189",382
"10.1109/TVCG.2015.2467717","Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions","Information visualization, interactivity, dimensionality reduction, multidimensional scaling",2015,"We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.","Julian Stahnke;Marian Dörk;Boris Müller;Andreas Thom","http://dx.doi.org/10.1109/TVCG.2015.2467717","10.1109/TVCG.2013.157;10.1109/TVCG.2011.255;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/TVCG.2009.153;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346419;10.1109/TVCG.2013.153;10.1109/TVCG.2009.127;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/INFVIS.2004.60;10.1109/INFVIS.1995.528686",383
"10.1109/TVCG.2015.2467754","Visually Comparing Weather Features in Forecasts","Design study, weather, geographic/geospatial visualization, ensemble data",2015,"Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.","P. Samuel Quinan;Miriah D. Meyer","http://dx.doi.org/10.1109/TVCG.2015.2467754","10.1109/VISUAL.1990.146361;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2011.209;10.1109/TVCG.2010.181;10.1109/TVCG.2012.213;10.1109/TVCG.2013.143",384
"10.1109/TVCG.2015.2467759","Guidelines for Effective Usage of Text Highlighting Techniques","Text highlighting techniques, visual document analytics, text annotation, crowdsourced study",2015,"Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.","Hendrik Strobelt;Daniela Oelke;Bum Chul Kwon;Tobias Schreck;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2015.2467759","10.1109/TVCG.2012.277;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.183;10.1109/TVCG.2009.139;10.1109/VAST.2011.6102453;10.1109/INFVIS.1995.528686",385
"10.1109/TVCG.2015.2467811","Poemage: Visualizing the Sonic Topology of a Poem","Visualization in the humanities, design studies, text and document data, graph/network data",2015,"The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.","Nina McCurdy;Julie Lein;Katherine Coles;Miriah D. Meyer","http://dx.doi.org/10.1109/TVCG.2015.2467811","10.1109/TVCG.2011.186;10.1109/TVCG.2009.122;10.1109/VAST.2009.5333443;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2008.172;10.1109/INFVIS.1995.528686",386
"10.1109/TVCG.2015.2467831","Visual Mementos: Reflecting Memories with Personal Data","Visual Memento, Memories, Personal Visualization, Movement Data, World Wide Web",2015,"In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.","Alice Thudt;Dominikus Baur;Samuel Huron;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2015.2467831","10.1109/TVCG.2010.206;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/INFVIS.2004.8",387
"10.1109/TVCG.2015.2467851","Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data","Temporal data visualization, information visualization, multidimensional scaling",2015,"We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.","Benjamin Bach;Conglei Shi;Nicolas Heulot;Tara M. Madhyastha;Thomas J. Grabowski;Pierre Dragicevic","http://dx.doi.org/10.1109/TVCG.2015.2467851","10.1109/TVCG.2011.186;10.1109/TVCG.2007.70535;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346325;10.1109/TVCG.2013.192;10.1109/INFVIS.2002.1173155",388
"10.1109/TVCG.2015.2467872","Orientation-Enhanced Parallel Coordinate Plots","Parallel Coordinates, Orientation-enhanced Parallel Coordinates, Brushing, Orientation-enhanced Brushing, Data Readability, Data Selection",2015,"Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques.","Renata Georgia Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova","http://dx.doi.org/10.1109/TVCG.2015.2467872","10.1109/INFVIS.1998.729559;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1999.809866;10.1109/TVCG.2011.166;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.15;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.179",389
"10.1109/TVCG.2015.2467951","A Psychophysical Investigation of Size as a Physical Variable","Data physicalization, physical visualization, psychophysics, experiment, physical variable",2015,"Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, ΓÇ£physical variablesΓÇ¥ remain poorly understood. One of them is physical size. A difficulty for solid elements is that ΓÇ£sizeΓÇ¥ is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants' estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables.","Yvonne Jansen;Kasper Hornbæk","http://dx.doi.org/10.1109/TVCG.2015.2467951","10.1109/TVCG.2012.251;10.1109/TVCG.2013.234;10.1109/TVCG.2012.220;10.1109/TVCG.2013.134;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/TVCG.2014.2346320",390
"10.1109/TVCG.2015.2467992","A Simple Approach for Boundary Improvement of Euler Diagrams","Euler diagrams, Boundary Improvement, Force-Directed Approaches",2015,"General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations.","Paolo Simonetto;Daniel Archambault;Carlos Eduardo Scheidegger","http://dx.doi.org/10.1109/TVCG.2015.2467992","10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210",391
"10.1109/SciVis.2015.7429485","A Classification of User Tasks in Visual Analysis of Volume Data","Task Taxonomy, Empirical Evaluation, Volume Visualization, Scientific Visualization, Virtual Reality, 3D Interaction",2015,"Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.","Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha","http://dx.doi.org/10.1109/SciVis.2015.7429485","10.1109/INFVIS.2004.10;10.1109/TVCG.2013.124;10.1109/TVCG.2012.216;10.1109/TVCG.2009.126;10.1109/TVCG.2013.130;10.1109/TVCG.2013.120;10.1109/TVCG.2014.2346321;10.1109/INFVIS.2004.59",392
"10.1109/SciVis.2015.7429487","Visual Verification of Space Weather Ensemble Simulations","Visual Verification, Space Weather, Coronal Mass Ejections, Ensemble",2015,"We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.","Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman","http://dx.doi.org/10.1109/SciVis.2015.7429487","10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143",393
"10.1109/SciVis.2015.7429488","A Visual Voting Framework for Weather Forecast Calibration","Weather forecast, analog method, calibration, majority voting, visual analytics",2015,"Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.","Hongsen Liao;Yingcai Wu;Li Chen;Thomas M. Hamill;Yunhai Wang;Kan Dai;Hui Zhang;Wei Chen","http://dx.doi.org/10.1109/SciVis.2015.7429488","10.1109/TVCG.2013.131;10.1109/TVCG.2013.138;10.1109/TVCG.2013.144;10.1109/TVCG.2009.197;10.1109/TVCG.2008.139;10.1109/TVCG.2014.2346755;10.1109/TVCG.2010.181;10.1109/VISUAL.1994.346298;10.1109/TVCG.2013.143",394
"10.1109/SciVis.2015.7429491","Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers","tensor visualization, feature-based visualisation, composite materials, structural mechanics",2015,"Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.","Valentin Zobel;Markus Stommel;Gerik Scheuermann","http://dx.doi.org/10.1109/SciVis.2015.7429491","10.1109/VISUAL.1994.346326;10.1109/TVCG.2009.184;10.1109/VISUAL.1995.485141;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105",395
"10.1109/TVCG.2015.2466838","Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data","Superconductor, Vortex extraction, Feature tracking, Unstructured grid",2015,"We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.","Hanqi Guo;Carolyn L. Phillips;Tom Peterka;Dmitry A. Karpeyev;Andreas Glatz","http://dx.doi.org/10.1109/TVCG.2015.2466838","10.1109/VISUAL.1994.346327;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.249;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2004.3;10.1109/TVCG.2012.212;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545",396
"10.1109/TVCG.2015.2467153","Visualization-by-Sketching: An Artist&#x0027;s Interface for Creating Multivariate Time-Varying Data Visualizations","Visualization design, multivariate, art, sketch, color map, glyph",2015,"We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data ΓÇ£underΓÇ¥ the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay ΓÇ£in the creative zoneΓÇ¥ as they work.","David Schroeder;Daniel F. Keefe","http://dx.doi.org/10.1109/TVCG.2015.2467153","10.1109/VAST.2008.4677356;10.1109/TVCG.2009.181;10.1109/TVCG.2013.124;10.1109/TVCG.2011.202;10.1109/TVCG.2008.153;10.1109/TVCG.2013.226;10.1109/TVCG.2014.2346271;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2009.145;10.1109/TVCG.2010.162;10.1109/INFVIS.2001.963286;10.1109/TVCG.2011.181;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346441",397
"10.1109/TVCG.2015.2467194","TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data","Co-occurrence, human mobility, telco data, bicluster, visual analytics",2015,"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.","Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni","http://dx.doi.org/10.1109/TVCG.2015.2467194","10.1109/VAST.2010.5652478;10.1109/TVCG.2013.193;10.1109/TVCG.2014.2346276;10.1109/TVCG.2013.226;10.1109/TVCG.2011.166;10.1109/TVCG.2013.173;10.1109/TVCG.2014.2346271;10.1109/VAST.2011.6102455;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346665;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/VAST.2014.7042490;10.1109/TVCG.2014.2346922",398
"10.1109/TVCG.2015.2467200","Rotation Invariant Vortices for Flow Visualization","Vortex cores, rotation invariance, Galilean invariance, scientific visualization, flow visualization, line fields",2015,"We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.","Tobias Günther;Maik Schulze;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2015.2467200","10.1109/TVCG.2014.2346415;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2014.2346412;10.1109/TVCG.2011.249;10.1109/TVCG.2013.189;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198",399
"10.1109/TVCG.2015.2467202","CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds","Selection, spatial selection, structure-aware selection, context-aware selection, exploratory data visualization and analysis, 3D interaction, user interaction",2015,"We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.","Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001","http://dx.doi.org/10.1109/TVCG.2015.2467202","10.1109/TVCG.2008.153;10.1109/VISUAL.1999.809932;10.1109/TVCG.2013.126;10.1109/TVCG.2012.292;10.1109/INFVIS.1996.559216;10.1109/TVCG.2012.217;10.1109/TVCG.2010.157",400
"10.1109/TVCG.2015.2467204","Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles","Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling",2015,"We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.","Florian Ferstl;Kai Bürger;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2015.2467204","10.1109/TVCG.2007.70595;10.1109/VISUAL.2000.885715;10.1109/VISUAL.1999.809863;10.1109/TVCG.2013.141;10.1109/TVCG.2007.70518;10.1109/TVCG.2014.2346455;10.1109/VISUAL.2005.1532779;10.1109/TVCG.2010.181;10.1109/VISUAL.1999.809865;10.1109/TVCG.2013.143",401
"10.1109/TVCG.2015.2467412","Adaptive Multilinear Tensor Product Wavelets","Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction",2015,"Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.","Kenneth Weiss;Peter Lindstrom","http://dx.doi.org/10.1109/TVCG.2015.2467412","10.1109/TVCG.2010.145;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183810;10.1109/TVCG.2011.252;10.1109/VISUAL.1996.568127;10.1109/TVCG.2009.186",402
"10.1109/TVCG.2015.2467431","Association Analysis for Visual Exploration of Multivariate Scientific Data Sets","Multivariate data, association analysis, visual exploration, multiple views",2015,"The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.","Xiaotong Liu;Han-Wei Shen","http://dx.doi.org/10.1109/TVCG.2015.2467431","10.1109/TVCG.2013.133;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70615;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.165;10.1109/VAST.2012.6400488;10.1109/TVCG.2011.178;10.1109/VAST.2007.4389000",403
"10.1109/TVCG.2015.2467433","Interactive Visualization for Singular Fibers of Functions f : R3 -> R2","Singular fibers, fiber topology, mathematical visualization, design study",2015,"Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R3->R2. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.","Daisuke Sakurai;Osamu Saeki;Hamish Carr;Hsiang-Yun Wu;Takahiro Yamamoto;David J. Duke;Shigeo Takahashi","http://dx.doi.org/10.1109/TVCG.2015.2467433","10.1109/TVCG.2008.119;10.1109/VISUAL.1997.663875;10.1109/TVCG.2012.287;10.1109/TVCG.2010.213;10.1109/TVCG.2014.2346447;10.1109/TVCG.2010.146;10.1109/VISUAL.2002.1183774;10.1109/TVCG.2008.143;10.1109/TVCG.2009.119;10.1109/TVCG.2007.70601",404
"10.1109/TVCG.2015.2467435","Glyph-Based Comparative Visualization for Diffusion Tensor Fields","Glyph Design, Comparative Visualization, Diffusion Tensor Field",2015,"Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject.","Changgong Zhang;Thomas Schultz 0001;Kai Lawonn;Elmar Eisemann;Anna Vilanova","http://dx.doi.org/10.1109/TVCG.2015.2467435","10.1109/TVCG.2015.2467031;10.1109/TVCG.2006.134;10.1109/TVCG.2010.134;10.1109/VISUAL.1998.745294;10.1109/VAST.2014.7042491;10.1109/TVCG.2010.199",405
"10.1109/TVCG.2015.2467436","Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis","Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis",2015,"Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.","Soumya Dutta;Han-Wei Shen","http://dx.doi.org/10.1109/TVCG.2015.2467436","10.1109/TVCG.2007.70599;10.1109/VISUAL.1993.398877;10.1109/VISUAL.2004.107;10.1109/TVCG.2011.246;10.1109/TVCG.2007.70615;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2013.152;10.1109/TVCG.2014.2346423;10.1109/TVCG.2007.70579;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1998.745288;10.1109/TVCG.2008.163;10.1109/TVCG.2008.140",406
"10.1109/TVCG.2015.2467441","NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects","Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking",2015,"In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.","Ali K. Ai-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger","http://dx.doi.org/10.1109/TVCG.2015.2467441","10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2013.174;10.1109/TVCG.2014.2346249;10.1109/TVCG.2007.70584",407
"10.1109/TVCG.2015.2467449","Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis","Domain specific language, portable parallel programming, scientific visualization, tensor fields",2015,"Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.","Gordon L. Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John H. Reppy","http://dx.doi.org/10.1109/TVCG.2015.2467449","10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2346322;10.1109/TVCG.2012.240;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809896;10.1109/TVCG.2007.70534;10.1109/TVCG.2014.2346318;10.1109/VISUAL.1998.745290;10.1109/TVCG.2008.148;10.1109/TVCG.2008.163",408
"10.1109/TVCG.2015.2467963","Anisotropic Ambient Volume Shading","Direct volume rendering, volume illumination, anisotropic shading",2015,"We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.","Marco Ament;Carsten Dachsbacher","http://dx.doi.org/10.1109/TVCG.2015.2467963","10.1109/TVCG.2014.2346333;10.1109/TVCG.2013.129;10.1109/TVCG.2014.2346411;10.1109/TVCG.2012.232;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2011.161;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183771;10.1109/TVCG.2011.198;10.1109/VISUAL.2004.5;10.1109/TVCG.2012.267;10.1109/VISUAL.1996.567777",409
"10.1109/TVCG.2015.2468031","Mining Graphs for Understanding Time-Varying Volumetric Data","Time-varying data visualization, graph simplification, community detection, visual recommendation",2015,"A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.","Yi Gu;Chaoli Wang;Tom Peterka;Robert Jacob;Seung Hyun Kim","http://dx.doi.org/10.1109/TVCG.2015.2468031","10.1109/TVCG.2009.122;10.1109/TVCG.2013.151;10.1109/TVCG.2011.246;10.1109/TVCG.2008.116;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/TVCG.2009.165;10.1109/TVCG.2006.159",410
"10.1109/TVCG.2015.2468091","Gaze Stripes: Image-Based Visualization of Eye Tracking Data","Eye tracking, time-dependent data, spatio-temporal visualization",2015,"We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques.","Kuno Kurzhals;Marcel Hlawatsch;Florian Heimerl;Michael Burch;Thomas Ertl;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2015.2468091","10.1109/TVCG.2011.232;10.1109/TVCG.2012.276;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.194;10.1109/TVCG.2008.125",411
"10.1109/TVCG.2015.2468093","Effective Visualization of Temporal Ensembles","Ensemble visualization",2015,"An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions.","Lihua Hao;Christopher G. Healey;Steffen A. Bass","http://dx.doi.org/10.1109/TVCG.2015.2468093","10.1109/TVCG.2014.2346448;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2014.2346751;10.1109/TVCG.2009.155;10.1109/TVCG.2014.2346455;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143",412
"10.1109/TVCG.2015.2467196","TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems","Anomaly Detection, Social Media, Visual Analysis",2015,"Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.","Nan Cao;Conglei Shi;Wan-Yi Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin","http://dx.doi.org/10.1109/TVCG.2015.2467196","10.1109/TVCG.2012.291;10.1109/TVCG.2006.170;10.1109/VISUAL.2002.1183816;10.1109/TVCG.2014.2346922",413
"10.1109/TVCG.2015.2467531","TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text","System, timelines, authoring environment, time-oriented data, journalism",2015,"We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.","Johanna Fulda;Matthew Brehmer;Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2015.2467531","10.1109/VAST.2014.7042493;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346431;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/TVCG.2013.214;10.1109/TVCG.2012.224;10.1109/TVCG.2014.2346291;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.212;10.1109/VAST.2012.6400530;10.1109/TVCG.2007.70577",414
"10.1109/TVCG.2015.2467551","Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes","Provenance, Analytic provenance, Visual analytics, Framework, Visualization, Conceptual model",2015,"While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.","Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen","http://dx.doi.org/10.1109/TVCG.2015.2467551","10.1109/INFVIS.2005.1532136;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.155;10.1109/VISUAL.1993.398857;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5652932;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/TVCG.2013.126;10.1109/VAST.2009.5333020;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.271;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677366;10.1109/TVCG.2013.130;10.1109/TVCG.2010.181;10.1109/TVCG.2010.179;10.1109/VISUAL.1990.146375",415
"10.1109/TVCG.2015.2467552","The Data Context Map: Fusing Data and Attributes into a Unified Display","High Dimensional Data, Low-Dimensional Embedding, Visual Analytics, Decision Make, Tradeoffs",2015,"Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.","Shenghui Cheng;Klaus Mueller","http://dx.doi.org/10.1109/TVCG.2015.2467552","10.1109/TVCG.2013.146;10.1109/VAST.2009.5332629;10.1109/VISUAL.1997.663916;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.220;10.1109/INFVIS.1997.636793;10.1109/TVCG.2010.207",416
"10.1109/TVCG.2015.2467553","Temporal MDS Plots for Analysis of Multivariate Data","Multivariate Data, Time Series, Data Reduction, Multidimensional Scaling",2015,"Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.","Dominik Jäckle;Fabian Fischer;Tobias Schreck;Daniel A. Keim","http://dx.doi.org/10.1109/TVCG.2015.2467553","10.1109/VAST.2009.5332593;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70592;10.1109/VAST.2009.5332628",417
"10.1109/TVCG.2015.2467554","An Uncertainty-Aware Approach for Exploratory Microblog Retrieval","microblog data, mutual reinforcement model, uncertainty modeling, uncertainty visualization, uncertainty propagation",2015,"Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.","Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan","http://dx.doi.org/10.1109/TVCG.2015.2467554","10.1109/TVCG.2013.186;10.1109/TVCG.2012.291;10.1109/VAST.2009.5332611;10.1109/TVCG.2013.223;10.1109/TVCG.2011.233;10.1109/VAST.2014.7042494;10.1109/VISUAL.1996.568116;10.1109/INFVIS.2005.1532150;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.197;10.1109/TVCG.2014.2346919;10.1109/TVCG.2013.232;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346920;10.1109/TVCG.2010.183;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346922",418
"10.1109/TVCG.2015.2467555","VisOHC: Designing Visual Analytics for Online Health Communities","Online health communities, visual analytics, conversation analysis, thread visualization, healthcare, design study",2015,"Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.","Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi","http://dx.doi.org/10.1109/TVCG.2015.2467555","10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102441;10.1109/TVCG.2014.2346292;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2010.175;10.1109/VAST.2014.7042494;10.1109/TVCG.2014.2346331;10.1109/VAST.2009.5333919;10.1109/TVCG.2012.213;10.1109/TVCG.2009.171;10.1109/TVCG.2009.187;10.1109/TVCG.2013.221;10.1109/VAST.2012.6400554;10.1109/VAST.2014.7042496;10.1109/TVCG.2008.171",419
"10.1109/TVCG.2015.2467592","Visually Exploring Transportation Schedules","Transportation, schedules, kernel density estimation, visual exploration",2015,"Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.","Cesar Palomo;Zhan Guo;Cláudio T. Silva;Juliana Freire","http://dx.doi.org/10.1109/TVCG.2015.2467592","10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346449;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.176;10.1109/TVCG.2013.226;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.137;10.1109/TVCG.2009.131;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2011.179;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249005",420
"10.1109/TVCG.2015.2467611","SensePath: Understanding the Sensemaking Process Through Analytic Provenance","Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization",2015,"Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.","Phong H. Nguyen;Kai Xu 0003;Ashley Wheat;B. L. William Wong;Simon Attfield;Bob Fields","http://dx.doi.org/10.1109/TVCG.2015.2467611","10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346575;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333020;10.1109/TVCG.2013.132",421
"10.1109/TVCG.2015.2467613","A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights","Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation",2015,"We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors.","Hua Guo;Steven R. Gomez;Caroline Ziemkiewicz;David H. Laidlaw","http://dx.doi.org/10.1109/TVCG.2015.2467613","10.1109/INFVIS.2005.1532136;10.1109/TVCG.2014.2346575;10.1109/VAST.2014.7042482;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346452;10.1109/TVCG.2012.221;10.1109/TVCG.2007.70515",422
"10.1109/TVCG.2015.2467615","InterAxis: Steering Scatterplot Axes via Observation-Level Interaction","Scatterplots, user interaction, model steering",2015,"Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.","Hannah Kim;Jaegul Choo;Haesun Park;Alex Endert","http://dx.doi.org/10.1109/TVCG.2015.2467615","10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.212;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.201;10.1109/TVCG.2008.153;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346250;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.178;10.1109/TVCG.2013.167",423
"10.1109/TVCG.2015.2467618","Task-Driven Comparison of Topic Models","Text visualization, topic modeling",2015,"Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.","Eric C. Alexander;Michael Gleicher","http://dx.doi.org/10.1109/TVCG.2015.2467618","10.1109/TVCG.2011.232;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/TVCG.2012.260;10.1109/INFVIS.2000.885098;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.221",424
"10.1109/TVCG.2015.2467619","Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data","Spatial temporal visual analytics, Geo-tagged social media, Sparsely sampling, Uncertainty, Movement",2015,"Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.","Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Luke Zhang;Jiawan Zhang","http://dx.doi.org/10.1109/TVCG.2015.2467619","10.1109/VAST.2009.5332584;10.1109/VAST.2008.4677356;10.1109/TVCG.2009.182;10.1109/TVCG.2011.185;10.1109/TVCG.2012.291;10.1109/TVCG.2009.143;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346746;10.1109/TVCG.2014.2346922",425
"10.1109/TVCG.2015.2467620","Interactive Visual Profiling of Musicians","visual analytics, profiling system, musicians database visualization, digital humanities, musicology",2015,"Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.","Stefan Jänicke;Josef Focht;Gerik Scheuermann","http://dx.doi.org/10.1109/TVCG.2015.2467620","10.1109/VAST.2011.6102454;10.1109/TVCG.2010.159;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/VAST.2009.5333443;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.175;10.1109/TVCG.2012.252;10.1109/VAST.2012.6400485;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2009.111;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333023;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333248;10.1109/VAST.2008.4677370;10.1109/VAST.2010.5652520",426
"10.1109/TVCG.2015.2467621","CiteRivers: Visual Analytics of Citation Patterns","scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering",2015,"The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.","Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2015.2467621","10.1109/INFVIS.2004.77;10.1109/TVCG.2015.2467757;10.1109/TVCG.2008.166;10.1109/TVCG.2013.212;10.1109/VAST.2009.5333443;10.1109/TVCG.2011.239;10.1109/TVCG.2012.252;10.1109/TVCG.2013.162;10.1109/TVCG.2012.277;10.1109/INFVIS.2004.45;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.162;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1995.528686;10.1109/TVCG.2014.2346920;10.1109/TVCG.2009.202",427
"10.1109/TVCG.2015.2467622","Supporting Iterative Cohort Construction with Visual Temporal Queries","Visual temporal queries, cohort definition, electronic medical records, information visualization",2015,"Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.","Josua Krause;Adam Perer;Harry Stavropoulos","http://dx.doi.org/10.1109/TVCG.2015.2467622","10.1109/TVCG.2011.185;10.1109/VAST.2007.4389013;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/VAST.2010.5652890;10.1109/TVCG.2014.2346482;10.1109/TVCG.2013.200;10.1109/TVCG.2013.206;10.1109/TVCG.2009.117;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.225;10.1109/TVCG.2013.167",428
"10.1109/TVCG.2015.2467733","PhenoBlocks: Phenotype Comparison Visualizations","Clinical diagnosis, differential hierarchy comparison, ontology, genomics, phenomics, phenotype",2015,"The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.","Michael Glueck;Peter Hamilton;Fanny Chevalier;Simon Breslav;Azam Khan;Daniel J. Wigdor;Michael Brudno","http://dx.doi.org/10.1109/TVCG.2015.2467733","10.1109/VAST.2011.6102439;10.1109/TVCG.2013.214;10.1109/TVCG.2013.231;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2009.167;10.1109/TVCG.2009.116;10.1109/INFVIS.2000.885091;10.1109/TVCG.2007.70529;10.1109/INFVIS.2003.1249030;10.1109/TVCG.2012.226",429
"10.1109/TVCG.2015.2467757","Visual Analysis and Dissemination of Scientific Literature Collections with SurVis","Visual analytics of documents, bibliographic data, dissemination, literature browser",2015,"Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.","Fabian Beck;Sebastian Koch;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2015.2467757","10.1109/TVCG.2011.169;10.1109/TVCG.2012.252;10.1109/TVCG.2015.2467621;10.1109/VAST.2009.5333564;10.1109/TVCG.2010.194;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.167",430
"10.1109/TVCG.2015.2467813","BiSet: Semantic Edge Bundling with Biclusters for Sensemaking","Bicluster, coordinated relationship, semantic edge bundling",2015,"Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, ΓÇ£in-betweenΓÇ¥, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.","Maoyuan Sun;Peng Mi;Chris North;Naren Ramakrishnan","http://dx.doi.org/10.1109/TVCG.2015.2467813","10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2008.135;10.1109/TVCG.2012.252;10.1109/TVCG.2012.260;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346260;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/VAST.2009.5333878;10.1109/TVCG.2011.250;10.1109/TVCG.2010.138;10.1109/TVCG.2014.2346752;10.1109/TVCG.2010.210;10.1109/TVCG.2011.183;10.1109/TVCG.2014.2346665",431
"10.1109/TVCG.2015.2467871","VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications","visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data",2015,"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.","Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2015.2467871","10.1109/TVCG.2012.276;10.1109/TVCG.2013.124;10.1109/VAST.2008.4677361;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346677;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.273;10.1109/VISUAL.2005.1532837",432
"10.1109/TVCG.2015.2467954","VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments","Visual Analytics, Evaluation, User Studies, Ontology, Experiments, Interaction, Virtual Reality, Visualization",2015,"Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.","Charilaos Papadopoulos;Ievgeniia Gutenko;Arie E. Kaufman","http://dx.doi.org/10.1109/TVCG.2015.2467954","10.1109/TVCG.2012.276;10.1109/TVCG.2012.251;10.1109/TVCG.2014.2346591;10.1109/TVCG.2010.157;10.1109/TVCG.2014.2346311;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12",433
"10.1109/TVCG.2015.2467971","VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History","Visual Analytics, Text Analytics, Wikipedia",2015,"Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.","Isaac Cho;Wenwen Dou;Xiaoyu Wang;Eric Sauda;William Ribarsky","http://dx.doi.org/10.1109/TVCG.2015.2467971","10.1109/VAST.2014.7042493;10.1109/VAST.2007.4389012;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.178;10.1109/VAST.2010.5652885;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2000.885091",434
"10.1109/TVCG.2015.2467991","Exploring Evolving Media Discourse Through Event Cueing","Media Analysis, Time Series Analysis, Event Detection",2015,"Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.","Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski","http://dx.doi.org/10.1109/TVCG.2015.2467991","10.1109/TVCG.2013.222;10.1109/VAST.2011.6102488;10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/VAST.2008.4677364;10.1109/TVCG.2014.2346682;10.1109/VAST.2014.7042484;10.1109/TVCG.2011.179;10.1109/VAST.2014.7042494;10.1109/VAST.2012.6400491;10.1109/VAST.2009.5333919;10.1109/INFVIS.1999.801851;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346913",435
"10.1109/TVCG.2015.2468011","LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design","Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery",2015,"State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.","Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schwärzler;Eduard Gröller;Harald Piringer","http://dx.doi.org/10.1109/TVCG.2015.2468011","10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.185;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/INFVIS.2003.1249032;10.1109/TVCG.2013.173;10.1109/TVCG.2009.110;10.1109/TVCG.2014.2346321",436
"10.1109/TVCG.2015.2468078","Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration","Dynamic Networks, Exploration, Dimensionality Reduction",2015,"We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.","Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk","http://dx.doi.org/10.1109/TVCG.2015.2468078","10.1109/TVCG.2011.226;10.1109/INFVIS.2004.18;10.1109/TVCG.2013.198;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2008.125;10.1109/TVCG.2011.178;10.1109/INFVIS.1999.801851",437
"10.1109/TVCG.2015.2468111","MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering","Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering",2015,"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.","Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren","http://dx.doi.org/10.1109/TVCG.2015.2468111","10.1109/TVCG.2011.202;10.1109/TVCG.2011.226;10.1109/TVCG.2011.233;10.1109/INFVIS.2004.18;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346441;10.1109/INFVIS.1999.801851;10.1109/VAST.2012.6400553;10.1109/VAST.2009.5333893;10.1109/INFVIS.2005.1532150",438
"10.1109/TVCG.2015.2468151","egoSlider: Visual Analysis of Egocentric Network Evolution","Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics",2015,"Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.","Yanhong Wu;Naveen Pitipornvivat;Jian Zhao;Sixiao Yang;Guowei Huang;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2015.2468151","10.1109/TVCG.2011.169;10.1109/TVCG.2011.226;10.1109/TVCG.2006.147;10.1109/TVCG.2013.149",439
"10.1109/TVCG.2015.2468291","3D Regression Heat Map Analysis of Population Study Data","Interactive Visual Analysis, Regression Analysis, Heat Map, Epidemiology, Breast Cancer, Hepatic Steatosis",2015,"Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject's lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease.","Paul Klemm;Kai Lawonn;Sylvia Glaßer;Uli Niemann;Katrin Hegenscheid;Henry Völzke;Bernhard Preim","http://dx.doi.org/10.1109/TVCG.2015.2468291","10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/VAST.2009.5333431;10.1109/TVCG.2013.160;10.1109/TVCG.2014.2346591;10.1109/TVCG.2013.161;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321",440
"10.1109/TVCG.2015.2468292","MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data","Human motion visualization, interactive clustering, motion tracking data, expert reviews, user study",2015,"Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.","Sujin Jang;Niklas Elmqvist;Karthik Ramani","http://dx.doi.org/10.1109/TVCG.2015.2468292","10.1109/TVCG.2013.178;10.1109/TVCG.2009.181;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.258;10.1109/TVCG.2013.196;10.1109/TVCG.2013.200;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2013.181;10.1109/TVCG.2010.149;10.1109/VISUAL.2002.1183778;10.1109/TVCG.2008.172;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346920",441
"10.1109/VAST.2015.7347624","Wavelet-based visualization of time-varying data on graphs","Time-varying data, graph wavelets, stacked graph visualization",2015,"Visualizing time-varying data defined on the nodes of a graph is a challenging problem that has been faced with different approaches. Although techniques based on aggregation, topology, and topic modeling have proven their usefulness, the visual analysis of smooth and/or abrupt data variations as well as the evolution of such variations over time are aspects not properly tackled by existing methods. In this work we propose a novel visualization methodology that relies on graph wavelet theory and stacked graph metaphor to enable the visual analysis of time-varying data defined on the nodes of a graph. The proposed method is able to identify regions where data presents abrupt and mild spacial and/or temporal variation while still been able to show how such changes evolve over time, making the identification of events an easier task. The usefulness of our approach is shown through a set of results using synthetic as well as a real data set involving taxi trips in downtown Manhattan. The methodology was able to reveal interesting phenomena and events such as the identification of specific locations with abrupt variation in the number of taxi pickups.","Paola Valdivia;Fabio Dias;Fabiano Petronetto;Cláudio T. Silva;Luis Gustavo Nonato","http://dx.doi.org/10.1109/VAST.2015.7347624","10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346449;10.1109/TVCG.2013.226;10.1109/INFVIS.2000.885098;10.1109/TVCG.2013.228",442
"10.1109/VAST.2015.7347625","Mixed-initiative visual analytics using task-driven recommendations","mixed-initiative visual analytics, task modeling, recommender systems, sensemaking",2015,"Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach.","Kristin A. Cook;Nick Cramer;David Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert","http://dx.doi.org/10.1109/VAST.2015.7347625","10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/TVCG.2014.2346573;10.1109/VAST.2014.7042492;10.1109/TVCG.2008.174;10.1109/TVCG.2013.225",443
"10.1109/VAST.2015.7347626","Integrating predictive analytics into a spatiotemporal epidemic simulation","Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems",2015,"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.","Chris Bryan;Xue Wu;Susan M. Mniszewski;Kwan-Liu Ma","http://dx.doi.org/10.1109/VAST.2015.7347626","10.1109/VAST.2011.6102457;10.1109/INFVIS.1998.729563;10.1109/TVCG.2014.2346926;10.1109/TVCG.2013.125;10.1109/TVCG.2010.181;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2012.190",444
"10.1109/VAST.2015.7347627","Collaborative visual analysis with RCloud","visual analytics process, provenance, collaboration, visualization, computer-supported cooperative work",2015,"Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.","Stephen C. North;Carlos Eduardo Scheidegger;Simon Urbanek;Gordon Woodhull","http://dx.doi.org/10.1109/VAST.2015.7347627","10.1109/TVCG.2011.185;10.1109/VAST.2007.4389011;10.1109/TVCG.2012.219;10.1109/TVCG.2009.195;10.1109/TVCG.2007.70577",445
"10.1109/VAST.2015.7347630","iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data","Smart card data, origin-destination (OD), spatiotemporal visualization, clustering, machine learning",2015,"Using transport smart card transaction data to understand the homework dynamics of a city for urban planning is emerging as an alternative to traditional surveys which may be conducted every few years are no longer effective and efficient for the rapidly transforming modern cities. As commuters travel patterns are highly diverse, existing rule-based methods are not fully adequate. In this paper, we present iVizTRANS - a tool which combines an interactive visual analytics (VA) component to aid urban planners to analyse complex travel patterns and decipher activity locations for single public transport commuters. It is coupled with a machine learning component that iteratively learns from the planners classifications to train a classifier. The classifier is then applied to the city-wide smart card data to derive the dynamics for all public transport commuters. Our evaluation shows it outperforms the rule-based methods in previous work.","Liang Yu;Wei Wu;Xiaohui Li;Guangxia Li;Wee Siong Ng;See-Kiong Ng;Zhongwen Huang;Anushiya Arunan;Hui Min Watt","http://dx.doi.org/10.1109/VAST.2015.7347630","10.1109/INFVIS.2004.27;10.1109/INFVIS.2002.1173155",446
"10.1109/VAST.2015.7347633","FPSSeer: Visual analysis of game frame rate data","frame rate data, game performance evaluation, visual analytics",2015,"The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers.","Quan Li;Peng Xu;Huamin Qu","http://dx.doi.org/10.1109/VAST.2015.7347633","10.1109/TVCG.2008.166;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346445;10.1109/INFVIS.2001.963273",447
"10.1109/TVCG.2016.2598496","PowerSet: A Comprehensive Visualization of Set Intersections","scalability;Set visualization;treemaps;interaction",2016,"When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.","Bilal Alsallakh;Liu Ren","http://dx.doi.org/10.1109/TVCG.2016.2598496","10.1109/TVCG.2014.2346248;10.1109/TVCG.2015.2467051;10.1109/TVCG.2006.142;10.1109/INFVIS.2001.963283;10.1109/TVCG.2010.186;10.1109/VISUAL.1991.175815;10.1109/TVCG.2012.233;10.1109/VISUAL.1993.398863;10.1109/TVCG.2011.227;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2012.205;10.1109/TVCG.2008.144;10.1109/TVCG.2011.185;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186",448
"10.1109/TVCG.2016.2598498","Investigating the Use of a Dynamic Physical Bar Chart for Data Exploration and Presentation","Shape-changing displays;physicalization;physical visualization;bar charts;user behaviour;data presentation",2016,"Physical data representations, or data physicalizations, are a promising new medium to represent and communicate data. Previous work mostly studied passive physicalizations which require humans to perform all interactions manually. Dynamic shape-changing displays address this limitation and facilitate data exploration tasks such as sorting, navigating in data sets which exceed the fixed size of a given physical display, or preparing &#x201C;views&#x201D; to communicate insights about data. However, it is currently unclear how people approach and interact with such data representations. We ran an exploratory study to investigate how non-experts made use of a dynamic physical bar chart for an open-ended data exploration and presentation task. We asked 16 participants to explore a data set on European values and to prepare a short presentation of their insights using a physical display. We analyze: (1) users' body movements to understand how they approach and react to the physicalization, (2) their hand-gestures to understand how they interact with physical data, (3) system interactions to understand which subsets of the data they explored and which features they used in the process, and (4) strategies used to explore the data and present observations. We discuss the implications of our findings for the use of dynamic data physicalizations and avenues for future work.","Faisal Taher;Yvonne Jansen;Jonathan Woodruff;John Hardy;Kasper Hornbæk;Jason Alexander","http://dx.doi.org/10.1109/TVCG.2016.2598498","10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2352953;10.1109/TVCG.2013.124",449
"10.1109/TVCG.2016.2598518","booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans","education;Hierarchies;information visualization",2016,"Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.","Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2016.2598518",";10.1109/TVCG.2006.147",450
"10.1109/TVCG.2016.2598586","Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations","Multi-dimensional data;Hybrid visualization",2016,"Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.","Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2016.2598586","10.1109/TVCG.2014.2346248;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2005.1532129;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.179;10.1109/INFVIS.2003.1249016;10.1109/TVCG.2010.205;10.1109/TVCG.2013.227;10.1109/TVCG.2013.210;10.1109/TVCG.2011.201;10.1109/TVCG.2015.2467325;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346279;10.1109/TVCG.2013.192;10.1109/TVCG.2013.167;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2011.186",451
"10.1109/TVCG.2016.2598587","Screenit: Visual Analysis of Cellular Screens","High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy",2016,"High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.","Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2016.2598587","10.1109/VAST.2012.6400492;10.1109/TVCG.2014.2346752;10.1109/TVCG.2015.2466971;10.1109/TVCG.2011.253;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.213;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.173;10.1109/VAST.2011.6102453;10.1109/TVCG.2014.2346482",452
"10.1109/TVCG.2016.2598589","WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making","Visual analysis;decision making;multi-objective optimization;interactive ranking;rank sensitivity",2016,"A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.","Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten Möller;Harald Piringer","http://dx.doi.org/10.1109/TVCG.2016.2598589","10.1109/TVCG.2015.2468011;10.1109/TVCG.2013.147;10.1109/VAST.2015.7347686;10.1109/VISUAL.1993.398859;10.1109/TVCG.2008.145;10.1109/VAST.2011.6102457;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2010.190;10.1109/TVCG.2009.110;10.1109/VAST.2010.5652460;10.1109/TVCG.2013.173;10.1109/TVCG.2011.248;10.1109/TVCG.2009.111",453
"10.1109/TVCG.2016.2598590","Visualizing Social Media Content with SentenTree","text visualization;social media;natural language processing;word cloud;Twitter",2016,"We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.","Mengdie Hu;Krist Wongsuphasawat;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2016.2598590","10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2009.5333443;10.1109/INFVIS.1995.528686;10.1109/TVCG.2010.154;10.1109/VAST.2012.6400485;10.1109/TVCG.2011.179;10.1109/TVCG.2010.194;10.1109/TVCG.2013.221;10.1109/TVCG.2006.156;10.1109/TVCG.2009.165;10.1109/VAST.2011.6102488;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239",454
"10.1109/TVCG.2016.2598591","Optimizing Hierarchical Visualizations with the Minimum Description Length Principle","antichain;Hierarchy data;data aggregation;multiscale visualization;tree cut",2016,"In this paper we examine how the Minimum Description Length (MDL) principle can be used to efficiently select aggregated views of hierarchical datasets that feature a good balance between clutter and information. We present MDL formulae for generating uneven tree cuts tailored to treemap and sunburst diagrams, taking into account the available display space and information content of the data. We present the results of a proof-of-concept implementation. In addition, we demonstrate how such tree cuts can be used to enhance drill-down interaction in hierarchical visualizations by implementing our approach in an existing visualization tool. Validation is done with the feature congestion measure of clutter in views of a subset of the current DMOZ web directory, which contains nearly half million categories. The results show that MDL views achieve near constant clutter level across display resolutions. We also present the results of a crowdsourced user study where participants were asked to find targets in views of DMOZ generated by our approach and a set of baseline aggregation methods. The results suggest that, in some conditions, participants are able to locate targets (in particular, outliers) faster using the proposed approach.","Rafael Veras;Christopher Collins","http://dx.doi.org/10.1109/TVCG.2016.2598591","10.1109/TVCG.2006.120;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729557;10.1109/TVCG.2006.184;10.1109/TVCG.2012.233;10.1109/TVCG.2006.161",455
"10.1109/TVCG.2016.2598592","Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks","Data Quality Assessment;High-Dimensional Data;Hierarchical Aggregation;Linked Views",2016,"Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.","Clemens Arbesser;Florian Spechtenhauser;Thomas Mühlbacher;Harald Piringer","http://dx.doi.org/10.1109/TVCG.2016.2598592","10.1109/TVCG.2014.2346248;10.1109/TVCG.2012.213;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346260;10.1109/VAST.2011.6102458;10.1109/TVCG.2009.110;10.1109/TVCG.2015.2466971",456
"10.1109/TVCG.2016.2598594","The Attraction Effect in Information Visualization","cognitive bias;Information visualization;decision-making;decoy effect;attraction effect;asymmetric dominance effect",2016,"The attraction effect is a well-studied cognitive bias in decision making research, where one's choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect.","Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic","http://dx.doi.org/10.1109/TVCG.2016.2598594","10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346984;10.1109/VAST.2008.4677363;10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.199;10.1109/TVCG.2010.174;10.1109/VAST.2009.5333920",457
"10.1109/TVCG.2016.2598608","Embedded Data Representations","augmented reality;Information visualization;data physicalization;ambient displays;ubiquitous computing",2016,"We introduce embedded data representations, the use of visual and physical representations of data that are deeply integrated with the physical spaces, objects, and entities to which the data refers. Technologies like lightweight wireless displays, mixed reality hardware, and autonomous vehicles are making it increasingly easier to display data in-context. While researchers and artists have already begun to create embedded data representations, the benefits, trade-offs, and even the language necessary to describe and compare these approaches remain unexplored. In this paper, we formalize the notion of physical data referents - the real-world entities and spaces to which data corresponds - and examine the relationship between referents and the visual and physical representations of their data. We differentiate situated representations, which display data in proximity to data referents, and embedded representations, which display data so that it spatially coincides with data referents. Drawing on examples from visualization, ubiquitous computing, and art, we explore the role of spatial indirection, scale, and interaction for embedded representations. We also examine the tradeoffs between non-situated, situated, and embedded data displays, including both visualizations and physicalizations. Based on our observations, we identify a variety of design challenges for embedded data representation, and suggest opportunities for future research and applications.","Wesley Willett;Yvonne Jansen;Pierre Dragicevic","http://dx.doi.org/10.1109/TVCG.2016.2598608","10.1109/TVCG.2013.134;10.1109/INFVIS.1998.729560",458
"10.1109/TVCG.2016.2598609","Iterating between Tools to Create and Edit Visualizations","illustration;Visualization;iteration",2016,"A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.","Alex Bigelow;Steven M. Drucker;Danyel Fisher;Miriah D. Meyer","http://dx.doi.org/10.1109/TVCG.2016.2598609","10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467091;10.1109/INFVIS.2004.12;10.1109/TVCG.2011.209;10.1109/TVCG.2007.70584;10.1109/TVCG.2011.185",459
"10.1109/TVCG.2016.2598619","Multi-Granular Trend Detection for Time-Series Analysis","Interactive Exploration;Trend Detection;Time Series",2016,"Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.","Goethem Arthur Van;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann","http://dx.doi.org/10.1109/TVCG.2016.2598619","10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/TVCG.2006.147;10.1109/TVCG.2014.2346448;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.166;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346455",460
"10.1109/TVCG.2016.2598620","Data-Driven Guides: Supporting Expressive Design for Information Graphics","Information graphics;visualization;design tools;2D graphics",2016,"In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack flexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being confined by predefined templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics.","Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister","http://dx.doi.org/10.1109/TVCG.2016.2598620","10.1109/TVCG.2014.2346292;10.1109/INFVIS.1996.559212;10.1109/TVCG.2011.175;10.1109/TVCG.2016.2598609;10.1109/TVCG.2013.234;10.1109/INFVIS.2004.64;10.1109/TVCG.2012.197;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2000.885093;10.1109/TVCG.2014.2346979;10.1109/TVCG.2014.2346320;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467732;10.1109/INFVIS.2004.12;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2010.144;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577",461
"10.1109/TVCG.2016.2598647","Authoring Data-Driven Videos with DataClips","data video;narrative visualization;data storytelling;authoring tools;visualization systems",2016,"Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven &#x201C;clips&#x201D; together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.","Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andres Monroy-Hernández;Pourang Irani","http://dx.doi.org/10.1109/TVCG.2016.2598647","10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/TVCG.2013.234;10.1109/TVCG.2013.119;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2012.6400487",462
"10.1109/TVCG.2016.2598694","Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets","data cubes;Data modeling;dimensionality reduction;interactive visualization",2016,"Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.","Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Eduardo Scheidegger","http://dx.doi.org/10.1109/TVCG.2016.2598694","10.1109/VAST.2008.4677357;10.1109/INFVIS.2000.885086;10.1109/TVCG.2013.179;10.1109/TVCG.2014.2346452;10.1109/TVCG.2009.129;10.1109/TVCG.2013.141;10.1109/TVCG.2014.2346325;10.1109/VAST.2012.6400490",463
"10.1109/TVCG.2016.2598839","Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration","Visual Data Exploration;Visualization by Demonstration;Visualization Tools",2016,"Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.","Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert","http://dx.doi.org/10.1109/TVCG.2016.2598839","10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70594;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2014.2346250;10.1109/TVCG.2012.275;10.1109/TVCG.2015.2467153;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291;10.1109/VAST.2012.6400486",464
"10.1109/TVCG.2016.2598867","Evaluation of Graph Sampling: A Visualization Perspective","Graph visualization;graph sampling;empirical evaluation",2016,"Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.","Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui","http://dx.doi.org/10.1109/TVCG.2016.2598867","10.1109/TVCG.2015.2468151;10.1109/VISUAL.2005.1532819;10.1109/TVCG.2008.151;10.1109/TVCG.2006.147;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.135;10.1109/TVCG.2012.238;10.1109/TVCG.2013.232",465
"10.1109/TVCG.2016.2598876","Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement","Narrative visualization;storytelling;annotations;comic strip visualization;time-varying data",2016,"Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.","Chris Bryan;Kwan-Liu Ma;Jonathan Woodring","http://dx.doi.org/10.1109/TVCG.2016.2598876","10.1109/TVCG.2008.166;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2010.5652890;10.1109/TVCG.2012.229;10.1109/TVCG.2012.212;10.1109/TVCG.2011.195;10.1109/VAST.2012.6400487",466
"10.1109/TVCG.2016.2598885","Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation","Flow Maps;Matrix Visualisation;Cartographic Information Visualisation",2016,"Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.","Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott","http://dx.doi.org/10.1109/TVCG.2016.2598885","10.1109/INFVIS.2004.1;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346441;10.1109/TVCG.2008.165;10.1109/INFVIS.2005.1532150",467
"10.1109/TVCG.2016.2598919","Probabilistic Graph Layout for Uncertain Network Visualization","Uncertainty visualization;graph layout;graph visualization;edge bundling;Monte Carlo method",2016,"We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.","Christoph Schulz;Arlind Nocaj;Jochen Görtler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2016.2598919","10.1109/TVCG.2006.147;10.1109/TVCG.2010.176;10.1109/TVCG.2009.150;10.1109/TVCG.2009.127;10.1109/TVCG.2015.2467691;10.1109/TVCG.2015.2467591;10.1109/VAST.2009.5332611;10.1109/TVCG.2009.122;10.1109/TVCG.2013.232",468
"10.1109/TVCG.2016.2598920","VLAT: Development of a Visualization Literacy Assessment Test","Visualization Literacy;Assessment Test;Instrument;Measurement;Aptitude;Education",2016,"The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users' visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument.","Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon","http://dx.doi.org/10.1109/TVCG.2016.2598920","10.1109/TVCG.2014.2346419;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346984;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70515;10.1109/TVCG.2015.2467195;10.1109/VAST.2011.6102435;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467201",469
"10.1109/TVCG.2016.2598958","Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization","bundling;Network visualization;edge compression;confluent;power graph",2016,"In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.","Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer","http://dx.doi.org/10.1109/TVCG.2016.2598958","10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/TVCG.2011.190;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2012.208;10.1109/TVCG.2006.160;10.1109/TVCG.2013.151;10.1109/INFVIS.2005.1532150",470
"10.1109/TVCG.2016.2599030","Vega-Lite: A Grammar of Interactive Graphics","Information visualization;interaction;systems;toolkits;declarative specification",2016,"We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.","Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer","http://dx.doi.org/10.1109/TVCG.2016.2599030","10.1109/TVCG.2015.2467091;10.1109/TVCG.2009.174;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.185",471
"10.1109/TVCG.2016.2599058","HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History","History;Visualization;Interaction",2016,"Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These &#x201C;footprints&#x201D; of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users' exploration and insights.","Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison","http://dx.doi.org/10.1109/TVCG.2016.2599058","10.1109/VISUAL.2002.1183791;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346424;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.109",472
"10.1109/TVCG.2016.2599106","Evaluating the Impact of Binning 2D Scalar Fields","Geographic/Geospatial Visualization;Qualitative Evaluation;Color Perception;Perceptual Cognition",2016,"The expressiveness principle for visualization design asserts that a visualization should encode all of the available data, and only the available data, implying that continuous data types should be visualized with a continuous encoding channel. And yet, in many domains binning continuous data is not only pervasive, but it is accepted as standard practice. Prior work provides no clear guidance for when encoding continuous data continuously is preferable to employing binning techniques or how this choice affects data interpretation and decision making. In this paper, we present a study aimed at better understanding the conditions in which the expressiveness principle can or should be violated for visualizing continuous data. We provided participants with visualizations employing either continuous or binned greyscale encodings of geospatial elevation data and compared participants' ability to complete a wide variety of tasks. For various tasks, the results indicate significant differences in decision making, confidence in responses, and task completion time between continuous and binned encodings of the data. In general, participants with continuous encodings were faster to complete many of the tasks, but never outperformed those with binned encodings, while performance accuracy with binned encodings was superior to continuous encodings in some tasks. These findings suggest that strict adherence to the expressiveness principle is not always advisable. We discuss both the implications and limitations of our results and outline various avenues for potential work needed to further improve guidelines for using continuous versus binned encodings for continuous data types.","Lace M. K. Padilla;P. Samuel Quinan;Miriah D. Meyer;Sarah H. Creem-Regehr","http://dx.doi.org/10.1109/TVCG.2016.2599106","10.1109/TVCG.2011.175;10.1109/TVCG.2015.2467754;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1996.568118;10.1109/VISUAL.1995.480803;10.1109/TVCG.2013.124",473
"10.1109/TVCG.2016.2599338","VizItCards: A Card-Based Toolkit for Infovis Design Education","information visualization education;peer learning;toolkit;card;design workshop",2016,"Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, VizItCards, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. VizItCards relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.","Shiqing He;Eytan Adar","http://dx.doi.org/10.1109/TVCG.2016.2599338","10.1109/TVCG.2015.2467271;10.1109/TVCG.2012.213;10.1109/VAST.2009.5333245;10.1109/TVCG.2014.2346331;10.1109/INFVIS.1996.559229;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.184;10.1109/TVCG.2009.111",474
"10.1109/TVCG.2016.2598448","Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields","Flow visualization;3D vector fields;Cutting planes;Glyphs;Perception;Evaluation;Human factors",2016,"Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.","Andrew H. Stevens;Thomas Butkiewicz;Colin Ware","http://dx.doi.org/10.1109/TVCG.2016.2598448","10.1109/VISUAL.1996.568139;10.1109/TVCG.2009.126;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2004.59;10.1109/VISUAL.1991.175792;10.1109/TVCG.2012.216;10.1109/VISUAL.1999.809918;10.1109/VISUAL.1998.745317;10.1109/VISUAL.2005.1532772;10.1109/TVCG.2009.138;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1996.567777",475
"10.1109/TVCG.2016.2598789","Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution","Bioinformatic visualization;education;learning;genome evolution;chromosome;user study",2016,"Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.","Chris Bryan;Gregory Guterman;Kwan-Liu Ma;Harris Lewin;Denis Larkin;Jaebum Kim;Jian Ma;Marta Farre","http://dx.doi.org/10.1109/TVCG.2016.2598789",";10.1109/TVCG.2007.70539;10.1109/TVCG.2012.272;10.1109/TVCG.2010.163;10.1109/TVCG.2009.167;10.1109/TVCG.2011.232;10.1109/TVCG.2010.137;10.1109/TVCG.2013.214",476
"10.1109/TVCG.2016.2598824","Molecular Surface Maps","Molecular Visualization;Maps;Cartography;Data Aggregation;Dimensionality Reduction;Space-time Cube",2016,"We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule's interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data.","Michael Krone;Florian Friess;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;Jürgen Pleiss;Thomas Ertl","http://dx.doi.org/10.1109/TVCG.2016.2598824","10.1109/TVCG.2013.194;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2015.2467413",477
"10.1109/TVCG.2016.2598827","Visualization as Seen through its Research Paper Keywords","data analysis;research themes;research topics;taxonomy;visualization history;theory",2016,"We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.","Petra Isenberg;Tobias Isenberg 0001;Michael Sedlmair;Jian Chen;Torsten Möller","http://dx.doi.org/10.1109/TVCG.2016.2598827","10.1109/TVCG.2012.195;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885092;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.126",478
"10.1109/TVCG.2016.2598866","Decal-Maps: Real-Time Layering of Decals on Surfaces for Multivariate Visualization","Multivariate;Visualization;Real-time;Decal;Surface;Layering;Design",2016,"We introduce the use of decals for multivariate visualization design. Decals are visual representations that are used for communication; for example, a pattern, a text, a glyph, or a symbol, transferred from a 2D-image to a surface upon contact. By creating what we define as decal-maps, we can design a set of images or patterns that represent one or more data attributes. We place decals on the surface considering the data pertaining to the locations we choose. We propose a (texture mapping) local parametrization that allows placing decals on arbitrary surfaces interactively, even when dealing with a high number of decals. Moreover, we extend the concept of layering to allow the co-visualization of an increased number of attributes on arbitrary surfaces. By combining decal-maps, color-maps and a layered visualization, we aim to facilitate and encourage the creative process of designing multivariate visualizations. Finally, we demonstrate the general applicability of our technique by providing examples of its use in a variety of contexts.","Allan Rocha;Usman R. Alim;Julio Daniel Silva;Mario Costa Sousa","http://dx.doi.org/10.1109/TVCG.2016.2598866","10.1109/VISUAL.1991.175811;10.1109/TVCG.2010.181;10.1109/TVCG.2011.243;10.1109/VISUAL.1998.745294;10.1109/TVCG.2015.2467153;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1999.809905;10.1109/TVCG.2011.170",479
"10.1109/TVCG.2016.2598868","Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles","Ensemble visualization;uncertainty visualization;meteorological visualization;iso-contours;time-varying data;clustering",2016,"We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability.","Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;Rüdiger Westermann","http://dx.doi.org/10.1109/TVCG.2016.2598868","10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2467754;10.1109/TVCG.2013.143;10.1109/TVCG.2013.141;10.1109/TVCG.2011.203;10.1109/TVCG.2014.2346332;10.1109/TVCG.2006.168",480
"10.1109/TVCG.2016.2598869","Visualization of Time-Varying Weather Ensembles across Multiple Resolutions","Ensemble;time-varying;multi-resolution;sensitivity analysis",2016,"Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.","Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen","http://dx.doi.org/10.1109/TVCG.2016.2598869","10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/SciVis.2015.7429487;10.1109/TVCG.2013.138;10.1109/TVCG.2015.2468093;10.1109/TVCG.2013.143;10.1109/TVCG.2014.2346448;10.1109/VAST.2015.7347634;10.1109/TVCG.2012.249;10.1109/TVCG.2014.2346455;10.1109/TVCG.2013.144",481
"10.1109/TVCG.2016.2598870","A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design","Visualization Models;Integrating Spatial and Non-Spatial Data Visualization;Design Methodologies",2016,"The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.","Ivan Kolesar;Stefan Bruckner;Ivan Viola;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2016.2598870","10.1109/TVCG.2014.2346591;10.1109/TVCG.2008.180;10.1109/TVCG.2009.153;10.1109/TVCG.2007.70550;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.164;10.1109/TVCG.2013.120;10.1109/TVCG.2009.136;10.1109/TVCG.2014.2346325;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.227;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2011.235;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2009.111",482
"10.1109/TVCG.2016.2598998","Glyphs for General Second-Order 2D and 3D Tensors","Glyph-based Techniques;Tensor Field Data;Flow Visualization",2016,"Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.","Tim Gerrits;Christian Rössl;Holger Theisel","http://dx.doi.org/10.1109/TVCG.2016.2598998","10.1109/TVCG.2014.2346325;10.1109/TVCG.2010.199;10.1109/VISUAL.1991.175773;10.1109/VISUAL.2004.115;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.1993.398849;10.1109/TVCG.2009.184",483
"10.1109/TVCG.2016.2599018","Topological Analysis of Inertial Dynamics","Visualization of inertial dynamics;N-body systems;magnetism;acceleration",2016,"Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.","Antoni Sagrista;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo","http://dx.doi.org/10.1109/TVCG.2016.2599018","10.1109/VISUAL.1993.398859;10.1109/TVCG.2014.2346415;10.1109/VISUAL.1990.146386",484
"10.1109/TVCG.2016.2599040","Direct Multifield Volume Ray Casting of Fiber Surfaces","Volume Rendering;Isosurface;Multidimensional Data",2016,"Multifield data are common in visualization. However, reducing these data to comprehensible geometry is a challenging problem. Fiber surfaces, an analogy of isosurfaces to bivariate volume data, are a promising new mechanism for understanding multifield volumes. In this work, we explore direct ray casting of fiber surfaces from volume data without any explicit geometry extraction. We sample directly along rays in domain space, and perform geometric tests in range space where fibers are defined, using a signed distance field derived from the control polygons. Our method requires little preprocess, and enables real-time exploration of data, dynamic modification and pixel-exact rendering of fiber surfaces, and support for higher-order interpolation in domain space. We demonstrate this approach on several bivariate datasets, including analysis of multi-field combustion data.","Kui Wu;Aaron Knoll;Benjamin J. Isaac;Hamish Carr;Valerio Pascucci","http://dx.doi.org/10.1109/TVCG.2016.2599040","10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.89;10.1109/TVCG.2009.185;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745713;10.1109/TVCG.2006.157;10.1109/TVCG.2010.145;10.1109/TVCG.2015.2467433;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1998.745300;10.1109/TVCG.2008.119;10.1109/VISUAL.2004.52",485
"10.1109/TVCG.2016.2599049","GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization","View-dependent visualization;focus + context techniques;manipulation and deformation;glyph-based techniques;human-computer interaction",2016,"Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.","Xin Tong;Cheng Li;Han-Wei Shen","http://dx.doi.org/10.1109/TVCG.2016.2599049","10.1109/TVCG.2013.121;10.1109/INFVIS.1996.559215;10.1109/TVCG.2010.199;10.1109/TVCG.2010.127;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1993.398849;10.1109/TVCG.2015.2467202;10.1109/TVCG.2006.167;10.1109/TVCG.2010.157",486
"10.1109/TVCG.2016.2599217","Hybrid Tactile/Tangible Interaction for 3D Data Exploration","3D data visualization;Interaction;tactile input;tangible input",2016,"We present the design and evaluation of an interface that combines tactile and tangible paradigms for 3D visualization. While studies have demonstrated that both tactile and tangible input can be efficient for a subset of 3D manipulation tasks, we reflect here on the possibility to combine the two complementary input types. Based on a field study and follow-up interviews, we present a conceptual framework of the use of these different interaction modalities for visualization both separately and combined-focusing on free exploration as well as precise control. We present a prototypical application of a subset of these combined mappings for fluid dynamics data visualization using a portable, position-aware device which offers both tactile input and tangible sensing. We evaluate our approach with domain experts and report on their qualitative feedback.","Lonni Besançon;Paul Issartel;Mehdi Ammi;Tobias Isenberg 0001","http://dx.doi.org/10.1109/TVCG.2016.2599217","10.1109/TVCG.2013.121;10.1109/TVCG.2010.164;10.1109/VISUAL.2004.47;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.157;10.1109/VISUAL.2005.1532846;10.1109/TVCG.2011.224;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467202;10.1109/TVCG.2012.292;10.1109/TVCG.2013.126;10.1109/TVCG.2012.217",487
"10.1109/TVCG.2016.2598432","SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations","optimal billboard locations;taxi trajectory;visual analytics;comparative analysis",2016,"The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.","Dongyu Liu;Di Weng;Yuhong Li;Jie Bao 0003;Yu Zheng;Huamin Qu;Yingcai Wu","http://dx.doi.org/10.1109/TVCG.2016.2598432","10.1109/TVCG.2013.122;10.1109/TVCG.2015.2467051;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.228;10.1109/TVCG.2015.2467112;10.1109/TVCG.2012.265;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346912;10.1109/TVCG.2007.70521;10.1109/TVCG.2015.2467771;10.1109/TVCG.2013.173;10.1109/TVCG.2011.181;10.1109/TVCG.2009.111",488
"10.1109/TVCG.2016.2598444","Visual Analysis of MOOC Forums with iForum","Discussion forum;MOOC;temporal visualization;visual analytics",2016,"Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.","Siwei Fu;Jian Zhao;Weiwei Cui;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2016.2598444","10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2015.2467555",489
"10.1109/TVCG.2016.2598445","TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections","topic modeling;nonnegative matrix factorization;t-distributed stochastic neighbor embedding;magic lens;text analytics",2016,"Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.","Minjeong Kim;Kyeongpil Kang;Deok Gun Park;Jaegul Choo;Niklas Elmqvist","http://dx.doi.org/10.1109/TVCG.2016.2598445","10.1109/INFVIS.2003.1249014;10.1109/TVCG.2013.212;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2004.43;10.1109/TVCG.2014.2346574;10.1109/TVCG.2011.239;10.1109/TVCG.2010.154;10.1109/VAST.2014.7042494",490
"10.1109/TVCG.2016.2598446","AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings","axis mapping;interactive model steering;sketch;axis visualization;human-centered visual analytics",2016,"Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users' complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user's drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users' nonlinear domain knowledge; 2) the underlying model that translates users' input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users' complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes.","Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert","http://dx.doi.org/10.1109/TVCG.2016.2598446","10.1109/INFVIS.2004.60;10.1109/TVCG.2013.190;10.1109/TVCG.2015.2467615;10.1109/TVCG.2013.188;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2012.262;10.1109/TVCG.2015.2467591;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.261;10.1109/TVCG.2013.191;10.1109/TVCG.2013.212;10.1109/TVCG.2013.167;10.1109/VAST.2012.6400486",491
"10.1109/TVCG.2016.2598447","TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text","Exploratory Text Analysis;Knowledge Discovery;Text Visualization",2016,"We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.","Cristian Felix;Anshul Vikram Pandey;Enrico Bertini","http://dx.doi.org/10.1109/TVCG.2016.2598447","10.1109/TVCG.2011.176;10.1109/INFVIS.2000.885098;10.1109/VAST.2012.6400485;10.1109/VAST.2009.5333443;10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.128;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346919",492
"10.1109/TVCG.2016.2598460","Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems","Theoretical models;human oracle;visual analytics;mixed initiative systems;semantic interaction;sensemaking",2016,"Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.","R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kristin A. Cook","http://dx.doi.org/10.1109/TVCG.2016.2598460","10.1109/VAST.2011.6102467;10.1109/VAST.2010.5652910;10.1109/VAST.2011.6102438;10.1109/TVCG.2012.195;10.1109/VAST.2015.7347625;10.1109/VAST.2007.4389009;10.1109/VAST.2011.6102449;10.1109/VAST.2012.6400486",493
"10.1109/TVCG.2016.2598466","Visualizing Dimension Coverage to Support Exploratory Analysis","Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets",2016,"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.","Ali Sarvghad;Melanie Tory;Narges Mahyar","http://dx.doi.org/10.1109/TVCG.2016.2598466","10.1109/TVCG.2015.2467191;10.1109/TVCG.2006.120;10.1109/INFVIS.1999.801862;10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/VAST.2009.5333020;10.1109/INFVIS.2001.963289;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VISUAL.1993.398857;10.1109/TVCG.2007.70589;10.1109/TVCG.2013.167;10.1109/TVCG.2008.109",494
"10.1109/TVCG.2016.2598467","Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration","Matrix Visualization;Visual Quality Measures;Quality Metrics;Feature Detection/Selection;Relational Data",2016,"In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.","Michael Behrisch;Benjamin Bach;Michael Hund;Michael Delz;Laura von Rüden;Jean-Daniel Fekete;Tobias Schreck","http://dx.doi.org/10.1109/TVCG.2016.2598467","10.1109/VAST.2012.6400488;10.1109/INFVIS.2004.15;10.1109/VAST.2014.7042480;10.1109/VAST.2010.5652433;10.1109/TVCG.2010.184;10.1109/VAST.2006.261423;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.229;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3",495
"10.1109/TVCG.2016.2598468","Characterizing Guidance in Visual Analytics","Visual analytics;guidance model;assistance;user support",2016,"Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk's model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA.","Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-Jörg Schulz;Marc Streit;Christian Tominski","http://dx.doi.org/10.1109/TVCG.2016.2598468","10.1109/VISUAL.2000.885678;10.1109/TVCG.2015.2467191;10.1109/VISUAL.1990.146375;10.1109/TVCG.2014.2346260;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2004.2;10.1109/TVCG.2013.120;10.1109/VISUAL.1997.663889;10.1109/TVCG.2015.2467691;10.1109/VISUAL.2002.1183803;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.174;10.1109/TVCG.2014.2346482",496
"10.1109/TVCG.2016.2598469","PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations","Cross-sectional cohort analysis;Phenotypes;Human Phenotype Ontology (HPO)",2016,"Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.","Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel J. Wigdor","http://dx.doi.org/10.1109/TVCG.2016.2598469","10.1109/TVCG.2014.2346248;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346279;10.1109/TVCG.2009.167;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467622;10.1109/TVCG.2015.2467733;10.1109/TVCG.2009.116",497
"10.1109/TVCG.2016.2598470","Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis","Progressive analytics;high dimensional data;iterative refinement;visual analytics",2016,"In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.","Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2016.2598470","10.1109/TVCG.2007.70539;10.1109/VAST.2008.4677361;10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346574;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.213;10.1109/TVCG.2013.125;10.1109/TVCG.2012.256;10.1109/VAST.2008.4677357;10.1109/TVCG.2015.2467613;10.1109/TVCG.2014.2346265;10.1109/TVCG.2011.178;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1996.559223;10.1109/TVCG.2011.229;10.1109/TVCG.2008.125",498
"10.1109/TVCG.2016.2598471","A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process","Machine Learning;Visual Analytics;User Interactions;Analytic Provenance",2016,"Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user's interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system.","Filip Dabek;Jesus J. Caban","http://dx.doi.org/10.1109/TVCG.2016.2598471","10.1109/TVCG.2014.2346575;10.1109/TVCG.2015.2467613;10.1109/VAST.2010.5650854;10.1109/TVCG.2015.2467871;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.219;10.1109/VAST.2009.5333020;10.1109/VAST.2006.261436;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467551;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70589",499
"10.1109/TVCG.2016.2598472","Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation","Brain Network;Visual Comparison;Hybrid Representation",2016,"Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.","Xinsong Yang;Lei Shi;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul M. Thompson","http://dx.doi.org/10.1109/TVCG.2016.2598472","10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2007.70582",500
"10.1109/TVCG.2016.2598479","A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections","Parallel Coordinates;Joint Distribution Reconstruction;Solution Space;High-dimensional Data;Multivariate Data",2016,"Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.","Cong Xie;Wen Zhong;Klaus Mueller","http://dx.doi.org/10.1109/TVCG.2016.2598479","10.1109/TVCG.2010.181;10.1109/TVCG.2013.190;10.1109/VAST.2009.5332586;10.1109/TVCG.2015.2467552;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2011.248",501
"10.1109/TVCG.2016.2598495","Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis","Interactive visualization;machine learning;visual analytics;dimensionality reduction",2016,"Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a &#x201C;human in the loop&#x201D; process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.","Dominik Sacha;Leishi Zhang;Michael Sedlmair;John Aldo Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim","http://dx.doi.org/10.1109/TVCG.2016.2598495","10.1109/TVCG.2012.195;10.1109/TVCG.2009.153;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/VAST.2008.4677350;10.1109/VAST.2009.5332629;10.1109/VAST.2010.5652443;10.1109/VAST.2014.7042492;10.1109/TVCG.2015.2467132;10.1109/TVCG.2015.2467553;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.153;10.1109/VAST.2010.5652484;10.1109/TVCG.2006.156;10.1109/TVCG.2015.2467717;10.1109/TVCG.2011.229;10.1109/TVCG.2013.124;10.1109/VAST.2010.5652392;10.1109/TVCG.2013.126",502
"10.1109/TVCG.2016.2598497","VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model","Visualization framework;data flow;subset flow model;tabular data",2016,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.","Bowen Yu;Cláudio T. Silva","http://dx.doi.org/10.1109/TVCG.2016.2598497","10.1109/TVCG.2009.195;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/INFVIS.1998.729560;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.225;10.1109/INFVIS.2003.1249013;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346753;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291",503
"10.1109/TVCG.2016.2598543","Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations","Externalization user-authored annotation;exploratory sequential data analysis;graph-based visualization",2016,"User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.","Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan","http://dx.doi.org/10.1109/TVCG.2016.2598543","10.1109/VAST.2009.5333878;10.1109/TVCG.2015.2467871;10.1109/VAST.2009.5333023;10.1109/VAST.2011.6102447;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124;10.1109/TVCG.2007.70577;10.1109/VAST.2010.5652879",504
"10.1109/TVCG.2016.2598544","Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods","trust;transparency;familiarity;uncertainty;biological data analysis",2016,"Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.","Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin A. Cook;Samuel Payne","http://dx.doi.org/10.1109/TVCG.2016.2598544","10.1109/TVCG.2015.2467591;10.1109/VAST.2015.7347625;10.1109/TVCG.2012.224;10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261416;10.1109/TVCG.2013.124;10.1109/TVCG.2013.120",505
"10.1109/TVCG.2016.2598664","ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories","Temporal Data;Marey's Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0",2016,"Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.","Panpan Xu;Honghui Mei;Liu Ren;Wei Chen 0001","http://dx.doi.org/10.1109/TVCG.2016.2598664","10.1109/TVCG.2014.2346454;10.1109/TVCG.2015.2467592;10.1109/TVCG.2006.170;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2011.185",506
"10.1109/TVCG.2016.2598695","Visual Analytics for Mobile Eye Tracking","Eye tracking;visual analytics;video visualization",2016,"The analysis of eye tracking data often requires the annotation of areas of interest (AOIs) to derive semantic interpretations of human viewing behavior during experiments. This annotation is typically the most time-consuming step of the analysis process. Especially for data from wearable eye tracking glasses, every independently recorded video has to be annotated individually and corresponding AOIs between videos have to be identified. We provide a novel visual analytics approach to ease this annotation process by image-based, automatic clustering of eye tracking data integrated in an interactive labeling and analysis system. The annotation and analysis are tightly coupled by multiple linked views that allow for a direct interpretation of the labeled data in the context of the recorded video stimuli. The components of our analytics environment were developed with a user-centered design approach in close cooperation with an eye tracking expert. We demonstrate our approach with eye tracking data from a real experiment and compare it to an analysis of the data by manual annotation of dynamic AOIs. Furthermore, we conducted an expert user study with 6 external eye tracking researchers to collect feedback and identify analysis strategies they used while working with our application.","Kuno Kurzhals;Marcel Hlawatsch;Christof Seeger;Daniel Weiskopf","http://dx.doi.org/10.1109/TVCG.2016.2598695","10.1109/TVCG.2010.149;10.1109/TVCG.2015.2468091;10.1109/VAST.2006.261433;10.1109/TVCG.2009.111",507
"10.1109/TVCG.2016.2598797","Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths","event sequences;Clickstream Data;sequence mining;visual analytics",2016,"Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.","Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson","http://dx.doi.org/10.1109/TVCG.2016.2598797","10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652926;10.1109/TVCG.2013.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346574;10.1109/VAST.2007.4389008;10.1109/TVCG.2011.185;10.1109/VAST.2014.7042487;10.1109/TVCG.2015.2467622;10.1109/VAST.2012.6400494",508
"10.1109/TVCG.2016.2598828","Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers","Performance analysis;classification;usable machine learning",2016,"Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.","Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams","http://dx.doi.org/10.1109/TVCG.2016.2598828","10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/TVCG.2014.2346660;10.1109/VAST.2011.6102453;10.1109/TVCG.2011.185",509
"10.1109/TVCG.2016.2598830","Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots","Parallel coordinates plots;parameter analysis;multi-resolution climate ensembles",2016,"Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.","Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin","http://dx.doi.org/10.1109/TVCG.2016.2598830","10.1109/TVCG.2010.181;10.1109/TVCG.2008.153;10.1109/INFVIS.1998.729559;10.1109/TVCG.2012.237;10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346755;10.1109/SciVis.2015.7429487;10.1109/VISUAL.1999.809866;10.1109/TVCG.2013.122;10.1109/INFVIS.2004.15;10.1109/TVCG.2015.2467431;10.1109/TVCG.2015.2468093;10.1109/TVCG.2010.184;10.1109/TVCG.2014.2346321",510
"10.1109/TVCG.2016.2598831","Towards Better Analysis of Deep Convolutional Neural Networks","Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering",2016,"Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.","Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu","http://dx.doi.org/10.1109/TVCG.2016.2598831","10.1109/TVCG.2015.2468151;10.1109/TVCG.2015.2467554;10.1109/TVCG.2015.2467813;10.1109/TVCG.2010.132;10.1109/TVCG.2008.135;10.1109/TVCG.2014.2346919;10.1109/TVCG.2011.239;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2005.1532820;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433",511
"10.1109/TVCG.2016.2598838","Visualizing the Hidden Activity of Artificial Neural Networks","Artificial neural networks;dimensionality reduction;algorithm understanding",2016,"In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.","Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru Telea","http://dx.doi.org/10.1109/TVCG.2016.2598838","10.1109/TVCG.2011.178;10.1109/TVCG.2011.220;10.1109/TVCG.2013.150;10.1109/TVCG.2014.2346578;10.1109/TVCG.2008.125;10.1109/TVCG.2015.2467553",512
"10.1109/TVCG.2016.2599378","VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment","Centralized matching;matching visualization;interaction techniques;visual analytics",2016,"Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.","Po-Ming Law;Wenchao Wu;Yixian Zheng;Huamin Qu","http://dx.doi.org/10.1109/TVCG.2016.2599378","10.1109/INFVIS.2004.1;10.1109/TVCG.2006.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2014.2346441;10.1109/VAST.2011.6102453",513
"10.1109/VAST.2016.7883506","Supporting visual exploration for multiple users in large display environments","",2016,"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.","Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani","http://dx.doi.org/10.1109/VAST.2016.7883506","10.1109/TVCG.2013.166;10.1109/TVCG.2009.162;10.1109/TVCG.2013.163;10.1109/TVCG.2011.185",514
"10.1109/VAST.2016.7883507","DocuCompass: Effective exploration of document landscapes","",2016,"The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.","Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl","http://dx.doi.org/10.1109/VAST.2016.7883507","10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333443;10.1109/TVCG.2012.277;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.186;10.1109/VAST.2012.6400487;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.152;10.1109/TVCG.2013.212;10.1109/TVCG.2013.162;10.1109/TVCG.2015.2467717;10.1109/VAST.2011.6102488;10.1109/VAST.2011.6102456",515
"10.1109/VAST.2016.7883510","D-Map: Visual Analysis of Ego-centric Information Diffusion Patterns in Social Media","",2016,"Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user's posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.","Siming Chen;Shuai Chen;Zhenhuang Wang;Jie Liang;Xiaoru Yuan;Nan Cao;Yadong Wu","http://dx.doi.org/10.1109/VAST.2016.7883510","10.1109/TVCG.2015.2467196;10.1109/TVCG.2014.2346922;10.1109/TVCG.2012.291;10.1109/TVCG.2010.154;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/TVCG.2014.2346920;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346277",516
"10.1109/VAST.2016.7883511","How ideas flow across multiple social groups","",2016,"Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.","Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo","http://dx.doi.org/10.1109/VAST.2016.7883511","10.1109/VAST.2011.6102461;10.1109/VAST.2010.5652931;10.1109/TVCG.2015.2467554;10.1109/TVCG.2014.2346433;10.1109/TVCG.2015.2467992;10.1109/TVCG.2015.2467691;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.196;10.1109/TVCG.2015.2467757;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.111;10.1109/INFVIS.2005.1532128",517
"10.1109/VAST.2016.7883512","EventAction: Visual analytics for temporal event sequence recommendation","",2016,"Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.","Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman","http://dx.doi.org/10.1109/VAST.2016.7883512","10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2012.213;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682",518
"10.1109/VAST.2016.7883513","SocialBrands: Visual analysis of public perceptions of brands on social media","",2016,"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.","Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen","http://dx.doi.org/10.1109/VAST.2016.7883513","10.1109/TVCG.2014.2346922;10.1109/VAST.2014.7042496;10.1109/TVCG.2013.227;10.1109/TVCG.2012.291;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/INFVIS.2000.885091;10.1109/TVCG.2011.183",519
"10.1109/VAST.2016.7883514","DimScanner: A Relation-based Visual Exploration Approach Towards Data Dimension Inspection","",2016,"Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.","Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebert","http://dx.doi.org/10.1109/VAST.2016.7883514","10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.153;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2010.5652450;10.1109/VAST.2006.261423;10.1109/TVCG.2013.160;10.1109/TVCG.2013.150;10.1109/TVCG.2011.229;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3",520
"10.1109/VAST.2016.7883515","SenseMap: Supporting browser-based online sensemaking through analytic provenance","",2016,"Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card's model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings.","Phong H. Nguyen;Kai Xu 0003;Andy Bardill;Betul Salman;Kate Herd;B. L. William Wong","http://dx.doi.org/10.1109/VAST.2016.7883515","10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.132;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.124;10.1109/TVCG.2011.185",521
"10.1109/VAST.2016.7883516","PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers","",2016,"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.","Johannes Weissenbock;Artem Amirkhanov;Eduard Gröller;Johann Kastner;Christoph Heinzl","http://dx.doi.org/10.1109/VAST.2016.7883516","10.1109/TVCG.2013.147;10.1109/TVCG.2008.153;10.1109/VISUAL.1993.398859;10.1109/TVCG.2012.200;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.177;10.1109/TVCG.2011.248",522
"10.1109/VAST.2016.7883517","DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction","",2016,"Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.","Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu","http://dx.doi.org/10.1109/VAST.2016.7883517","10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2468151;10.1109/INFVIS.2000.885098;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.129;10.1109/VAST.2012.6400557;10.1109/INFVIS.2001.963273;10.1109/TVCG.2013.221;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.239",523
"10.1109/VAST.2016.7883520","Visual analysis and coding of data-rich user behavior","",2016,"Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.","Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf","http://dx.doi.org/10.1109/VAST.2016.7883520","10.1109/VAST.2009.5333443;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.226;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467757;10.1109/TVCG.2010.194;10.1109/TVCG.2014.2346677;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124",524
"10.1109/VISUAL.1990.146375","A problem-oriented classification of visualization techniques","",1990,"Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods","Stephen Wehrend;Clayton Lewis","http://dx.doi.org/10.1109/VISUAL.1990.146375","",525
"10.1109/VISUAL.1990.146386","Exploring N-dimensional databases","",1990,"The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.","Jeffrey LeBlanc;Matthew O. Ward;Norman Wittels","http://dx.doi.org/10.1109/VISUAL.1990.146386","",526
"10.1109/VISUAL.1990.146402","Parallel coordinates: a tool for visualizing multi-dimensional geometry","",1990,"A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point - line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R N. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.","Alfred Inselberg;Bernard Dimsdale","http://dx.doi.org/10.1109/VISUAL.1990.146402","",527
"10.1109/VISUAL.1991.175773","A tool for visualizing the topology of three-dimensional vector fields","",1991,"A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 3×3 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.","Al Globus;Creon Levit;T. Lasinski","http://dx.doi.org/10.1109/VISUAL.1991.175773","10.1109/VISUAL.1990.146360;10.1109/VISUAL.1990.146359",528
"10.1109/VISUAL.1991.175782","The asymptotic decider: resolving the ambiguity in marching cubes","",1991,"A method for computing isovalue or contour surfaces of a trivariate function is discussed. The input data are values of the trivariate function, Fijk, at the cuberille grid points (xi, yj, zk ), and the output of a collection of triangles representing the surface consisting of all points where F(x,y, z) is a constant value. The method is a modification that is intended to correct a problem with a previous method.","Gregory M. Nielson;Bernd Hamann","http://dx.doi.org/10.1109/VISUAL.1991.175782","10.1109/VISUAL.1990.146363",529
"10.1109/VISUAL.1991.175815","Tree-maps: a space-filling approach to the visualization of hierarchical information structures","",1991,"A method for visualizing hierarchically structured information is described. The tree-map visualization technique makes 100% use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. Tree-maps can depict both the structure and content of the hierarchy. However, the approach is best suited to hierarchies in which the content of the leaf nodes and the structure of the hierarchy are of primary importance, and the content information associated with internal nodes is largely derived from their children","Brian Johnson;Ben Shneiderman","http://dx.doi.org/10.1109/VISUAL.1991.175815","",530
"10.1109/VISUAL.1992.235211","Constructing stream surfaces in steady 3D vector fields","",1992,"Maintenance of a front of particles, an efficient method of generating a set of sample points over a two-dimensional stream surface, is described. The particles are repeatedly advanced a short distance through the flow field. New polygons are appended to the downstream edge of the surface. The spacing of the particles is adjusted to maintain an adequate sampling across the width of the growing surface. Curve and ribbon methods of vector field visualization are reviewed","Jeff P. Hultquist","http://dx.doi.org/10.1109/VISUAL.1992.235211","10.1109/VISUAL.1990.146359;10.1109/VISUAL.1991.175837;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235202;10.1109/VISUAL.1991.175789",531
"10.1109/VISUAL.1993.398849","A probe for local flow field visualization","",1993,"A probe for the interactive visualization of flow fields is presented. The probe can be used to visualize many characteristics of the flow in detail for a small region in the data set. The velocity and the local change of velocity (the velocity gradient tensor) are visualized by a set of geometric primitives. To this end, the velocity gradient tensor is transformed to a local coordinate frame, and decomposed into components parallel with and perpendicular to the flow. These components are visualized as geometric objects with an intuitively meaningful interpretation. An implementation is presented which shows that this probe is a useful tool for flow visualization","Wim C. de Leeuw;Jarke J. van Wijk","http://dx.doi.org/10.1109/VISUAL.1993.398849","10.1109/VISUAL.1992.235193;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1992.235210",532
"10.1109/VISUAL.1993.398877","Texture splats for 3D scalar and vector field visualization","",1993,"Volume visualization is becoming an important tool for understanding large 3D data sets. A popular technique for volume rendering is known as splatting. With new hardware architectures offering substantial improvements in the performance of rendering texture mapped objects, we present textured splats. An ideal reconstruction function for 3D signals is developed which can be used as a texture map for a splat. Extensions to the basic splatting technique are then developed to additionally represent vector fields","Roger Crawfis;Nelson L. Max","http://dx.doi.org/10.1109/VISUAL.1993.398877","",533
"10.1109/VISUAL.1994.346302","XmdvTool: integrating multiple methods for visualizing multivariate data","",1994,"Much of the attention in visualization research has focussed on data rooted in physical phenomena, which is generally limited to three or four dimensions. However, many sources of data do not share this dimensional restriction. A critical problem in the analysis of such data is providing researchers with tools to gain insights into characteristics of the data, such as anomalies and patterns. Several visualization methods have been developed to address this problem, and each has its strengths and weaknesses. This paper describes a system named XmdvTool which integrates several of the most common methods for projecting multivariate data onto a two-dimensional screen. This integration allows users to explore their data in a variety of formats with ease. A view enhancement mechanism called an N-dimensional brush is also described. The brush allows users to gain insights into spatial relationships over N dimensions by highlighting data which falls within a user-specified subspace","Matthew O. Ward","http://dx.doi.org/10.1109/VISUAL.1994.346302","10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146402",534
"10.1109/VISUAL.1994.346326","The topology of symmetric, second-order tensor fields","",1994,"We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields","Thierry Delmarcelle;Lambertus Hesselink","http://dx.doi.org/10.1109/VISUAL.1994.346326","10.1109/VISUAL.1991.175773",535
"10.1109/VISUAL.1994.346331","An evaluation of reconstruction filters for volume rendering","",1994,"To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter","Steve Marschner;Richard Lobb","http://dx.doi.org/10.1109/VISUAL.1994.346331","10.1109/VISUAL.1993.398851",536
"10.1109/INFVIS.1995.528686","Visualizing the non-visual: spatial analysis and interaction with information from text documents","",1995,"The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.","James A. Wise;James J. Thomas;Kelly Pennock;D. Lantrip;M. Pottier;Anne Schur;V. Crow","http://dx.doi.org/10.1109/INFVIS.1995.528686","10.1109/VISUAL.1993.398863",537
"10.1109/VISUAL.1995.480821","An extended data-flow architecture for data analysis and visualization","",1995,"Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure ÔÇ£data-flowÔÇØ. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer","Greg Abram;Lloyd Treinish","http://dx.doi.org/10.1109/VISUAL.1995.480821","10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",538
"10.1109/VISUAL.1995.485139","High Dimensional Brushing for Interactive Exploration of Multivariate Data","",1995,"Brushing is an operation found in many data visualization systems. It is a mechanism for interactively selecting subsets of the data so that they may be highlighted, deleted, or masked. Traditionally, brushes have been defined in screen space via methods such as painting and rubberband rectangles. In this paper we describe the design of N-dimensional brushes which are defined in data space rather than screen space, and show how they have been integrated into XmdvTool, a visualization package for displaying multivariate data. Depending on the data display technique in use, brushes may be specified and manipulated via direct or indirect methods, and the specification may be demand-driven or data-driven. Various brush operations such as highlighting, linking, masking, moving average, and quantitative display have been developed to apply to the selected data. In addition, we have explored several new brush concepts, such as non-discrete brush boundaries, simultaneous display of multiple brushes, and creating composite brushes via logical operators. Preliminary experimental evaluation with test subjects supports the usefulness of N-dimensional brushes in data exploration tasks.","Allen R. Martin;Matthew O. Ward","http://dx.doi.org/10.1109/VISUAL.1995.485139","10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302",539
"10.1109/VISUAL.1995.485141","Iconic techniques for feature visualization","scientific visualization, feature extraction, iconic visualization, attribute calculation",1995,"Presents a conceptual framework and a process model for feature extraction and iconic visualization. Feature extraction is viewed as a process of data abstraction, which can proceed in multiple stages, and corresponding data abstraction levels. The features are represented by attribute sets, which play a key role in the visualization process. Icons are symbolic parametric objects, designed as visual representations of features. The attributes are mapped to the parameters (or degrees of freedom) of an icon. We describe some generic techniques to generate attribute sets, such as volume integrals and medial axis transforms. A simple but powerful modeling language was developed to create icons, and to link the attributes to the icon parameters. We present illustrative examples of iconic visualization created with the techniques described, showing the effectiveness of this approach","Frank J. Post;Theo van Walsum;Frits H. Post;Deborah Silver","http://dx.doi.org/10.1109/VISUAL.1995.485141","10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175809;10.1109/VISUAL.1992.235174",540
"10.1109/VISUAL.1996.567777","Interactive visualization of 3D-vector fields using illuminated stream lines","",1996,"A new technique for interactive vector field visualization using large numbers of properly illuminated stream lines is presented. Taking into account ambient, diffuse, and specular reflection terms as well as transparency, we employ a realistic shading model which significantly increases quality and realism of the resulting images. While many graphics workstations offer hardware support for illuminating surface primitives, usually no means for an accurate shading of line primitives are provided. However, we show that proper illumination of lines can be implemented by exploiting the texture mapping capabilities of modern graphics hardware. In this way high rendering performance with interactive frame rates can be achieved. We apply the technique to render large numbers of integral curves in a vector field. The impression of the resulting images can be further improved by making the curves partially transparent. We also describe methods for controlling the distribution of stream lines in space. These methods enable us to use illuminated stream lines within an interactive visualization environment.","Malte Zöckler;Detlev Stalling;Hans-Christian Hege","http://dx.doi.org/10.1109/VISUAL.1996.567777","10.1109/VISUAL.1993.398850;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1992.235226;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1993.398877",541
"10.1109/INFVIS.1997.636718","H3: laying out large directed graphs in 3D hyperbolic space","",1997,"We present the H3 layout technique for drawing large directed graphs as node-link diagrams in 3D hyperbolic space. We can lay out much larger structures than can be handled using traditional techniques for drawing general graphs because we assume a hierarchical nature of the data. We impose a hierarchy on the graph by using domain-specific knowledge to find an appropriate spanning tree. Links which are not part of the spanning tree do not influence the layout but can be selectively drawn by user request. The volume of hyperbolic 3-space increases exponentially, as opposed to the familiar geometric increase of euclidean 3-space. We exploit this exponential amount of room by computing the layout according to the hyperbolic metric. We optimize the cone tree layout algorithm for 3D hyperbolic space by placing children on a hemisphere around the cone mouth instead of on its perimeter. Hyperbolic navigation affords a Focus+Context view of the structure with minimal visual clutter. We have successfully laid out hierarchies of over 20,000 nodes. Our implementation accommodates navigation through graphs too large to be rendered interactively by allowing the user to explicitly prune or expand subtrees.","Tamara Munzner","http://dx.doi.org/10.1109/INFVIS.1997.636718","10.1109/INFVIS.1995.528691;10.1109/INFVIS.1995.528689",542
"10.1109/VISUAL.1997.663860","ROAMing terrain: Real-time Optimally Adapting Meshes","triangle bintree, view-dependent mesh, frame-to-frame coherence, greedy algorithms",1997,"Terrain visualization is a difficult problem for applications requiring accurate images of large datasets at high frame rates, such as flight simulation and ground-based aircraft testing using synthetic sensor simulation. On current graphics hardware, the problem is to maintain dynamic, view-dependent triangle meshes and texture maps that produce good images at the required frame rate. We present an algorithm for constructing triangle meshes that optimizes flexible view-dependent error metrics, produces guaranteed error bounds, achieves specified triangle counts directly and uses frame-to-frame coherence to operate at high frame rates for thousands of triangles per frame. Our method, dubbed Real-time Optimally Adapting Meshes (ROAM), uses two priority queues to drive split and merge operations that maintain continuous triangulations built from pre-processed bintree triangles. We introduce two additional performance optimizations: incremental triangle stripping and priority-computation deferral lists. ROAM's execution time is proportional to the number of triangle changes per frame, which is typically a few percent of the output mesh size; hence ROAM's performance is insensitive to the resolution and extent of the input terrain. Dynamic terrain and simple vertex morphing are supported.","Mark A. Duchaineau;Murray Wolinsky;David E. Sigeti;Mark C. Miller;Charles Aldrich;Mark B. Mineev-Weinstein","http://dx.doi.org/10.1109/VISUAL.1997.663860","10.1109/VISUAL.1996.567600;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1995.480813;10.1109/VISUAL.1995.480805",543
"10.1109/VISUAL.1997.663875","The contour spectrum","Visualization, Scalar Data, User Interfaces, Real-time Quantitative Query",1997,"The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.","Chandrajit L. Bajaj;Valerio Pascucci;Daniel Schikore","http://dx.doi.org/10.1109/VISUAL.1997.663875","10.1109/VISUAL.1996.568123;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1996.568113",544
"10.1109/INFVIS.1998.729559","Similarity clustering of dimensions for an enhanced visualization of multidimensional data","",1998,"The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results","Mihael Ankerst;Stefan Berchtold;Daniel A. Keim","http://dx.doi.org/10.1109/INFVIS.1998.729559","10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",545
"10.1109/INFVIS.1998.729560","An operator interaction framework for visualization systems","information visualization, operators, user interactions, view/value, framework, spreadsheet, design, extensibility, visualization systems",1998,"Information visualization encounters a wide variety of different data domains. The visualization community has developed representation methods and interactive techniques. As a community, we have realized that the requirements in each domain are often dramatically different. In order to easily apply existing methods, researchers have developed a semiology of graphic representations. We have extended this research into a framework that includes operators and interactions in visualization systems, such as a visualization spreadsheet. We discuss properties of this framework and use it to characterize operations spanning a variety of different visualization techniques. The framework developed in the paper enables a new way of exploring and evaluating the design space of visualization operators, and helps end users in their analysis tasks","Ed Huai-hsin Chi;John Riedl","http://dx.doi.org/10.1109/INFVIS.1998.729560","10.1109/VISUAL.1996.567796;10.1109/INFVIS.1996.559213;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636793;10.1109/INFVIS.1997.636792;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1995.480801;10.1109/INFVIS.1997.636761",546
"10.1109/VISUAL.1998.745294","Visualizing diffusion tensor images of the mouse spinal cord","multi-valued visualization, tensor field visualization,oil painting",1998,"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.","David H. Laidlaw;Eric T. Ahrens;David Kremers;Matthew J. Avalos;Russell E. Jacobs;Carol Readhead","http://dx.doi.org/10.1109/VISUAL.1998.745294","10.1109/VISUAL.1992.235201",547
"10.1109/VISUAL.1998.745713","Interactive ray tracing for isosurface rendering","",1998,"We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.","Steven G. Parker;Peter Shirley;Yarden Livnat;Charles D. Hansen;Peter-Pike J. Sloan","http://dx.doi.org/10.1109/VISUAL.1998.745713","10.1109/VISUAL.1997.663888;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1998.745300",548
"10.1109/INFVIS.1999.801851","Cluster and calendar based visualization of time series data","",1999,"A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented","Jarke J. van Wijk;Edward R. van Selow","http://dx.doi.org/10.1109/INFVIS.1999.801851","",549
"10.1109/VISUAL.1999.809866","Hierarchical parallel coordinates for exploration of large datasets","Large-scale multivariate data visualization, hierarchical data exploration, parallel coordinates",1999,"Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in searching for patterns, anomalies and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multi-resolution view of the data via hierarchical clustering, and use a variation of parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.","Ying-Huey Fua;Matthew O. Ward;Elke A. Rundensteiner","http://dx.doi.org/10.1109/VISUAL.1999.809866","10.1109/VISUAL.1994.346302;10.1109/INFVIS.1999.801858;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729556;10.1109/VISUAL.1995.485139",550
"10.1109/VISUAL.1999.809896","The ""Parallel Vectors"" operator-a vector field visualization primitive","",1999,"We propose an elementary operation on a pair of vector fields as a building block for defining and computing global line-type features of vector or scalar fields. While usual feature definitions often are procedural and therefore implicit, our operator allows precise mathematical definitions. It can serve as a basis for comparing feature definitions and for reuse of algorithms and implementations. Applications focus on vortex core methods.","Ronald Peikert;Martin Roth","http://dx.doi.org/10.1109/VISUAL.1999.809896","10.1109/VISUAL.1998.745290;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1995.480795;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1997.663894;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1996.567807",551
"10.1109/VISUAL.1999.809905","Visualizing Multivalued Data from 2D Incompressible Flows Using Concepts from Painting","",1999,"We present a new visualization method for 2D flows which allows us to combine multiple data values in an image for simultaneous viewing. We utilize concepts from oil painting, art and design as introduced in (Laidlaw et al., 1998) to examine problems within fluid mechanics. We use a combination of discrete and continuous visual elements arranged in multiple layers to visually represent the data. The representations are inspired by the brush strokes artists apply in layers to create an oil painting. We display commonly visualized quantities such as velocity and vorticity together with three additional mathematically derived quantities: the rate of strain tensor, and the turbulent charge and turbulent current. We describe the motivation for simultaneously examining these quantities and use the motivation to guide our choice of visual representation for each particular quantity. We present visualizations of three flow examples and observations concerning some of the physical relationships made apparent by the simultaneous display technique that we employed.","Robert Michael Kirby;H. Marmanis;David H. Laidlaw","http://dx.doi.org/10.1109/VISUAL.1999.809905","10.1109/VISUAL.1998.745294",552
"10.1109/INFVIS.2000.885086","Polaris: a system for query, analysis and visualization of multi-dimensional relational databases","",2000,"In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations","Chris Stolte;Pat Hanrahan","http://dx.doi.org/10.1109/INFVIS.2000.885086","10.1109/INFVIS.1996.559210",553
"10.1109/INFVIS.2000.885091","Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations","",2000,"Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space","John T. Stasko;Eugene Zhang","http://dx.doi.org/10.1109/INFVIS.2000.885091","10.1109/INFVIS.1999.801860;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1998.729557;10.1109/VISUAL.1991.175815",554
"10.1109/INFVIS.2000.885092","A taxonomy of visualization techniques using the data state reference model","Information Visualization, Data State Model,Reference Model, Taxonomy, Techniques, Operators",2000,"In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly","Ed Huai-hsin Chi","http://dx.doi.org/10.1109/INFVIS.2000.885092","10.1109/INFVIS.1997.636761;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1998.729560",555
"10.1109/INFVIS.2000.885098","ThemeRiver: visualizing theme changes over time","",2000,"ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events","Susan L. Havre;Elizabeth G. Hetzler;Lucy T. Nowell","http://dx.doi.org/10.1109/INFVIS.2000.885098","10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636789;10.1109/INFVIS.1998.729570",556
"10.1109/VISUAL.2000.885683","Hardware-accelerated volume and isosurface rendering based on cell-projection","Volume Rendering, Isosurfaces, Unstructured
Meshes, Cell Projection, Graphics Hardware, Texture Mapping, Compositing",2000,"We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.","Stefan Röttger;Martin Kraus;Thomas Ertl","http://dx.doi.org/10.1109/VISUAL.2000.885683","10.1109/VISUAL.1993.398846;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1999.809887;10.1109/VISUAL.1994.346308;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1994.346306;10.1109/VISUAL.1997.663853;10.1109/VISUAL.1999.809878;10.1109/VISUAL.1996.568127;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745713",557
"10.1109/VISUAL.2000.885694","Volume illustration: non-photorealistic rendering of volume models","Volume rendering, non-photorealistic rendering,illustration, lighting models, shading, visualization",2000,"Accurately and automatically conveying the structure of a volume model is a problem that has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing structural perception of volume models through the amplification of features and the addition of illumination effects.","David S. Ebert;Penny Rheingans","http://dx.doi.org/10.1109/VISUAL.2000.885694","10.1109/VISUAL.1996.568111;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1995.480795;10.1109/VISUAL.2000.885696;10.1109/VISUAL.1998.745319;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1990.146391",558
"10.1109/INFVIS.2002.1173148","SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation","",2002,"We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.","Catherine Plaisant;Jesse Grosjean;Benjamin B. Bederson","http://dx.doi.org/10.1109/INFVIS.2002.1173148","10.1109/VISUAL.1996.567745",559
"10.1109/INFVIS.2002.1173156","Interactive information visualization of a million items","",2002,"Existing information visualization techniques are usually limited to the display of a few thousand items. This article describes new interactive techniques capable of handling a million items (effectively visible and manageable on screen). We evaluate the use of hardware-based techniques available with newer graphics cards, as well as new animation techniques and non-standard graphical features such as stereovision and overlap count. These techniques have been applied to two popular information visualizations: treemaps and scatter plot diagrams; but are generic enough to be applied to other 2D representations as well.","Jean-Daniel Fekete;Catherine Plaisant","http://dx.doi.org/10.1109/INFVIS.2002.1173156","10.1109/INFVIS.2001.963274;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2001.963279;10.1109/INFVIS.1995.528685;10.1109/VISUAL.1996.567774",560
"10.1109/INFVIS.2002.1173157","Angular brushing of extended parallel coordinates","information visualization, parallel coordinates, brushing, linear correlations, focus+context visualization",2002,"In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.","Helwig Hauser;Florian Ledermann;Helmut Doleisch","http://dx.doi.org/10.1109/INFVIS.2002.1173157","10.1109/INFVIS.1996.559216;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402",561
"10.1109/VISUAL.2003.1250384","Acceleration techniques for GPU-based volume rendering","Volume Rendering, Programmable Graphics Hardware, Ray-Casting",2003,"Nowadays, direct volume rendering via 3D textures has positioned itself as an efficient tool for the display and visual analysis of volumetric scalar fields. It is commonly accepted, that for reasonably sized data sets appropriate quality at interactive rates can be achieved by means of this technique. However, despite these benefits one important issue has received little attention throughout the ongoing discussion of texture based volume rendering: the integration of acceleration techniques to reduce per-fragment operations. In this paper, we address the integration of early ray termination and empty-space skipping into texture based volume rendering on graphical processing units (GPU). Therefore, we describe volume ray-casting on programmable graphics hardware as an alternative to object-order approaches. We exploit the early z-test to terminate fragment processing once sufficient opacity has been accumulated, and to skip empty space along the rays of sight. We demonstrate performance gains up to a factor of 3 for typical renditions of volumetric data sets on the ATI 9700 graphics card.","Jens H. Krüger;Rüdiger Westermann","http://dx.doi.org/10.1109/VISUAL.2003.1250384","10.1109/VISUAL.1999.809889;10.1109/VISUAL.1997.663880;10.1109/VISUAL.1993.398852;10.1109/VISUAL.2002.1183764",562
"10.1109/VISUAL.2003.1250414","Curvature-based transfer functions for direct volume rendering: methods and applications","volume rendering, implicit surface curvature, convolution-based differentiation, non-photorealistic rendering, surface processing, uncertainty visualization, flowline curvature",2003,"Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.","Gordon L. Kindlmann;Ross T. Whitaker;Tolga Tasdizen;Torsten Möller","http://dx.doi.org/10.1109/VISUAL.2003.1250414","10.1109/VISUAL.2000.885696;10.1109/VISUAL.2002.1183766;10.1109/VISUAL.1995.480795;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183777",563
"10.1109/INFVIS.2004.1","A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations","Visualization of graphs, adjacency matrices, node-link representation, readability, evaluation",2004,"In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation","Mohammad Ghoniem;Jean-Daniel Fekete;Philippe Castagliola","http://dx.doi.org/10.1109/INFVIS.2004.1","10.1109/INFVIS.2003.1249030",564
"10.1109/INFVIS.2004.12","Building Highly-Coordinated Visualizations in Improvise","coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language",2004,"Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration","Chris Weaver","http://dx.doi.org/10.1109/INFVIS.2004.12","10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885086",565
"10.1109/INFVIS.2004.15","Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering","Multidimensional visualization, dimension order, visual clutter, visual structure",2004,"Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer's understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization's expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display","Wei Peng;Matthew O. Ward;Elke A. Rundensteiner","http://dx.doi.org/10.1109/INFVIS.2004.15","10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1990.146386;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559215;10.1109/INFVIS.2000.885086",566
"10.1109/INFVIS.2004.27","GeoTime Information Visualization","3-D visualization, spatiotemporal, geospatial, interactive visualization, visual data analysis, link analysis",2004,"Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks","Thomas Kapler;William Wright","http://dx.doi.org/10.1109/INFVIS.2004.27","10.1109/INFVIS.2003.1249006",567
"10.1109/INFVIS.2004.64","The InfoVis Toolkit","Information Visualization, Toolkit, Graphics, Integration",2004,"This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications","Jean-Daniel Fekete","http://dx.doi.org/10.1109/INFVIS.2004.64","10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.1995.528688;10.1109/INFVIS.2002.1173148",568
"10.1109/INFVIS.2004.66","Topological Fisheye Views for Visualizing Large Graphs","topological fisheye,large graph visualization",2004,"Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays","Emden R. Gansner;Yehuda Koren;Stephen C. North","http://dx.doi.org/10.1109/INFVIS.2004.66","10.1109/INFVIS.1997.636718;10.1109/INFVIS.2003.1249011",569
"10.1109/INFVIS.2005.1532122","Baby names, visualization, and social data analysis","Design Study, Time-Varying Data Visualization, Human-Computer Interaction",2005,"The Name Voyager, a Web based visualization of historical trends in baby naming, has proven remarkably popular. This paper discusses the interaction techniques it uses for smooth visual exploration of thousands of time series. We also describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables ""social"" data analysis","Martin Wattenberg","http://dx.doi.org/10.1109/INFVIS.2005.1532122","10.1109/INFVIS.2004.8;10.1109/INFVIS.2000.885098",570
"10.1109/INFVIS.2005.1532126","Vizster: visualizing online social networks","social networks, visualization, graphs, community,data mining, exploration, play",2005,"Recent years have witnessed the dramatic popularity of online social networking services, in which millions of members publicly articulate mutual ""friendship"" relations. Guided by ethnographic research of these online communities, we have designed and implemented a visualization system for playful end-user exploration and navigation of large scale online social networks. Our design builds upon familiar node link network layouts to contribute customized techniques for exploring connectivity in large graph structures, supporting visual search and analysis, and automatically identifying and visualizing community structures. Both public installation and controlled studies of the system provide evidence of the system's usability, capacity for facilitating discovery, and potential for fun and engaged social activity","Jeffrey Heer;Danah Boyd","http://dx.doi.org/10.1109/INFVIS.2005.1532126","10.1109/INFVIS.2004.1",571
"10.1109/INFVIS.2005.1532136","Low-level components of analytic activity in information visualization","Analytic activity, taxonomy, knowledge discovery, design, evaluation",2005,"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.","Robert A. Amar;James R. Eagan;John T. Stasko","http://dx.doi.org/10.1109/INFVIS.2005.1532136","10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.5;10.1109/INFVIS.2001.963289",572
"10.1109/INFVIS.2005.1532138","Revealing structure within clustered parallel coordinates displays","Parallel coordinates, clustering, transfer function, feature animation",2005,"In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.","Jimmy Johansson;Patric Ljung;Mikael Jern;Matthew D. Cooper","http://dx.doi.org/10.1109/INFVIS.2005.1532138","10.1109/VISUAL.1990.146402;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.68",573
"10.1109/INFVIS.2005.1532142","Graph-theoretic scagnostics","visualization, statistical graphics",2005,"We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.","Leland Wilkinson;Anushka Anand;Robert L. Grossman","http://dx.doi.org/10.1109/INFVIS.2005.1532142","10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.15",574
"10.1109/INFVIS.2005.1532150","Flow map layout","flow maps, GIS, hierarchical clustering",2005,"Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data.","Doantam Phan;Ling Xiao;Ron B. Yeh;Pat Hanrahan;Terry Winograd","http://dx.doi.org/10.1109/INFVIS.2005.1532150","10.1109/INFVIS.1995.528697;10.1109/INFVIS.1996.559226",575
"10.1109/VISUAL.2005.1532788","VisTrails: enabling interactive multiple-view visualizations","interrogative visualization, dataflow, caching, coordinated views",2005,"VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.","Louis Bavoil;Steven P. Callahan;Carlos Eduardo Scheidegger;Huy T. Vo;Patricia Crossno;Cláudio T. Silva;Juliana Freire","http://dx.doi.org/10.1109/VISUAL.2005.1532788","10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",576
"10.1109/TVCG.2006.147","Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data","Network visualization, edge bundling, edge aggregation, edge concentration, curves, graph visualization, tree visualization, node-link diagrams, hierarchies, treemaps",2006,"A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations","Danny Holten","http://dx.doi.org/10.1109/TVCG.2006.147","10.1109/INFVIS.2004.1;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2002.1173152",577
"10.1109/TVCG.2006.166","Network Visualization by Semantic Substrates","Network visualization, semantic substrate, information visualization, graphical user interfaces",2006,"Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations","Ben Shneiderman;Aleks Aris","http://dx.doi.org/10.1109/TVCG.2006.166","10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.2005.1532126",578
"10.1109/TVCG.2006.170","Outlier-Preserving Focus+Context Visualization in Parallel Coordinates","Parallel coordinates, focus+context visualization, outliers & trends, large data visualization",2006,"Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions","Matej Novotny;Helwig Hauser","http://dx.doi.org/10.1109/TVCG.2006.170","10.1109/INFVIS.1997.636793;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1990.146402",579
"10.1109/TVCG.2007.70515","Toward a Deeper Understanding of the Role of Interaction in Information Visualization","Information visualization, interaction, interaction techniques, taxonomy, visual analytics",2007,"Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.","Ji Soo Yi;Youn ah Kang;John T. Stasko;Julie A. Jacko","http://dx.doi.org/10.1109/TVCG.2007.70515","10.1109/VISUAL.1994.346302;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1996.559213;10.1109/VISUAL.1991.175794;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2000.885091;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2000.885086",580
"10.1109/TVCG.2007.70535","A Taxonomy of Clutter Reduction for Information Visualisation","Clutter reduction, information visualisation, occlusion, large datasets, taxonomy",2007,"Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.","Geoffrey P. Ellis;Alan J. Dix","http://dx.doi.org/10.1109/TVCG.2007.70535","10.1109/INFVIS.2003.1249018;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.138;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1998.745301;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249019;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.170",581
"10.1109/TVCG.2007.70539","Animated Transitions in Statistical Data Graphics","Statistical data graphics, animation, transitions, information visualization, design, experiment",2007,"In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in DynaVis, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.","Jeffrey Heer;George G. Robertson","http://dx.doi.org/10.1109/TVCG.2007.70539","10.1109/INFVIS.1999.801854;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173148",582
"10.1109/TVCG.2007.70541","Casual Information Visualization: Depictions of Data in Everyday Life","Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation",2007,"Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.","Zachary Pousman;John T. Stasko;Michael Mateas","http://dx.doi.org/10.1109/TVCG.2007.70541","10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375",583
"10.1109/TVCG.2007.70577","ManyEyes: a Site for Visualization at Internet Scale","Visualization, World Wide Web, Social Software, Social Data Analysis, Communication-Minded Visualization",2007,"We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.","Fernanda B. Viégas;Martin Wattenberg;Frank van Ham;Jesse Kriss;Matthew M. McKeon","http://dx.doi.org/10.1109/TVCG.2007.70577","10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1991.175820;10.1109/INFVIS.2003.1249007",584
"10.1109/TVCG.2007.70582","NodeTrix: a Hybrid Visualization of Social Networks","Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction",2007,"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.","Nathalie Henry Riche;Jean-Daniel Fekete;Michael J. McGuffin","http://dx.doi.org/10.1109/TVCG.2007.70582","10.1109/TVCG.2006.160;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532129;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147;10.1109/INFVIS.2004.64;10.1109/INFVIS.2003.1249011",585
"10.1109/TVCG.2007.70594","Show Me: Automatic Presentation for Visual Analysis","Automatic presentation, visual analysis, graphic design, best practices, data visualization, small multiples",2007,"This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.","Jock D. Mackinlay;Pat Hanrahan;Chris Stolte","http://dx.doi.org/10.1109/TVCG.2007.70594","10.1109/INFVIS.2000.885086",586
"10.1109/VAST.2007.4389006","Jigsaw: Supporting Investigative Analysis through Interactive Visualization","Visual analytics, investigative analysis, intelligence analysis, information visualization, multiple views",2007,"Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.","John T. Stasko;Carsten Görg;Zhicheng Liu;Kanupriya Singhal","http://dx.doi.org/10.1109/VAST.2007.4389006","10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.27;10.1109/VAST.2006.261432",587
"10.1109/TVCG.2008.125","Effectiveness of Animation in Trend Visualization","Information visualization, animation, trends, design, experiment",2008,"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.","George G. Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John T. Stasko","http://dx.doi.org/10.1109/TVCG.2008.125","10.1109/INFVIS.1999.801854;10.1109/TVCG.2007.70539",588
"10.1109/TVCG.2008.137","Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation","Visualization, history, undo, analysis, presentation, evaluation",2008,"Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.","Jeffrey Heer;Jock D. Mackinlay;Chris Stolte;Maneesh Agrawala","http://dx.doi.org/10.1109/TVCG.2008.137","10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",589
"10.1109/TVCG.2008.153","Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation","Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction",2008,"Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.","Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete","http://dx.doi.org/10.1109/TVCG.2008.153","10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70577;10.1109/VISUAL.1990.146386;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.15",590
"10.1109/TVCG.2008.166","Stacked Graphs - Geometry & Aesthetics","Streamgraph, ThemeRiver, listening history, lastfm, aesthetics, communication-minded visualization, time series",2008,"In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.","Lee Byron;Martin Wattenberg","http://dx.doi.org/10.1109/TVCG.2008.166","10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70577;10.1109/INFVIS.2000.885098",591
"10.1109/VAST.2008.4677365","Characterizing users' visual analytic activity for insight provenance","Taxonomy, Information Visualization, Analytic Activity, Visual Analytics, Insight Provenance",2008,"Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.","David Gotz;Michelle X. Zhou","http://dx.doi.org/10.1109/VAST.2008.4677365","10.1109/INFVIS.2004.2;10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70577;10.1109/VISUAL.2005.1532788;10.1109/VAST.2007.4388992;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/VAST.2006.261430;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375;10.1109/VISUAL.2002.1183791",592
"10.1109/TVCG.2009.111","A Nested Model for Visualization Design and Validation","Models, frameworks, design, evaluation",2009,"We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.","Tamara Munzner","http://dx.doi.org/10.1109/TVCG.2009.111","10.1109/VAST.2007.4389008;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2008.117;10.1109/TVCG.2006.160;10.1109/VISUAL.1998.745289;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2008.125;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2005.1532150;10.1109/VISUAL.1990.146375",593
"10.1109/TVCG.2009.122","Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations","clustering, spatial layout, graph visualization, tree visualization",2009,"While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.","Christopher Collins;Gerald Penn;M. Sheelagh T. Carpendale","http://dx.doi.org/10.1109/TVCG.2009.122","10.1109/TVCG.2006.122;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.130;10.1109/TVCG.2008.144;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.153",594
"10.1109/TVCG.2009.153","Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics","dimensionality reduction, interactivity, quality metrics, variable ordering",2009,"Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.","Sara Johansson;Jimmy Johansson","http://dx.doi.org/10.1109/TVCG.2009.153","10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.161;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2008.138;10.1109/INFVIS.2004.15",595
"10.1109/TVCG.2010.181","Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty","Uncertainty visualization, weather ensemble, geographic/geospatial visualization, glyph-based techniques, time-varying data, qualitative evaluation",2010,"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 ""Superstorm"". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.","Jibonananda Sanyal;Song Zhang 0004;Jamie Dyer;Andrew Mercer 0001;Philip Amburn;Robert J. Moorhead II","http://dx.doi.org/10.1109/TVCG.2010.181","10.1109/TVCG.2009.114;10.1109/INFVIS.2002.1173145",596
